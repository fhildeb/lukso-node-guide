// File: archive/network/blockchain-timeline

# Blockchain Timeline

This timeline outlines the key milestones that led from early project phases to the launch of network.

| Date                           | Event                                                                                                                                         | Description                                                                                                                                                                                            |
| ------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| <nobr> Aug 2019 </nobr>        | [L14 Testnet Launch](https://medium.com/lukso/the-puzzle-comes-together-milestone-update-2022-7b69571f63a2)                                   | Launched a first Proof-of-Authority network for testing purposes.                                                                                                                                      |
| <nobr> Sep 2019 </nobr>        | [Universal Profile Prototype](https://l14.universalprofile.cloud/)                                                                            | Released the first blockchain-based [Profile Explorer](https://l14.universalprofile.cloud/) on L14.                                                                                                    |
| <nobr> **20 May 2020** </nobr> | **[Reversible ICO](https://medium.com/lukso/re-launching-the-reversible-ico-5289989ce7ed)**                                                   | **Launched a [Reversible ICO](https://medium.com/lukso/rico-the-reversible-ico-5392bf64318b) on Ethereum, introducing [LYXe](https://etherscan.io/token/0xA8b919680258d369114910511cc87595aec0be6D).** |
| <nobr> 28 Oct 2021 </nobr>     | [L15 Testnet Launch](https://medium.com/lukso/l15-the-ephemeral-testnet-has-undergone-some-heavy-developments-in-the-past-weeks-f0f67aa30cc0) | Launched a testnet using the [Vanguard and Pandora](https://medium.com/lukso/lukso-mainnet-progress-update-1-5d678e47a3eb) stack.                                                                      |
| <nobr> Feb - Dec 2022</nobr>   | [L16 Testnet Phase](https://medium.com/lukso/the-advent-of-the-l16-testnet-3e352ddee229)                                                      | Iteration through multiple testnets using Ethereum Proof-of-Stake.                                                                                                                                     |
| <nobr> 19 Apr 2023 </nobr>     | [Genesis Deposit Launch](https://medium.com/lukso/genesis-validators-deposit-smart-contract-freeze-and-testnet-launch-c5f7b568b1fc)           | Opened the [Deposit Contract](https://etherscan.io/address/0x42000421dd80D1e90E56E87e6eE18D7770b9F8cC#code) on Ethereum to launch the network.                                                         |
| <nobr> 03 May 2023 </nobr>     | [Deposit Contract Freeze](https://etherscan.io/tx/0x668eecd9465fbbafa3e15e28efa88b767bc23227f8266ff854fbd701d9c6a8b7#eventlog)                | Manual freeze of the Genesis Deposit Contract was initiated.                                                                                                                                           |
| <nobr> 03 May 2023 </nobr>     | [LUKSO Testnet Launch](https://medium.com/lukso/genesis-validators-deposit-smart-contract-freeze-and-testnet-launch-c5f7b568b1fc)             | The testnet was launched by core community members.                                                                                                                                                    |
| <nobr> 10 May 2023 </nobr>     | [Final Deposits Received](https://etherscan.io/address/0x42000421dd80D1e90E56E87e6eE18D7770b9F8cC#tokentxns)                                  | The genesis deposit contract was frozen to finalize deposits.                                                                                                                                          |
| <nobr> **23 May 2023** </nobr> | **[LUKSO Mainnet Launch](https://medium.com/lukso/genesis-validators-start-your-clients-fe01db8f3fba)**                                       | **The LUKSO Blockchain was launched by Genesis Validators.**                                                                                                                                           |
| <nobr> May - Jul 2023 </nobr>  | [Mainnet Discovery Month](https://medium.com/lukso/lukso-mainnet-timeline-and-process-dd997fe811c8)                                           | Network stabilization phase before LYXe migration and withdrawals.                                                                                                                                     |
| <nobr> 04 Jul 2023 </nobr>     | [Validator Onboarding](https://medium.com/lukso/pending-validator-deposits-and-the-migration-process-770db9cd486e)                            | Start of new validator registration using LYX on the mainnet.                                                                                                                                          |
| <nobr> **12 Jul 2023** </nobr> | **[LYXe Migration Launch](https://medium.com/lukso/the-lyxe-migration-process-374053e5ddf5)**                                                 | **Launched the Migration from LYXe to LYX.**                                                                                                                                                           |
| <nobr> 12 Sep 2023 </nobr>     | [UP Extension Release](https://medium.com/lukso/the-universal-profile-browser-extension-beta-is-here-7944cfd5eeb7)                            | Released the [Universal Profile Extension](https://chromewebstore.google.com/detail/universal-profiles/abpickdkkbnbcoepogfhkhennhfhehfn) for Universal Profiles.                                       |
| <nobr> 25 Oct 2023 </nobr>     | [Universal Profile Launch](https://universaleverything.io/)                                                                                   | Launched Universal Profiles, Management Tools, and a Relay Service.                                                                                                                                    |
| <nobr> 25 May 2025 </nobr>     | [LYXe Migration Deadline](https://medium.com/lukso/lyxe-to-lyx-migration-deadline-update-from-4-years-to-2-years-f58cb915f5e8)                | Closed the LYXe transition phase after more than 2 years.                                                                                                                                              |

---

// File: archive/network/configuration-updates

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Configuration Updates

This page lists changes introduced to the [LUKSO Mainnet Network Configuration Files](https://github.com/lukso-network/network-configs) since [Genesis Launch on 23 May 2023](https://explorer.execution.mainnet.lukso.network/block/1).

:::tip

Client-specific blockchain configurations can be updated on a node setup by:

- üé® **[DAppNode](https://dappnode.com/)**: Reinstalling both execution and consensus clients, as their configuration is only fetched during setup.
- üëæ **[LUKSO CLI](https://github.com/lukso-network/tools-lukso-cli)**: Updating files manually, as `lukso update configs` only affects shared, cross-client configurations.
- üê≥ **[Docker](https://github.com/lukso-network/network-docker-containers)**: Updating the client's `docker_compose.yml` files for the container configuration.
- üóÇÔ∏è **[Custom](https://docs.lukso.tech/networks/mainnet/running-a-node#-with-your-own-clients)**: Redownloading the network configuration or updating files manually.

:::

:::info

The page was last updated on July 30, 2025. Up-to-date until commit [#150](https://github.com/lukso-network/network-configs/pull/150/).

:::

## Geth File

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>
vim geth/geth.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>
nano geth/geth.toml
```

</TabItem>
</Tabs>

| Date        | Action  | Property                | Commit                                                                  |
| ----------- | ------- | ----------------------- | ----------------------------------------------------------------------- |
| 15 Mar 2024 | updated | `GasPrice = 1000000000` | [#132](https://github.com/lukso-network/network-configs/pull/132/files) |
| 4 Oct 2024  | updated | `GasPrice = 1000000`    | [#143](https://github.com/lukso-network/network-configs/pull/143/files) |

## Besu File

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>
vim besu/besu.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>
nano besu/besu.toml
```

</TabItem>
</Tabs>

| Date       | Action  | Property                 | Commit                                                                  |
| ---------- | ------- | ------------------------ | ----------------------------------------------------------------------- |
| 4 Oct 2024 | updated | `'min-gas-price' = 1000` | [#143](https://github.com/lukso-network/network-configs/pull/143/files) |

## Erigon File

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>
vim erigon/erigon.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>
nano erigon/erigon.toml
```

</TabItem>
</Tabs>

| Date        | Action  | Property                                | Commit                                                                  |
| ----------- | ------- | --------------------------------------- | ----------------------------------------------------------------------- |
| 21 Jun 2023 | removed | `"externalcl" = true`                   | [#115](https://github.com/lukso-network/network-configs/pull/115/files) |
| 21 Jun 2023 | added   | `"snapshots" = false`                   | [#115](https://github.com/lukso-network/network-configs/pull/115/files) |
| 21 Jun 2023 | added   | `"prune" = "htc"`                       | [#115](https://github.com/lukso-network/network-configs/pull/115/files) |
| 5 Jul 2023  | added   | `"private.api.addr" = "127.0.0.1:9098"` | [#118](https://github.com/lukso-network/network-configs/pull/118/files) |
| 27 Dec 2023 | added   | `"db.size.limit" = "8TB"`               | [#129](https://github.com/lukso-network/network-configs/pull/129/files) |
| 17 Jul 2024 | added   | `"maxpeers" = 100`                      | [#138](https://github.com/lukso-network/network-configs/pull/138/files) |
| 30 Jul 2025 | removed | `"snapshots" = false`                   | [#149](https://github.com/lukso-network/network-configs/pull/149/files) |
| 30 Jul 2025 | removed | `"prune" = "htc"`                       | [#149](https://github.com/lukso-network/network-configs/pull/149/files) |
| 30 Jul 2025 | added   | `"prune.mode" = "full"`                 | [#149](https://github.com/lukso-network/network-configs/pull/149/files) |

## Lighthouse File

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>
vim lighthouse/lighthouse.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>
nano lighthouse/lighthouse.toml
```

</TabItem>
</Tabs>

| Date        | Action  | Property                      | Commit                                                                  |
| ----------- | ------- | ----------------------------- | ----------------------------------------------------------------------- |
| 21 Jun 2023 | removed | `http-address = "0.0.0.0"`    | [#116](https://github.com/lukso-network/network-configs/pull/116/files) |
| 21 Jun 2023 | removed | `metrics-address = "0.0.0.0"` | [#116](https://github.com/lukso-network/network-configs/pull/116/files) |
| 21 Jun 2023 | removed | `metrics-allow-origin = "\*"` | [#116](https://github.com/lukso-network/network-configs/pull/116/files) |
| 21 Jun 2023 | added   | `metrics = true`              | [#116](https://github.com/lukso-network/network-configs/pull/116/files) |
| 21 Jun 2023 | added   | `metrics-port=5057`           | [#116](https://github.com/lukso-network/network-configs/pull/116/files) |

## Prysm File

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>
vim prysm/prysm.yaml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>
nano prysm/prysm.yaml
```

</TabItem>
</Tabs>

| Date        | Action  | Property                             | Commit                                                                  |
| ----------- | ------- | ------------------------------------ | ----------------------------------------------------------------------- |
| 19 Sep 2023 | removed | `p2p-host-ip: '0.0.0.0'`             | [#112](https://github.com/lukso-network/network-configs/pull/112/files) |
| 1 Mar 2024  | updated | `min-sync-peers: 1`                  | [#131](https://github.com/lukso-network/network-configs/pull/131/files) |
| 1 Mar 2024  | updated | `minimum-peers-per-subnet: 1`        | [#131](https://github.com/lukso-network/network-configs/pull/131/files) |
| 1 Mar 2024  | removed | `block-batch-limit: 512`             | [#131](https://github.com/lukso-network/network-configs/pull/131/files) |
| 1 Mar 2024  | removed | `block-batch-limit-burst-factor: 10` | [#131](https://github.com/lukso-network/network-configs/pull/131/files) |
| 3 Jul 2023  | added   | `contract-deployment-block: 0`       | [#117](https://github.com/lukso-network/network-configs/pull/117/files) |
| 30 Aug 2024 | removed | `subscribe-all-subnets: true`        | [#135](https://github.com/lukso-network/network-configs/pull/135/files) |
| 17 Jul 2024 | added   | `p2p-max-peers: 70`                  | [#138](https://github.com/lukso-network/network-configs/pull/138/files) |

## Teku File

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>
vim teku/config.yaml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>
nano teku/config.yaml
```

</TabItem>
</Tabs>

| Date        | Action  | Property                                      | Commit                                                                  |
| ----------- | ------- | --------------------------------------------- | ----------------------------------------------------------------------- |
| 22 Sep 2023 | added   | `MIN_EPOCHS_FOR_BLOCK_REQUESTS: 33024`        | [#128](https://github.com/lukso-network/network-configs/pull/128/files) |
| 21 Mar 2024 | added   | `MAX_PER_EPOCH_ACTIVATION_CHURN_LIMIT: 8`     | [#134](https://github.com/lukso-network/network-configs/pull/134/files) |
| 2 Oct 2024  | updated | `DENEB_FORK_EPOCH: 123075`                    | [#142](https://github.com/lukso-network/network-configs/pull/142/files) |
| 2 Oct 2024  | added   | `MAX_PER_EPOCH_ACTIVATION_CHURN_LIMIT: 8`     | [#142](https://github.com/lukso-network/network-configs/pull/142/files) |
| 2 Oct 2024  | added   | `MAX_REQUEST_BLOCKS_DENEB: 128`               | [#142](https://github.com/lukso-network/network-configs/pull/142/files) |
| 2 Oct 2024  | added   | `MAX_REQUEST_BLOB_SIDECARS: 768`              | [#142](https://github.com/lukso-network/network-configs/pull/142/files) |
| 2 Oct 2024  | added   | `MIN_EPOCHS_FOR_BLOB_SIDECARS_REQUESTS: 4096` | [#142](https://github.com/lukso-network/network-configs/pull/142/files) |
| 2 Oct 2024  | added   | `BLOB_SIDECAR_SUBNET_COUNT: 6`                | [#142](https://github.com/lukso-network/network-configs/pull/142/files) |
| 6 Feb 2025  | added   | `MAX_BLOBS_PER_BLOCK: 6`                      | [#146](https://github.com/lukso-network/network-configs/pull/146/files) |
| 29 Jul 2025 | added   | `ELECTRA_FORK_VERSION: 0x42000006`            | [#148](https://github.com/lukso-network/network-configs/pull/148/files) |
| 29 Jul 2025 | added   | `ELECTRA_FORK_EPOCH: 190800`                  | [#148](https://github.com/lukso-network/network-configs/pull/148/files) |

## Nimbus File

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>
vim nimbus2/config.yaml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>
nano nimbus2/config.yaml
```

</TabItem>
</Tabs>

| Date        | Action | Property                           | Commit                                                                  |
| ----------- | ------ | ---------------------------------- | ----------------------------------------------------------------------- |
| 29 Jul 2025 | added  | `ELECTRA_FORK_VERSION: 0x42000006` | [#148](https://github.com/lukso-network/network-configs/pull/148/files) |
| 29 Jul 2025 | added  | `ELECTRA_FORK_EPOCH: 190800`       | [#148](https://github.com/lukso-network/network-configs/pull/148/files) |

---

// File: archive/network/network-forks

# Network Forks

Forks are network upgrades that alter or enhance functionality within blockchain networks. LUKSO, as EVM-based network, applies these upgrades to stay in sync with Ethereum's ongoing technological evolution. Upgrades might introduce consensus changes, performance improvements, execution layer capabilities, or new protocol rules.

| Date                       | Epoch  | Phase    | Included Updates                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| -------------------------- | ------ | -------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> 23 May 2023 </nobr> | 0      | Genesis  | - [Homestead](https://ethereum.org/en/history/#homestead) <br /> - [Byzantium](https://ethereum.org/en/history/#byzantium) <br/> - [Constantinople](https://ethereum.org/en/history/#constantinople) <br/> - [Petersburg](https://ethereum.org/en/history/#petersburg) <br/> - [Istanbul](https://ethereum.org/en/history/#istanbul) <br/> - [Berlin](https://ethereum.org/en/history/#berlin) <br/> - [London](https://ethereum.org/en/history/#london) <br/> - [Paris](https://ethereum.org/en/upgrades/merge/) | - Introduced static gas costs and contract creation protections <br/> - Added cryptographic precompiles and opcode enhancements <br/> - Enabled cheaper operations and off-chain contract execution <br/> - Disabled flawed EIPs to mitigate reentrancy attacks <br/> - Optimized zero-knowledge proof costs and gas pricing <br/> - Added chain IDs, opcodes, and streamlined gas accounting <br/> - Activated [EIP-1559](https://eips.ethereum.org/EIPS/eip-1559) for fee market reform and base fee burn <br/> - Merged Proof of Stake consensus via beacon chain |
| <nobr> 28 Jun 2023 </nobr> | 8100   | Shapella | - [Shanghai](https://ethereum.org/en/history/#shapella) <br/> - [Capella](https://ethereum.org/en/history/#shapella)                                                                                                                                                                                                                                                                                                                                                                                              | - Enabled continious validator withdrawals <br/> - Execution-Layer gas cost improvements                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| <nobr> 20 Nov 2024 </nobr> | 123075 | Dencun   | - [Cancun](https://ethereum.org/en/history/#dencun) <br/> - [Deneb](https://ethereum.org/en/history/#dencun)                                                                                                                                                                                                                                                                                                                                                                                                      | - Introduced blobs for [EIP-4844](https://eips.ethereum.org/EIPS/eip-4844) proto-danksharding <br/> - Consensus updates for blob handling                                                                                                                                                                                                                                                                                                                                                                                                                            |
| <nobr> 17 Sep 2025 </nobr> | 190800 | Pectra   | - [Prague](https://ethereum.org/en/roadmap/pectra/) <br/> - [Electra](https://ethereum.org/en/roadmap/pectra/)                                                                                                                                                                                                                                                                                                                                                                                                    | - Implements native account abstraction & BLS precompiles <br/> - Enhances validator exits, stake limits and blob throughput                                                                                                                                                                                                                                                                                                                                                                                                                                         |

---

// File: archive/testnet-operators/l16-client-setup

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# L16 Client Setup

This guide walks through the setup of a LUKSO L16 testnet node using the Legacy CLI and Docker.

:::danger Historical Guide

This guide is kept for historical reference. The old LUKSO CLI and L16 Faucet are unavailable by now.

:::

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Software Installation

**1.1 LUKSO CLI Download**: _Move to your home directory, then fetch and execute the installation script._

```sh
cd ~
curl https://raw.githubusercontent.com/lukso-network/lukso-cli/main/cli_downloader.sh | bash
```

**1.2 Add the CLI to Binary Path**: _Move the binary into the system path so it can be called globally._

```sh
sudo mv ~/lukso /usr/local/bin
```

**1.3 Install Docker**: _Install the Docker runtime environment used to run client containers._

```sh
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
```

**1.4 Install Docker Compose**: _Install Docker Compose to manage multi-container deployments._

```sh
sudo curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
docker-compose --version
```

**1.5 Setup the Node Environment**: _Create the node directory and initialize the network configuration._

```sh
mkdir l16-node-testnet
cd l16-node-testnet
lukso network init
```

## 2. Network Configuration

**2.1 Set the Environment Name**: _Edit the environment file to name your node using your preferred text editor._

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
vim .env
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
nano .env
```

</TabItem>
</Tabs>

**2.2 Set the Node Name**: _Edit the node config file to name your node using your preferred text editor._

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
vim node_config.yaml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
nano node_config.yaml
```

</TabItem>
</Tabs>

:::info

The name is used to reference your node in the node explorer. Genesis validators use `beta-genesis-validator_XX` and replace the `XX` with the validator number of their ZIP files that they received, housing the funded validator keys.

:::

**2.3 Update the Network Configuration**: _Retrieve and overwrite the network configuration with the latest bootnodes and specs._

```sh
lukso network update
lukso network refresh
```

## 3. Deposit Key Integration

<Tabs groupId="validator">
  <TabItem value="regular" label="Regular Validators" default>

**3.1 Generate Validator Keys**: _Generate new validator deposit keys directly from the validator wallet of the consensus client._

```sh
lukso network validator setup
```

**3.2 Save Mnemonics**: _Add the mnemonic seed of your wallet into the node configuration using your preferred text editor._

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
vim node_config.yaml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
nano node_config.yaml
```

</TabItem>
</Tabs>

**3.3 Check Validator Status**: _Verify the amount of validator keys to determine the LYXt amount needed for deposits._

```sh
lukso network validator describe
```

**3.4 Fund Wallet**: _Visit the [L16 Faucet](https://faucet.l16.lukso.network/) and fund your address with at least 32 LYX for one validator._

![L16 Faucet](/img/archive/l16_faucet.png)

**3.5 Dry Run Deposit**: _Simulate the validator deposit process to ensure your mnemonic seed was added correctly._

```sh
lukso network validator deposit --dry
```

**3.6 Execute Deposit**: _If there were no isuess, execute the deposit on the L16 testnet using your wallet funds._

```sh
lukso network validator deposit
```

**3.7 Backup the Validator Keys**: _Save the validator keys in a recovery file._

```sh
lukso network validator backup
```

:::warning

The LUKSO CLI will generate a `node_recovery.json` file in its working directory. Store it securely on an offline device.

:::

</TabItem> <TabItem value="genesis" label="Genesis Validators">

**Import Validator Keys**: _Unzip and copy your validator files into the keystore directory._

```sh
cd
mkdir l16-node-testnet/keystore
mv beta l16-node-testnet/keystore
```

:::tip

Genesis Validators received whitelisted and funded validator keys from the LUKSO Network Team via Email and had to pre-register via the official validator questionary to receive a spot in the public node list.

:::

:::info

Ensure all validator files are inside the `keystore` folder and not within nested directories.

:::

</TabItem> 
</Tabs>

## 4. Folder Structure Check

**Check the Folder Structure**: _During the setup and key integration, your working directory created new files._

```sh
cd l16-node-testnet
ls -al
```

```sh
l16-node-testnet
‚îú‚îÄ‚îÄ configs
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ config.yaml
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ genesis.json
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ genesis.ssz
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îú‚îÄ‚îÄ consensus_data
‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ beaconchaindata
‚îÇ   ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ metaData
‚îÇ   ‚îú‚îÄ‚îÄ execution_data
‚îÇ   ‚îî‚îÄ‚îÄ validator_data
‚îú‚îÄ‚îÄ deposit_data.json
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ keystore
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ keys
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ lodestar-secrets
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ nimbus-keys
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ password.txt
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ prysm
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pubkeys.json
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ secrets
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ teku-keys
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ teku-secrets
‚îú‚îÄ‚îÄ node_config.yaml
‚îî‚îÄ‚îÄ transaction_wallet
```

:::info

The data folder will apear during the first node start using the `sudo lukso network start` command.

:::

## 5. Node Startup

<Tabs>
<TabItem value="validator" label="Validator Node" default>

**Start the Validator**: _Execute the consensus and execution clients with the deposit keys of the node wallet._

```sh
cd ~/l16-node-testnet
lukso network start
lukso network start validator
```

:::info

Your node should start staking once synced. It can take up to eight hours before the deposit becomes active.

:::

</TabItem><TabItem value="regular" label="Regular Fullnode">

**Start the Node**: _Execute the consensus and execution clients based on the CLI client configurations and network stats._

```sh
cd ~/l16-node-testnet
lukso network start
```

</TabItem> 
</Tabs>

:::tip

Details about analyzing the staking and node processes can be found on the [**Monitoring**](/docs/guides/monitoring/software-preparation.md) page of the üìñ [**Guide**](/docs/guides/validator-setup/precautions.md) section.

:::

---

// File: archive/testnet-operators/l16-node-tooltips

# L16 Node Tooltips

This page provides quick access to LUKSO L16 testnet node commands through the Legacy CLI and Docker.

:::danger Historical Guide

This guide is kept for historical reference. The old LUKSO CLI commands may be unavailable by now.

:::

:::info

The following steps are performed on your üìü **node server**.

:::

## Stop Node Operation

```sh
lukso network stop validator
lukso network stop
```

## Clear Network Config

```sh
lukso network stop validator
lukso network stop
lukso network clear
lukso network init
```

## Update Bootnodes

```sh
lukso network update
lukso network refresh
```

## Restart the Validator

```sh
lukso network start
lukso network start validator
```

## Check Docker Containers

```sh
docker ps -a
```

## Monitor Docker Images

```sh
docker images -a
```

## Log Blockchain Clients

:::tip

Open multiple terminals to track them all at the same time.

:::

```sh
# Execution Client
sudo docker logs lukso-geth -f

# Validator Client
sudo docker logs prysm_validator -f

# Consensus Client
sudo docker logs prysm_beacon -f

# ETH Stats Monitoring Service
sudo docker logs eth2stats-client -f
```

:::info

Use `Control + C` to exit the logs and return to the regular terminal window.

:::

---

// File: archive/testnet-operators/l16-software-removal

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# L16 Software Removal

This guide teaches you how to remove the Legacy LUKSO CLI and all installed data after completing L16 testnet runs.

:::danger Historical Guide

This guide is kept for historical reference. The old LUKSO CLI commands may be unavailable by now.

:::

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Remove LUKSO CLI

**1.1 Stop the Node**: _Make sure all running LUKSO services are stopped._

```sh
lukso network stop validator
lukso network stop
```

**1.2 Delete CLI Binary**: _Remove the LUKSO CLI from the binary path._

```sh
cd /usr/local/bin
ls -al
sudo rm -rf lukso
```

## 2. Remove Docker Data

Depending on the further use of the server, there are two different ways to reset docker data used for node operation.

| **Method**                           | **Description**                                                                                                                                                                    | **Removed Software**                                                                                                                              |
| ------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> **Node Data Removal** </nobr> | This lightway version only removes the data related to the blockchain node operation. If you continue to use the server and _Docker_ for other purposes, this is the right choice. | - Stopped Containers <br /> - LUKSO L16 Images <br />                                                                                             |
| <nobr> **System Prune** </nobr>      | This is a complete removal of the container setup and the entire data that has ever been worked with. Its the ideal choice if you are not using _Docker_ for other software.       | <nobr> - Stopped Containers and Images </nobr><br /> - All Volumes and Networks<br /> - Docker Compose Tool <br /> - Docker Tool and Config Files |

<Tabs>
<TabItem value="soft" label="Node Data Removal" default>

**2.1 Remove Docker Containers**: _Find and remove containers related to your node._

```sh
docker ps -a
sudo docker rm <container-id>
```

**2.2 Remove Docker Images**: _Find and remove images associated with LUKSO services._

```sh
docker images -a
sudo docker rmi <image-id>
```

:::tip

Containers and images are typically named `docker-geth/geth`, `docker-prysm/beacon`, `docker-prysm/validator`.

:::

:::info

Replace `<container-id>` and `<image-id>` with the actual identification numbers like `7e9f0a29f3b3`, or `c3c1a1d3b6a1`.

:::

</TabItem>
<TabItem value="hard" label="System Prune">

**2.1 Prune Docker System**: _This will delete all Docker data and cache._

```sh
sudo docker system prune -a
```

**2.2 Remove Docker Compose**:

```sh
sudo rm -rf /usr/local/bin/docker-compose
```

**2.3 Remove Docker Directories**:

```sh
sudo rm -rf /var/lib/docker
sudo rm -rf /etc/docker
```

</TabItem>
</Tabs>

## 3. Remove Blockchain Data

**3.1 Backup Your Validator Keys**: _Copy the keystore and wallet folders into a new directory._

```sh
cd ~
mkdir l16-key-backup
cd <my-node-folder>
mv keystore ~/l16-key-backup/keystore
mv transaction_wallet ~/l16-key-backup/transaction_wallet
cd ..
```

**3.2 Delete the Node Folder**: _Remove the old working directory with all blockchain data, logs, wallets, and configs._

```sh
sudo rm -rf <my-node-folder>
```

:::info

Replace `<my-node-folder>` with your actual node directory like `l16-node-testnet`.

:::

## 4. Remove Monitoring Software

**4.1 Stop Monitoring Services**: _Stop the software daemons of the dashboard and data collector._

```sh
systemctl stop grafana-server
systemctl stop prometheus
```

**4.2 Remove Monitoring Packages**: _Delete all tools used to install exporters or dashboards._

```sh
sudo apt remove apt-transport-https software-properties-common wget grafana-enterprise
```

**4.3 Delete Exporter Binaries**: _Delete the exporter services of Prometheus._

```sh
cd /usr/local/bin
sudo rm -rf node_exporter prometheus promtool blackbox_exporter
```

**4.4 Remove Database Files**: _Delete the data collected by Grafana and Prometheus._

```sh
cd /var/lib
sudo rm -rf prometheus grafana
```

**4.5 Remove Systemd Services**: _Delete service configurations of Grafana._

```sh
cd /lib/systemd/system
sudo rm -rf grafana-server.service grafana-server.service.old
```

**4.6 Remove Configurations**: _Delete data collection configurations for exporters, Grafana, and Prometheus._

```sh
cd /etc
sudo rm -rf prometheus grafana blackbox_exporter

cd /etc/systemd/system
sudo rm -rf prometheus.service grafana.service blackbox_exporter.service
```

---

// File: archive/genesis-validators/blockchain-launch

# Blockchain Launch

Before creating its blockchain as an independent network, LUKSO conducted a [Reversible Initial Coin Offering](https://medium.com/lukso/re-launching-the-reversible-ico-5289989ce7ed) in 2020, which provided for tokenization of the LYX token on the Ethereum platform. The token's primary purpose was to invest in the project and start the upcoming blockchain distributedly. Over time, changes were introduced into the network's [genesis supply](https://medium.com/lukso/its-happening-the-genesis-validators-are-coming-ce5e07935df6) of LYX, and additional LYXe was burned respectively.

:::tip Token Contract

LYXe is based on the [**ERC-777**](https://eips.ethereum.org/EIPS/eip-777) standardization and can be viewed on üèôÔ∏è [**Etherscan**](https://etherscan.io/token/0xA8b919680258d369114910511cc87595aec0be6D).

:::

## Genesis Deposits

On the 19th of April, 2023, LUKSO launched the [Genesis Deposit Contract](https://etherscan.io/address/0x42000421dd80D1e90E56E87e6eE18D7770b9F8cC#code) as an entry portal for the creation of a unique blockchain. All users who held as little as 32 LYXe were allowed to lock up their LYXe in this deposit contract and become genesis validators. Participants pre-reserved their validator spots in the genesis files, which allowed them to start a staking node.

The deposit contract remained open for about three weeks, whereupon it was manually triggered by the team on the 3rd of May 2023, as part of the launch of the [LUKSO Testnet](https://medium.com/lukso/genesis-validators-deposit-smart-contract-freeze-and-testnet-launch-c5f7b568b1fc). Following a predefined delay of one week, final deposits were received on the 10th of May 2023. About 223 separate wallets took part in deposits for more than 10,000 validators, totaling more than 330,000 LYXe, an approximately 3.5 million-dollar equivalent at that time. Community participants and builders carried out all these deposits, as the LUKSO team did not actively distribute stake. Due to the high demand of the Ethereum network during the time, gas prices soared and LUKSO decided to [pay back the gas costs](https://medium.com/lukso/genesis-validators-deposit-smart-contract-freeze-and-testnet-launch-c5f7b568b1fc) of the first 10,000 genesis validators in ETH.

:::tip

Further details about [**Proof of Stake**](/docs/theory/blockchain-knowledge/proof-of-stake.md), [**Tokenomics**](/docs/theory/blockchain-knowledge/tokenomics.md), and [**Peer Networks**](/docs/theory/blockchain-knowledge/peer-networks.md) can be found in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

:::info

Further insights about the genesis validators can be gathered from the [**Dune Analytics Dashboard**](https://dune.com/hmc/lukso-genesis-validators) by [**Hugo Masclet**](https://x.com/HugoApps).

:::

## Genesis Deposit Contract

Instead of using protocol-level checks while validators deposit on the live blockchain, the [Genesis Deposit Contract](https://etherscan.io/address/0x42000421dd80D1e90E56E87e6eE18D7770b9F8cC#code) was required to call the external [LYXe Token Contract](https://etherscan.io/token/0xA8b919680258d369114910511cc87595aec0be6D) to confirm deposits were valid before creating files necessary to start an independent blockchain.

In comparison to live EVM networks, where users can stake smaller amounts of coins until the validator deposit key has reached a total of 32 coins, transactions to the [Genesis Deposit Contract](https://etherscan.io/address/0x42000421dd80D1e90E56E87e6eE18D7770b9F8cC#code) required a fixed amount of 32 LYXe to prepare ready-to-use genesis files without pending validators. In addition, the contract also verified that the public key wasn't registered already to prevent duplicate deposits.

![Genesis Contract](/img/theory/node-operation/genesis-contract.png)

The manual freeze option allowed for an accurate recording of valid deposits to a certain point in time. Moreover, an additional one-week freeze covering 46,523 blocks was used to ensure that more validators joined once the minimum number of [4,096 validators](https://medium.com/lukso/genesis-validators-deposit-smart-contract-freeze-and-testnet-launch-c5f7b568b1fc) was reached. The deposit function within the [Genesis Deposit Contract](https://etherscan.io/address/0x42000421dd80D1e90E56E87e6eE18D7770b9F8cC#code) not only served to accept LYXe for every validator key, but also to record votes related to the network's initial supply of LYX. Every supply vote is retrievable on the Ethereum blockchain, making it publicly verifiable at any time.

## Validator Differentiation

Genesis validators were given an exclusive and honored position during the chain launch, while regular validators were part of the network upon LYXe migration.

| Type                         | Genesis Validators                                                                                                                                               | Regular Validators                                                                                           |
| ---------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------ |
| <nobr> **Purpose** </nobr>   | Starting the Blockchain                                                                                                                                          | Securing the Blockchain                                                                                      |
| <nobr> **Audience** </nobr>  | Core Community Members                                                                                                                                           | Retail Investors and Builders                                                                                |
| <nobr> **Contract** </nobr>  | Genesis Deposit Contract                                                                                                                                         | Deposit Contract                                                                                             |
| <nobr> **Currency** </nobr>  | LYXe on Ethereum Mainnet                                                                                                                                         | LYX on LUKSO Mainnet                                                                                         |
| <nobr> **Timeframe** </nobr> | 19th of April 2023 - 10th of May 2023                                                                                                                            | 4th of July 2023 and onwards                                                                                 |
| <nobr> **Benefits** </nobr>  | - Became part of the genesis state <br /> - Received LYX before it was tradable <br /> - Had initial APRs of up to 32% <br /> - Had no validator activation time | - Can utilize instant withdrawals <br /> - Have low deposit fees <br /> - Receive instantly tradable revenue |
| <nobr> **Drawbacks** </nobr> | - Needed high amounts of ETH for deposits <br /> <nobr> - Could not withdraw within the first 3 months </nobr>                                                   | - Receive Average staking APRs around 5-12% <br /> - Must wait for validator activation                      |

## Network Launch

The Proof-of-Stake creation was carefully coordinated with all genesis validators who deposited LYX into the deposit contract before block [17,227,300](https://etherscan.io/block/17,227,300) of the Ethereum blockchain. After the contract was frozen, LUKSO's team confirmed all deposits and created the corresponding genesis files for every one of the [supply options](https://medium.com/lukso/its-happening-the-genesis-validators-are-coming-ce5e07935df6) that were initially put forth. More than 70% of the votes significantly registered overwhelming support for a 42,000,000 LYX supply.

About two weeks thereafter, the genesis and config files were released for public verification, including the genesis token supply, the genesis validators' keys, and the launch date. Before the launch on the 23rd of May 2023, operators could [start preparing their nodes](https://medium.com/lukso/genesis-validators-start-your-clients-fe01db8f3fba), making sure the software was running, the imported validators were showing, and the nodes were able to connect.

On the 23rd of May, 2023, the LUKSO Mainnet went live. Following this launch, the LUKSO team announced a [Discovery Month](https://medium.com/lukso/genesis-validators-deposit-smart-contract-freeze-and-testnet-launch-c5f7b568b1fc) to allow for network stabilization before continuing the [LYXe Migration](https://medium.com/lukso/the-lyxe-migration-process-374053e5ddf5) and introducing [Universal Profiles](https://medium.com/lukso/the-lyxe-migration-process-374053e5ddf5). The network showed some fragility in the first few weeks, with participation rates varying between 78% and 85%. After larger stakeholders fixed node setup issues, the network ran stably. A little more than two months later, the [LYXe Migration](https://migrate.lukso.network/) was successfully concluded, and [LYX became tradable](https://https://www.kucoin.com/announcement/en-kucoin-has-completed-the-token-swap-of-lyxe-to-lyx-20230721). In addition, regular validators could then register through the [LUKSO Launchpad](https://deposit.mainnet.lukso.network/en/) using the blockchain's native coin, resulting in the addition of many new nodes and a handful of staking providers.

---

// File: archive/genesis-validators/gashawk-deposits

# GasHawk Deposits

In 2023, LUKSO introduced their [Staking Launchpad](https://deposit.mainnet.lukso.network/) for [Genesis Validators](https://medium.com/lukso/its-happening-the-genesis-validators-are-coming-ce5e07935df6) who had already invested in LYXe. Users could each burn their LYXe through the launchpad to be included in the genesis block of the new network, which held LYX. With each validator key that was funded, users voted for the initial [blockchain supply](https://medium.com/lukso/genesis-validators-deposit-smart-contract-freeze-and-testnet-launch-c5f7b568b1fc).

As the Genesis deposits on Ethereum were relatively expensive, costing around 25 to 70 dollars per validator, many people used the [GasHawk](https://gashawk.io/) platform. It is an off-chain buffer system in which you forward your transaction to an off-chain server instead of using the direct Mainnet RPC channel. The service will buffer the transactions to find the sweet spot and conserve gas at a specific moment. GasHawk time metrics are based on the [ERC1559](https://eips.ethereum.org/EIPS/eip-1559) standard that got applied within the [London] update of Ethereum.

![GasHawk Dashboard](/img/guides/validator-setup/gas-hawk.png)

## Transaction Buffering

Transaction buffer systems are tools that optimize the process of sending transactions to a blockchain network, where the transaction fee can fluctuate significantly based on the congestion of the network. These systems act as middlemen between the user and the blockchain. When a user submits a transaction to a network of off-chain servers, the transaction is not passed directly to the blockchain. Instead, the system holds the transaction and waits for a suitable time to send it, usually when the gas prices are more favorable. These delays make it highly probable that the system will offer lower costs for the user's transaction.

## Security Concerns

Signing a transaction involving a person‚Äôs private key creates cryptographically verifiable proof of the person behind the transaction. This proof includes information related to the transaction, such as the destination address and how much cryptocurrency is being sent. Once the transaction is signed, its contents cannot be changed without the integrity of the signature being breached. The signature is created by hashing the transaction information and the person‚Äôs private key. In the event of any change in the transaction details, the signature would no longer match the transaction.

The off-chain service cannot change its contents once a signed transaction is sent. The only action it can take is to ascertain the best time for the transaction to be sent to the blockchain network in a way that incurs lower fees. In certain situations, the service might abort forwarding the transaction and exclude it from the blockchain transaction pool if it could not find a cheap spot or the user's wallet already sent a regular transaction with a higher nonce, so the previous transaction becomes invalid.

## Relaying Deposits

**1. Connect to GasHawk**: _Sign-in to [GasHawk](https://gashawk.io/#/tx) dashboard using the [MetaMask](https://metamask.io/) wallet and open the main view._

**2. Add the Buffer Endpoint**: _Connect to GasHawk's Ethereum endpoint by adding it's RPC to your wallet._

**3. Adjust the Time Delays**: _Configure your wanted delay time within the settings on the left side._

**4. Enable Nonce Modification**: _Within MetaMask, enable nonce modification to adjust off-chain nonces manually._

**5. Start the Launchpad**: _Change your RPC back to Ethereum Mainnet and go through the [LUKSO Launchpad](https://deposit.mainnet.lukso.network/en/) process._

**6. Change Network**: _On the final deposit page, change the network back to the previously added GasHawk's RPC._

**7. Executing Deposits**: _Separately send each validator key deposit transaction while raising the nonce._

:::tip Off-Chain Queue

Never deposit all keys at once and always remember the nonce within the transaction screen. When timing transactions for later, the account's nonce always has to be increased by one without any gaps to ensure valid execution order. As the RPC is a private endpoint, the nonce within the wallet does not always raise automatically, meaning you might have to adjust it within the transaction window of MetaMask.

:::

:::info Transaction Status

After sending the transaction to the GasHawk endpoint, the launchpad will show the transaction as failed. This status is entirely normal as the launchpad only listens to the Ethereum and no additional services. Your transaction will still be published to the blockchain, just at a later time. Do not re-set the same transaction multiple times.

:::

**8. Reviewing Transactions**: _Head over to the [GasHawk](https://gashawk.io/#/tx) dashboard and wait for the transactions to be executed._

:::info Resending Transactions

In case a transaction failed due to a nonce error, you can _resend_ it directly from GasHawk dashboard.

:::

**9. Verify Deposits**: _Return to the front page of the [LUKSO Launchpad](https://deposit.mainnet.lukso.network/en/) and input your deposit file._

:::tip

If the transactions succeeded, all entries of the deposit file will show with green checkmarks.

:::

![Launchpad Checkmarks](/img/guides/validator-setup/launchpad_12.png)

---

// File: guides/validator-setup/precautions

# 1.1 Precautions

The validator setup is the first step for anyone aspiring to participate in a blockchain consensus. In this section, we cover the initial processes for securely generating validator keys and the launchpad walkthrough. Regardless of which [blockchain clients ](/docs/theory/blockchain-knowledge/client-providers.md) you choose or whether you are running the software on a dedicated server or at home, it‚Äôs crucial to prepare thoroughly.

:::tip

If you're not quite sure about [**Hardware Preparations**](/docs/theory/preparations/node-specifications.md), [**Blockchain Fundamentals**](/docs/theory/blockchain-knowledge/proof-of-stake.md), or the basics of [**Node Operations**](/docs/theory/node-operation/client-setups.md), please refer to the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section to build a solid foundation of knowledge before continuing with the validator or node setup.

:::

:::info

In case you dont want to participate in the staking process and just intend to setup a regular network peer to access, stabalize, and synchronize the blockchain data, you can skip this step and move to the [**Hardware Setup**](/docs/guides/hardware-setup/introduction.md) or [**Client Setup**](/docs/guides/client-setup/firewall-settings.md) sections.

:::

Validator nodes play a crucial role in the blockchain network, participating in the consensus mechanism to validate transactions and create new blocks. As such, the security of these validator nodes and their associated keys is of utmost importance. Generating your validator keys on a clean, offline device that has never touched the internet during setup is an ideal practice.

| **Benefit**                                    | **Description**                                                                                                                                                                                                                                                                                                                                                                                                               |
| ---------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> **Mitigation of Cyber Threats** </nobr> | By generating validator keys on a clean, offline device, you reduce exposure to potential online threats, including malware, hacking, and other forms of cyberattacks. With no internet connection, the chances of a hacker accessing your keys are essentially zero.                                                                                                                                                         |
| <nobr> **Control Over Key Generation** </nobr> | Generating keys offline ensures that you have complete control over the entire process. The private keys are not exposed to third-party services, minimizing the risk of unauthorized access or leakage. A clean operating system installation is an excellent method to establish this security, as it prevents other programs or services from copying clipboards or storing data until the network connection is restored. |
| <nobr> **Elimination of Spyware Risk** </nobr> | A clean device implies a system free of potential spyware, adware, or other malicious software that could compromise your keys. Eliminating this risk is crucial, as such threats might record your keystrokes or screen data and expose your private keys.                                                                                                                                                                   |
| <nobr> **Remote Attack Protection** </nobr>    | An offline device is inherently immune to remote attacks. Hackers cannot penetrate a system that is not connected to a network.                                                                                                                                                                                                                                                                                               |
| <nobr> **Enhanced Privacy** </nobr>            | Offline key generation ensures that no traces of your keys are left online, thereby providing maximum privacy.                                                                                                                                                                                                                                                                                                                |

:::warning

For the above reasons, please ensure you have a machine that can be flashed or used as a key-generation device. In case you only have your node device, please perform the **key generation** on your node **before** flashing the system and setting up the node's operating system.

:::

---

// File: guides/validator-setup/os-installation

# 1.2 OS Installation

This section covers the installation of the operating system for your offline machine used to generate the validator keys.

:::info

The guide uses the latest Ubuntu LTS release to ensure compatibility with the key generation tools and provides a stable, secure environment for generating your validator keys. It‚Äôs the quickest and easiest setup for an offline machine using a USB drive. However, you could also use MacOS or Windows.

:::

## 1. Download and Preparation

Follow these steps to prepare your bootable USB device from a machine that connected to the internet:

**1. Download Ubuntu**: Get the latest official Ubuntu version from [Ubuntu 22.04.2 LTS](https://ubuntu.com/download/desktop).

**2. Create a Bootable USB Drive**: Use the ISO file to create a bootable device:

- Windows: [Rufus Guide for Ubuntu](https://ubuntu.com/tutorials/create-a-usb-stick-on-windows#1-overview)
- Linux: [Disk Creator Guide for Ubuntu](https://ubuntu.com/tutorials/create-a-usb-stick-on-ubuntu#1-overview)
- macOS [Etcher Guide for Ubuntu](https://ubuntu.com/tutorials/create-a-usb-stick-on-macos#1-overview)

**3. Finalize USB Preparation**:

- Disconnect the USB drive from your current computer.
- Reconnect the USB drive to your offline machine when ready.

## 2. System Installation

In this phase, Ubuntu will be installed on your offline machine. Keeping the system offline is crucial for ensuring the security and integrity of the key generation process as outlined in detail within the previous [Precautions](./precautions.md) page.

:::warning

Make sure to never connect to the internet during the installation process. Do not connect an Ethernet cable.

:::

:::info

Steps have been done on an Intel NUC. Key combinations or commands may be different across devices.

:::

**2.1 Enter the BIOS**: _Power your machine, attach keyboard and monitor, and follow these steps to enter the BIOs menu._

1. Connect your bootable USB device to the machine.
2. Turn on the machine using the power button.
3. Press `F2` on your keyboard during boot to enter the BIOS setup.

**2.2 Change Boot Order**: _Adjust the boot priority to ensure the machine boots from the USB drive._

1. Navigate to `Boot` -> `Boot Priority` in the BIOS.
2. Set `Boot Option #1` to your USB device.
3. Set `Boot Option #2` to your internal SSD.

**2.3 Operating System Startup**: _After configuring the BIOS settings, start the OS from the bootable USB device._

1. Press `F10` to save changes and exit the BIOS.
2. Wait for the system to boot from the USB drive.
3. Select **Try or Install Ubuntu Server** from the boot menu.

![Try or Install Ubuntu Server](/img/guides/validator-setup/validator_install_1.png)

## 3. Ubuntu Installation

Once the machine boots from the USB drive, the Ubuntu installation environment will launch. Follow these steps to ensure a minimal and secure installation without unneccesary software bloating the system or previous data still being on the device.

:::tip

Further details about [**Operating Systems**](/docs/theory/node-operation/operation-systems.md) and [**Disk Management**](/docs/theory/node-operation/disk-management.md)
can be found in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.
:::

![Initial Setup Screen](/img/guides/validator-setup/validator_install_2.png)

1. System Language: Choose your preferred language for the operating system.
2. Keyboard Configuration: Select the appropriate keyboard layout.
3. Updates and Software: Choose Minimal Installation to speed up installation and reduce unnecessary load.
4. Installation Type: Select Erase disk and install Ubuntu to ensure a clean installation.
5. Time Zones: Choose any time zone; this sets the default system clock.
6. Login Data: Enter your name, username, and password for the system.
7. Finish the setup and remove the bootable USB stick when prompted.

:::warning

- Do not **download updates while installing Ubuntu** since the device is offline.
- Do not **install third-party software for graphics and Wi-Fi hardware** to reduce unnecessary load.

:::

---

// File: guides/validator-setup/wagyu-key-generation

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 1.3 Wagyu Key Generation

This section explains how to generate your validator keys using the [LUKSO Wagyu Key Gen](https://github.com/lukso-network/tools-wagyu-key-gen) tool. By leveraging a graphical interface, the process becomes more intuitive and accessible for both beginners and experienced users. The following steps walk you through downloading the software, preparing a USB device, and running the key generation process on your designated keygen computer.

## 1. Software Comparison

The table below compares the two available tools for generating validator keys:

| Tool                                                                                           | Interface                   | Description                                                                                                           |
| ---------------------------------------------------------------------------------------------- | --------------------------- | --------------------------------------------------------------------------------------------------------------------- |
| <nobr> [**LUKSO Wagyu Key Gen**](https://github.com/lukso-network/tools-wagyu-key-gen) </nobr> | <nobr> Graphical </nobr>    | Simplifies the staking process with an intuitive, step-by-step interface, ideal for users who prefer visual guidance. |
| <nobr> [**LUKSO Key Gen CLI**](https://github.com/lukso-network/tools-key-gen-cli) </nobr>     | <nobr> Command-Line </nobr> | Provides a terminal-based approach for generating keys, suitable for servers, automation and advanced users           |

:::tip

If you prefer a command-line approach, switch to the [**CLI Key Generation**](./cli-key-generation.md) page.

:::

## 2. Download the Software

This step prepares the key generation tool. You need to chose the correct download file for the operating system on your offline machine where you are going to generate the keys on, not the operating system of your personal computer.

- Linux, Ubuntu: _AppImage-File_
- Apple, MacOS: _DMG-File_
- Microsoft, Windows: _EXE-File_

:::info

The following steps are performed on your üíª **personal computer**.

:::

<Tabs>
<TabItem value="linux" label="Ubuntu" default>

1. Visit the [Official Release Page](https://github.com/lukso-network/tools-wagyu-key-gen/) on the [LUKSO Network](https://github.com/lukso-network/) GitHub page.
2. Download the _AppImage_ file from the [Latest Release](https://github.com/lukso-network/tools-wagyu-key-gen/releases).
3. Connect a USB device.
4. Flash it using your preferred disk utility tool.
5. Copy the downloaded _AppImage_ onto the USB device.
6. Eject the USB disk safely.

</TabItem>
<TabItem value="apple" label="MacOS">

1. Visit the [Official Release Page](https://github.com/lukso-network/tools-wagyu-key-gen/) on the [LUKSO Network](https://github.com/lukso-network/) GitHub page.
2. Download the _DMG_ file from the [Latest Release](https://github.com/lukso-network/tools-wagyu-key-gen/releases).
3. Connect a USB device.
4. Flash it using your preferred disk utility tool.
5. Copy the downloaded _DMG_ onto the USB device.
6. Eject the USB disk safely.

</TabItem>
<TabItem value="microsoft" label="Windows">

1. Visit the [Official Release Page](https://github.com/lukso-network/tools-wagyu-key-gen/) on the [LUKSO Network](https://github.com/lukso-network/) GitHub page.
2. Download the _EXE_ file from the [Latest Release](https://github.com/lukso-network/tools-wagyu-key-gen/releases).
3. Connect a USB device.
4. Flash it using your preferred disk utility tool.
5. Copy the downloaded _EXE_ onto the USB device.
6. Eject the USB disk safely.

</TabItem>
</Tabs>

## 3. Connect to Keygen Computer

:::info

The following steps are performed on your üóÑÔ∏è **offline computer**.

:::

1. Connect the prepared USB device to the computer designated for key generation.
2. Copy the AppImage file from the USB device to your home directory.

## 4. Generate Initial Keys

Follow these steps to generate your initial validator keys using the Wagyu application:

**1. Launch the Application**: Open your file explorer, navigate to your home directory, and _execute_ the application.

![Wagyu Starting Screen](/img/guides/validator-setup/gui_keygen_1.png)

**2. Select the Network**: In the upper right corner, click the _LUKSO_ button to choose between testnet and mainnet.

![Wagyu Network Select](/img/guides/validator-setup/gui_keygen_2.png)

**3. Initiate Mnemonic Creation**: Click on _CREATE NEW SECRET RECOVERY PHRASE_ to begin generating your mnemonic.

![Wagyu Security Notice](/img/guides/validator-setup/gui_keygen_3.png)

**4. Generate the Mnemonic**: After reviewing the displayed information, click _CREATE_ to generate a new mnemonic.

![Wagyu Secret Creation](/img/guides/validator-setup/gui_keygen_4.png)

:::info

A **seed phrase** and a **mnemonic phrase** refer to the same thing: a human-readable set of words that encodes a cryptographic seed used to generate private keys. These terms are often used interchangeably depending on a more technical or more general context.

:::

:::warning

Write down your mnemonic on paper and store it securely. Do not save it digitally as plain text. **Anyone with access** to this seed phrase **can control your deposits** or slash your validator, as it can be used to regenerate your validator's private keys and sign messages on your behalf. **Treat it like your most valuable secret.** Never share it or store it insecurely.

:::

**5. Confirm the Mnemonic**: Click _NEXT_ and retype your saved mnemonic seed phrase to verify it.

![Wagyu Secret Confirmation](/img/guides/validator-setup/gui_keygen_5.png)

**6. Verification Process**: Proceed by clicking _CHECK_ until the process confirms your mnemonic successfully.

![Wagyu Key Screen](/img/guides/validator-setup/gui_keygen_6.png)

**7. Enter Key Generation Details**: Provide the amount of keys to generate, a password for encryption, and a withdrawal address.

:::tip

You can generate more keys than you immediately fund. These keys will remain inactive until they are sufficiently funded. When generating keys in multiple rounds, you can use the same withdrawal address multiple times so all revenue goes to the same account. Further details can be found on the [**Tokenomics**](/docs/theory/blockchain-knowledge/tokenomics.md) and [**Validator Credentials**](/docs/theory/node-operation/validator-credentials.md) pages within the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

:::info Split Deposits to multiple Wallets

If you only require deposits from a single wallet, simply complete the process once. However, if you have multiple wallets with varying amounts of LYXt, LYXe, or LYX to make the deposits with, you have two primary options:

**1. Generate Batches with the Same Seed**

- Generate keys for the first wallet using a new seed phrase.
- For subsequent wallets, import the existing mnemonic seed phrase and generate additional keys.
- This process produces separate `deposit_data.json` files for each wallet.

üôáüèª‚Äç‚ôÇÔ∏è _Example: 30 validators across 3 wallets, generated 10 keys per run in different files._

**2. Modify the Deposit File**

- Generate all keys in a single run, creating one comprehensive `deposit_data.json` file.
- Duplicate and modify the file and use a JSON Editor to remove `pubkey` entries, dividing keys appropriately.

üôáüèª‚Äç‚ôÇÔ∏è _Example: 30 validators across 3 wallets, generated 3 file copies and removed pubkey entries manually:_

- _Keept the first 10 `pubkey` entries for wallet one. (validators 1-10)_
- _Removed the first and last 10 `pubkey` entries for wallet two. (validators 11‚Äì20)_
- _Removed the first 20 for wallet three. (keeping validators 21‚Äì30)_

In both cases, you will have to go through the [**Launchpad Process**](./launchpad-walkthrough.md) 3 times, as the launchpad will check if your current wallet has enough balance before you can continue to the deposit screen.

:::

**8. Generate the deposit files**: Select the file destination and wait for file generation.

- Click _BROWSE_ to select the folder where the deposit and keystore files will be stored.
- Click _CREATE_ to generate your keys and wait for the key generation process to finish.

![Wagyu Creation Screen](/img/guides/validator-setup/gui_keygen_9.png)

**9. Review the Generated Files**: Once completed, the final screen will appear and show the created files.

![Wagyu Final Screen](/img/guides/validator-setup/gui_keygen_10.png)

:::warning Verifying Generated Files

Please ensure that your destination folder contains the following files:

- `deposit_data.json`: This file is used to make deposit transactions during the [Deposit Launchpad](./launchpad-walkthrough.md) process.
- `keystore.json`: Each validator key has a corresponding keystore file, later used in the [Validator Setup](/docs/guides/client-setup/validator-configuration.md).

:::

## 5. Generate Additional Keys

If you need to add more stake, follow these steps to generate additional validator keys using the Wagyu application:

**1. Initiate the Import Process**: Click _USE EXISTING SECRET RECOVERY PHRASE_ and select the appropriate network.

![Wagyu Starting Screen](/img/guides/validator-setup/gui_keygen_1.png)

**2. Import Your Mnemonic**: Enter your validator seed phrase and press _IMPORT_ to begin the key import process.

![Wagyu Seed Import](/img/guides/validator-setup/gui_keygen_11.png)

**3. Set Up Additional Key Details**: Specify the number of new and previously generated keys with your withdrawal address.

:::tip

You can generate more keys than you immediately fund. These keys will remain inactive until they are sufficiently funded. When generating keys in multiple rounds, you can use the same withdrawal address multiple times so all revenue goes to the same account. Further details can be found on the [**Tokenomics**](/docs/theory/blockchain-knowledge/tokenomics.md) and [**Validator Credentials**](/docs/theory/node-operation/validator-credentials.md) pages within the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

:::info

To regenerate keys for **a backup** or **updating** the **withdrawal address** or **password**, you can set the **starting index** to **0** and specify the total number of all your previously generated keys. The new files can then be re-used to setup a new node once the original one stopped operating.

:::

**4. Finalize the Additional Key Generation**: Enter your previous password and select the destination folder.

![Wagyu Key Screen](/img/guides/validator-setup/gui_keygen_12.png)

:::warning Verifying Generated Files

Always ensure that your destination folder contains the following files:

- `deposit_data.json`: This file is used to make deposit transactions during the [Deposit Launchpad](./launchpad-walkthrough.md) process.
- `keystore.json`: Each validator key has a corresponding keystore file, later used in the [Validator Setup](/docs/guides/client-setup/validator-configuration.md).

:::

---

// File: guides/validator-setup/cli-key-generation

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 1.4 CLI Key Generation

This section explains how to generate your validator keys using the [LUKSO Key Gen CLI](https://github.com/lukso-network/tools-key-gen-cli) tool. Using a command-line interface provides flexibility, greater control, and is well-suited for servers, automation, and advanced users. Follow the steps below to download, set up, and run the CLI tool, ensuring that your keys are generated securely on your offline machine.

## 1. Software Comparison

The table below compares the two available tools for generating validator keys:

| Tool                                                                                           | Interface                   | Description                                                                                                           |
| ---------------------------------------------------------------------------------------------- | --------------------------- | --------------------------------------------------------------------------------------------------------------------- |
| <nobr> [**LUKSO Wagyu Key Gen**](https://github.com/lukso-network/tools-wagyu-key-gen) </nobr> | <nobr> Graphical </nobr>    | Simplifies the staking process with an intuitive, step-by-step interface, ideal for users who prefer visual guidance. |
| <nobr> [**LUKSO Key Gen CLI**](https://github.com/lukso-network/tools-key-gen-cli) </nobr>     | <nobr> Command-Line </nobr> | Provides a terminal-based approach for generating keys, suitable for servers, automation and advanced users           |

:::tip

If you prefer a graphical interface, switch to the [**Wagyu Key Generation**](./wagyu-key-generation.md) page.

:::

## 2. Download the Software

This step prepares the key generation tool. You need to chose the correct archive file for the operating system on your offline machine where you are going to generate the keys on, not the operating system of your personal computer.

- Linux, Ubuntu: _linux.tar.gz_
- Apple, MacOS: _macos.tar.gz_
- Microsoft, Windows: _windows.tar.gz_

:::info

The following steps are performed on your üíª **personal computer**.

:::

<Tabs>
<TabItem value="linux" label="Ubuntu" default>

1. Visit the [official release page](https://github.com/lukso-network/tools-key-gen-cli/releases).
2. Download the _linux.tar.gz_ file from the [latest release](https://github.com/lukso-network/tools-key-gen-cli/releases).
3. Connect a USB device.
4. Flash the USB device using your preferred disk utility tool.
5. Copy the _tar.gz_ archive file onto the USB disk.
6. Eject the USB device safely.

</TabItem>
<TabItem value="apple" label="MacOS">

1. Visit the [official release page](https://github.com/lukso-network/tools-key-gen-cli/releases).
2. Download the _macos.tar.gz_ file from the [latest release](https://github.com/lukso-network/tools-key-gen-cli/releases).
3. Connect a USB device.
4. Flash the USB device using your preferred disk utility tool.
5. Copy the _tar.gz_ archive file onto the USB disk.
6. Eject the USB device safely.

</TabItem>
<TabItem value="microsoft" label="Windows">

1. Visit the [official release page](https://github.com/lukso-network/tools-key-gen-cli/releases).
2. Download the _windows.tar.gz_ file from the [latest release](https://github.com/lukso-network/tools-key-gen-cli/releases).
3. Connect a USB device.
4. Flash the USB device using your preferred disk utility tool.
5. Copy the _tar.gz_ archive file onto the USB disk.
6. Eject the USB device safely.

</TabItem>
</Tabs>

## 3. Connect to Keygen Computer

:::info

The following steps are performed on your üóÑÔ∏è **offline computer**.

:::

1. Connect the prepared USB device to your computer.
2. Copy the archive file to your home directory.
3. Open the terminal and navigate to your home directory:

```sh
cd
```

## 4. Setup the Executable

:::info

The following steps are performed using Ubuntu. Commands may differ depending on the operating system.

:::

After downloading, we need to unpack the file. After downloading it, we can extract the tape archive using Ubuntu's archiving tool. We're going to extract (_x_) and compress (_z_) the tape archive into its previous packaged files (_f_) using verbose mode (_v_) to list all files being processed during the extraction and compression. Please note that the filenames might change due to the versioning.

**1. Unpack the downloaded file**

```sh
tar xzfv lukso-key-gen-cli-v2.5.8-linux.tar.gz
```

**2. Move into the created folder**

```sh
cd lukso-key-gen-cli-v2.5.8-linux
```

## 5. Generate Initial Keys

Follow these steps to generate your initial validator keys using the CLI tool:

**1. Start the Key Generation Process**: Start the tool using the _new-mnemonic_ option and paste your withdrawal address.

```sh
./lukso-key-gen new-mnemonic --eth1_withdrawal_address <your-withdrawal-address>
```

:::tip

When generating keys in multiple rounds, you can use the same withdrawal address multiple times so all revenue goes to the same account. Further details can be found on the [**Tokenomics**](/docs/theory/blockchain-knowledge/tokenomics.md) and [**Validator Credentials**](/docs/theory/node-operation/validator-credentials.md) pages within the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

:::info

A **seed phrase** and a **mnemonic phrase** refer to the same thing: a human-readable set of words that encodes a cryptographic seed used to generate private keys. These terms are often used interchangeably depending on a more technical or more general context.

:::

:::note

The initial startup will take some time, do not close the terminal window.

:::

**2. Select the Language**: Choose your language by typing the corresponding number into the input prompt.

```text
> 3.
```

:::info

If you press _Enter_ it will select English as default.

:::

**3. Specify the Validator Number**: Select how many validator keys you want to generate to deposit stake.

```text
> 10
```

:::note

You can generate more keys than you immediately fund. These keys will remain inactive until they are sufficiently funded.

:::

:::info Split Deposits to multiple Wallets

If you only require deposits from a single wallet, simply complete the process once. However, if you have multiple wallets with varying amounts of LYXt, LYXe, or LYX to make the deposits with, you have two primary options:

**1. Generate Batches with the Same Seed**

- Generate keys for the first wallet using a new seed phrase.
- For subsequent wallets, import the existing mnemonic seed phrase and generate additional keys.
- This process produces separate `deposit_data.json` files for each wallet.

üôáüèª‚Äç‚ôÇÔ∏è _Example: 30 validators across 3 wallets, generated 10 keys per run in different files._

**2. Modify the Deposit File**

- Generate all keys in a single run, creating one comprehensive `deposit_data.json` file.
- Duplicate and modify the file and use a JSON Editor to remove `pubkey` entries, dividing keys appropriately.

üôáüèª‚Äç‚ôÇÔ∏è _Example: 30 validators across 3 wallets, generated 3 file copies and removed pubkey entries manually:_

- _Kept the first 10 `pubkey` entries for wallet one. (validators 1-10)_
- _Removed the first and last 10 `pubkey` entries for wallet two. (validators 11‚Äì20)_
- _Removed the first 20 `pubkey` elements for wallet three. (keeping validators 21‚Äì30)_

In both cases, you will have to go through the [**Launchpad Process**](./launchpad-walkthrough.md) 3 times, as the launchpad will check if your wallets have enough balance before you can continue to the deposit screen.

:::

**4. Select Network**: Choose between generating the _lukso-testnet_ or _lukso_ mainnet keys and press any key to continue.

```text
> lukso
```

**5. Password Input**: Input the password that will be used to encrypt your validator keys and confirm it.

**6. Mnemonic Seed Generation**: Your mnemonic seed phrase will be generated and printed in the terminal.

:::warning

Write down your mnemonic on paper and store it securely. Do not save it digitally as plain text. **Anyone with access** to this seed phrase **can control your deposits** or slash your validator, as it can be used to regenerate your validator's private keys and sign messages on your behalf. **Treat it like your most valuable secret.** Never share it or store it insecurely.

:::

**7. Confirm the Mnemonic**: You will be asked to re-enter your mnemonic seed phrase for verification purposes.

:::info

You have to input the words of your mnemonic seed phrase with spaces in between.

:::

When you press _Enter_, the CLI will check the seed. If correct, you will see the following output on the terminal window:

```text
                  #####     #####
                ##     #####     ##
    ###         ##   #######     #########################
    ##  ##      #####               ##                   ##
    ##     #####                 ##                       ##
    ##     ##                     ##                      ###
   ########                        ##                     ####
   ##        ##   ###         #####                       #####
   #                          ##                         # #####
   #                            #                        #  #####
   ##                             ##                    ##
   ##                              ##                   ##
   ##             ###              ##                   ##
   ###############                 ##                   ##
   ###               ##                                 ##
      #############################                    ##
                     ##                             ###
                     #######     #################     ###
                     ##   ## ##        ##   ##    ###
                     ##############          #############

Creating your keys.
Creating your keys:     [####################################]  10/10
...
Creating your keystores:    [####################################]  10/10
...
Creating your depositdata:    [####################################]  10/10
...
Verifying your keystores:   [####################################]  10/10
...
Verifying your deposits:    [####################################]  10/10

Success!
```

**8. Reviewing Output Files**: The deposit files will be saved in the current destination, you can press any key to exit.

:::warning Verifying Generated Files

Please ensure that your destination folder contains a folder with the following files:

- `deposit_data.json`: This file is used to make deposit transactions during the [Deposit Launchpad](./launchpad-walkthrough.md) process.
- `keystore.json`: Each validator key has a corresponding keystore file, later used in the [Validator Setup](/docs/guides/client-setup/validator-configuration.md) process.

:::

## 6. Generate Additional Keys

If you need to add more stake, follow these steps to generate additional validator keys using the CLI tool:

**1. Navigate to the CLI Folder**: Ensure you are in the same folder as the LUKSO Key Gen CLI.

```sh
cd && cd lukso-key-gen-cli-v2.5.8-linux
```

**2. Rename Existing Folder**: To differentiate batches, rename the folder containing the first batch of keys.

```sh
mv validator_keys <new-folder-name>
```

**3. Run the Existing Mnemonic Process**: Start the tool using the _existing-mnemonic_ option and paste your withdrawal address.

:::tip

When generating keys in multiple rounds, you can use the same withdrawal address multiple times so all revenue goes to the same account. Further details can be found on the [**Tokenomics**](/docs/theory/blockchain-knowledge/tokenomics.md) and [**Validator Credentials**](/docs/theory/node-operation/validator-credentials.md) pages within the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

```sh
./lukso-key-gen existing-mnemonic --eth1_withdrawal_address <your-withdrawal-address>
```

**4. Select the Language**: Choose your language by typing the corresponding number into the input prompt.

```text
> 3.
```

:::info

If you press _Enter_ it will select English as default.

:::

**5. Enter the Existing Mnemonic**: Input your previously generated mnemonic seed phrase when prompted.

**6. Specify the Validator Number**: Specify the amount of previous and new keys before verifying them again.

:::note

You can generate more keys than you immediately fund. These keys will remain inactive until they are sufficiently funded.

:::

:::tip

The starting index is the total amount of previously generated keys.

üôáüèª‚Äç‚ôÇÔ∏è _Example: If the starting index is 10, the tool will start generating the 11th deposit key._

:::

:::info

To regenerate keys for **a backup** or **updating** the **withdrawal address** or **password**, you can set the **starting index** to **0** and specify the total number of all your previously generated keys. The new files can then be re-used to setup a new node once the original one stopped operating.

:::

```text
> 10
```

**7. Select Network**: Choose between your network type and select _lukso-testnet_ or _lukso_ mainnet keys.

```text
> lukso
```

**8. Enter your Password**: Input the password that will be used to encrypt your validator keys and confirm it.

When you press _Enter_, the CLI will generate the validator keys, showing the following output on the terminal window:

```text
                  #####     #####
                ##     #####     ##
    ###         ##   #######     #########################
    ##  ##      #####               ##                   ##
    ##     #####                 ##                       ##
    ##     ##                     ##                      ###
   ########                        ##                     ####
   ##        ##   ###         #####                       #####
   #                          ##                         # #####
   #                            #                        #  #####
   ##                             ##                    ##
   ##                              ##                   ##
   ##             ###              ##                   ##
   ###############                 ##                   ##
   ###               ##                                 ##
      #############################                    ##
                     ##                             ###
                     #######     #################     ###
                     ##   ## ##        ##   ##    ###
                     ##############          #############

Creating your keys.
Creating your keys:     [####################################]  10/10
...
Creating your keystores:    [####################################]  10/10
...
Creating your depositdata:    [####################################]  10/10
...
Verifying your keystores:   [####################################]  10/10
...
Verifying your deposits:    [####################################]  10/10

Success!
```

:::warning Verifying Generated Files

Always ensure that your destination folder contains a `validator_keys` folder with the following files:

- `deposit_data.json`: This file is used to make deposit transactions during the [Deposit Launchpad](./launchpad-walkthrough.md) process.
- `keystore.json`: Each validator key has a corresponding keystore file, later used in the [Validator Setup](/docs/guides/client-setup/validator-configuration.md).

:::

---

// File: guides/validator-setup/launchpad-walkthrough

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 1.5 Launchpad Walkthrough

This section guides you through the deposit process using the LUKSO Validator Deposit Launchpads. Depositing funds is a critical step that activates your validator keys and enables your node to participate in staking, which in turn generates income.

:::tip

If you're not quite sure about [**Hardware Preparations**](/docs/theory/preparations/node-specifications.md), [**Blockchain Fundamentals**](/docs/theory/blockchain-knowledge/proof-of-stake.md), or the basics of [**Node Operations**](/docs/theory/node-operation/client-setups.md), please refer to the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section to build a solid foundation of knowledge before continuing with the validator or node setup.

:::

:::warning

Further details about validator operation and deposit instructions can be found on the [**Staking Deposits**](/docs/theory/node-operation/staking-deposits.md) page.

:::

After you have generated your deposit keys, you can visit the _LUKSO Validator Deposit Launchpads_ to stake funds:

- [Mainnet Deposit Launchpad](https://deposit.mainnet.lukso.network/en/)
- [Testnet Deposit Launchpad](https://deposit.testnet.lukso.network/en/)

![Deposit Launchpad](/img/guides/validator-setup/launchpad_1.png)

:::danger Domain Verification

Always double-check the `lukso.network` domain before continuing the deposit process.

:::

Take a moment to review the launchpad‚Äôs functionality and statistics. For each network, you will see details such as the total staked amount of LYX or LYXt, the total number of validators, and the current Annual Percentage Rate during staking, which is particularly useful for monitoring the network dynamics.

## 1. Preparing Deposit Files

Before making any deposits, you must prepare and verify your deposit files on the launchpad. If you only have one wallet with enough LYX or LYXt to fund your validator keys, you can use one single deposit file during the process. However, if you have multiple wallets or currently only have enough funds to activate a smaller amount of validators, you must prepare or split your deposit file.

:::info Split Deposits to multiple Wallets

**1. You Generated Batches with the Same Seed**

- If you created separate batches for each wallet, you likely have multiple deposit folders.
- Each deposit folder should contain one or multiple deposit key files
- Each deposit folder should conatain one _deposit_data.json_ file

üôáüèª‚Äç‚ôÇÔ∏è_Example: With 30 validators across 3 wallets containing 320 LYX or LYXt, you should have 3 deposit files.

**2. You Modify the Deposit File**

- If you generated all keys in one run, you will have a single folder with one comprehensive _deposit_data.json_ file.
- You will have to duplicate the file for each wallet and use a JSON Editor to remove specific `pubkey` entries
- Each file then only contains the deposit keys for one wallet.

üôáüèª‚Äç‚ôÇÔ∏è _Example: 30 validators across 3 wallets, generated 3 file copies and removed pubkey entries manually:_

- _Only kept the first 10 `pubkey` entries for wallet one and removed the rest. (validators 1-10)_
- _Removed the first and last 10 `pubkey` entries for wallet two. (validators 11‚Äì20)_
- _Removed the first 20 `pubkey` elements for wallet three. (keeping validators 21‚Äì30)_

:::

:::tip

If your wallets hold different amounts of LYX or LYXt, adjust the subkeys and validator counts of the deposit file accordingly to match holdings. If you only want to fund some of your validator keys later, you can create a copy of the deposit file and remove the last pubkey elements.

:::

In case you chose to modify the deposit file copies, an editor with JSON formatting support is highly recommended. It will help you verify that the JSON structure remains valid and that commas and brackets are correctly placed.

:::note

Great and free examples of editors with JSON formatting are ü¶é [**Notepad++**](https://notepad-plus-plus.org/) or üîπ [**Visual Studio Code**](https://code.visualstudio.com/).

![Deposit Data Modification](/img/guides/validator-setup/deposit_modify.png)

:::

## 2. Checking Deposits

If you're a Genesis or Testnet Validator, the prepared deposit files can be checked again before starting the staking launchpad process. Icons are then used to indicate whether the file is valid and whether it contains validation keys that have already been used.

:::info

Further details about validator differentiations can be found on the [**Staking Deposits**](/docs/theory/node-operation/staking-deposits.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

<Tabs>
<TabItem value="genesis" label="Genesis Validators" default>

Geneses Validators were able to upload their deposit file to the front page of the Staking Launchpad. You could observe the status icons for each validator key element. Unused deposit keys display grey symbols, indicating that no funds have been deposited yet. If they showed green arrows, you knew that those could be removed from the file, because you cannot find a key twice.

![Deposit Launchpad](/img/guides/validator-setup/launchpad_2.png)

It was advisable to keep a second browser window open displaying the complete deposit file to monitor the deposits in real-time.

![Deposit Launchpad](/img/guides/validator-setup/launchpad_3.png)

Additionally, the genesis validators could view the current votes for the network's initial coin supply.

![Deposit Launchpad](/img/guides/validator-setup/launchpad_4.png)

</TabItem>
<TabItem value="testnet" label="Testnet Validators">

If you're a Testnet Validator, you're allowed to check the deposit status by verifying your address. Each wallet will display the number of validators you are eligible to deposit. Each wallet must previously whitelisted by the LUKSO team.

:::tip Whitelists and Deposits

Whitelisting only affects the ability to make deposits, not becoming a validator. If you are removed from the whitelist before all validators are deposited, you will not be able to proceed. You can find further information on becoming a Testnet Validator on the related [**LUKSO Tech Documentation**](https://docs.lukso.tech/networks/testnet/become-a-validator) or the [**Staking Deposits**](/docs/theory/node-operation/staking-deposits.md) page.

:::

![Whitelist Checkup](/img/guides/validator-setup/whitelist-check.png)

</TabItem>
<TabItem value="mainnet" label="Mainnet Validators">

:::note

The Mainnet Staking Launchpad only supports deposit checks in the final transaction window after submitting the deposit file and connecting your wallet. The wallet must contain enough LYX or LYXt to proceed to the final screen.

:::

</TabItem>
</Tabs>

## 3. Placing Deposits

You can initiate the deposits by the clicking _Become a validator_ button on the Staking Launchpad.

:::warning

Deposits can only be made once and cannot be refunded in the event of an error.

- **Review Information:** Carefully read all the theoretical pages and informational content provided.
- **Verify Wallet Balance:** Check that the wallet‚Äôs LYX or LYXt balance meets the minimum requirements.
- **Confirm Deposit File Details:** Review the summary of your deposit keys, which will be transformed into transaction data.

:::

**1. Read through the Information**: Review the first 10 pages of necessary blockchain knowledge.

![Deposit Launchpad](/img/guides/validator-setup/launchpad_5.png)

**2. Upload the Deposit File**: Proceed by uploading one single deposit file per walkthrough.

![Deposit Launchpad](/img/guides/validator-setup/launchpad_6.png)

**3. Connect the Wallet**: Connect your wallet containing enough LYX or LYXt to fund all keys within the file.

![Deposit Launchpad](/img/guides/validator-setup/launchpad_7.png)

:::tip

While the Staking Launchpad only supports MetaMask as browser wallet, you can still [**link your hardware wallet**](https://support.lukso.network/general/supported-wallets/hardware-wallets) or send LYX to a different Ethereum address. It will show up once you've [**added and switched**](https://docs.lukso.tech/networks/mainnet/parameters#add-lukso-to-wallets) to the LUKSO network.

:::

:::info

If you create deposits on the LUKSO Testnet, clean your MetaMask activity and nonce to avoid potential network conflicts.

![MetaMask Clear Activity](/img/guides/validator-setup/metamask-clear.png)

:::

**4. Review Wallet Balance**: The launchpad will fetch your balance and will allow you to continue with sufficient funds.

![Deposit Launchpad](/img/guides/validator-setup/launchpad_8.png)

:::tip

If you have insufficient funds or want to activate some of the generated validator keys later on, you can create a copy of the deposit file with a subsection of keys to fullfil the deposit requirements.

:::

**5. Confirm Summary Page**: Review the summary of your deposit keys and agree to the terms to proceed with the transactions.

![Deposit Launchpad](/img/guides/validator-setup/launchpad_9.png)

After the confirmation and setup, you will be able to send deposit transactions by either clicking _Confirm deposit_ or _Send X deposits_. If you select the latter option, the transactions will be sent in series, and you will be prompted to confirm each one individually.

:::warning Status Updates

Please remain on the deposit page and monitor the transaction status. The deposit keys will **initially show as ready** and will update to **pending**, **deposited**, or **failed** based on the blockchain‚Äôs response. If a transaction error occurs and the option to resend from the final screen should not be available, restart the process from the home screen.

:::

## 4. Checking Deposits

After the transactions have been sent, you can verify the status of your deposits using the provided transaction buttons.

<Tabs>
<TabItem value="genesis" label="Genesis Validators" default>

For [Genesis Validators](/docs/archive/genesis-validators/blockchain-launch.md), the Ethereum Blockchain Explorer displayed all the deposit transactions to the [Genesis Contract](https://etherscan.io/address/0x42000421dd80D1e90E56E87e6eE18D7770b9F8cC).

![Genesis Execution Chain Deposit](/img/guides/validator-setup/genesis-deposit-screen.png)

[Genesis Validators](/docs/archive/genesis-validators/blockchain-launch.md) were also able to review the deposit files on the Staking Launchpad. If all validator keys show as green, every deposit transaction was successful. In case some validator keys remained in grey, the deposit had to be repeated.

![Deposit Launchpad](/img/guides/validator-setup/launchpad_12.png)

</TabItem>
<TabItem value="testnet" label="Testnet Validators">

For Testnet Validators, the [LUKSO Testnet Consensus Explorer](https://explorer.consensus.testnet.lukso.network/) will display the deposit transactions.

![Testnet Beacon Chain Deposit](/img/guides/validator-setup/testnet-deposit-screen.png)

</TabItem>
<TabItem value="mainnet" label="Mainnet Validators">

For Mainnet Validators, the [LUKSO Mainnet Consensus Explorer](https://explorer.consensus.mainnet.lukso.network/) will display the deposit transactions.

![Testnet Beacon Chain Deposit](/img/guides/validator-setup/testnet-deposit-screen.png)

</TabItem>
</Tabs>

:::tip

Validator activation can take up multiple days depending on the network occupation. You can already start to run your node using one of the [**Client Setups**](/docs/theory/node-operation/client-setups.md) and import the validator keys. The validator clients will then run in idle mode until the blockchain is synced and validators got activated.

:::

---

// File: guides/hardware-setup/introduction

# 2.1 Introduction

While LUKSO is an independent blockchain, it leverages the [Ethereum Virtual Machine](https://ethereum.org/de/developers/docs/evm/) for executing smart contracts. This compatibility means that LUKSO benefits from many of the robust practices established for Ethereum validators. Whether you‚Äôre setting up a modest homestaking server or a professionally managed staking environment, you‚Äôll notice that hardware and networking recommendations overlap with those for Ethereum nodes.

:::tip

Detailed information about minimal hardware specifications, storage recommendations, router requirements, or network demands can be gathered from the [**Node Specification**](/docs/theory/preparations/node-specifications.md) and [**Network Demand**](/docs/theory/preparations/network-demand.md) pages on the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

## Hardware Setup

I opted for an expensive and professional setup because I plan to use the slasher functionality and run multiple networks from one node‚Äîpartly by deploying Docker images on top of the LUKSO CLI. Please understand that this advanced configuration is not mandatory. You can get started with an entry-level computer for around 600‚Ç¨ and further trim down the hardware specifications by running the node without the slasher functionality.

- **Operating System**: Ubuntu 22.04.2 Server - _A stable choice known for long-term support and security updates._
- **Motherboard**: Barebone Intel NUC 10 - _Compact yet powerful, ideal for a home or small office environment._
- **Processor**: Intel Core i7-10710U - _Provides robust multitasking for node operations and concurrent network tasks._
- **Housing**: Akasa Turing FX for Intel NUC 10 - _A fanless solution to reduce noise and ensure efficient thermal management._
- **RAM**: Crucial 32GB DDR4 Kit - _Sufficient memory for high-performance workloads and multiple network instances._
- **Storage**: Samsung 970 EVO Plus M.2 NVMe SSD 2TB - _Offers fast data access and demands of EVM-based blockchains._

![Node Parts](/img/guides/hardware-setup/build_01.png)

I spent around 1100‚Ç¨ on this setup in 2021. Current prices might be even lower. I assembled the node myself to achieve a fanless, quiet operation with minimal moving parts, reducing both maintenance and thermal issues.

:::tip

If you dont want to built your own homestaking node, you can aquire pre-built servers specifically designed for the use as Ethereum node that even come with preinstalled operating systems. üé® [**DAppNode**](https://dappnode.com/) and üåê [**Avado**](https://ava.do/) are good examples.

:::

## Optional Components

Depending on your long-term plans, you may need to expand the storage capacity, for example, if you plan to support multiple blockchains or require a future-proof solution. The freezer functionality available in clients like Geth can partition network data across different disks.

:::info Storage

I personally plan to add a second 2 TB or 4 TB 2.5" HDD from to accommodate future growth. If you plan to run your node for more than a decade or run an archive or slasher service on top, be sure to keep accessories and mounting frames handy.

:::

:::info Accessories

- **Thermal Paste & Tools:** Remember to have thermal paste and the correct screwdrivers ready for the built.
- **WiFi Antennas:** If planning to use the machine as a home server or personal computer at some point down the line, consider installing WiFi antennas right from the start. These small additions cost around 10‚Ç¨ but can save you significant time later. The anchoring can be crewed in without attaching the antennas, so you dont lose any space.

:::

:::tip

Further storage details can be found on the [**Client Providers**](/docs/theory/blockchain-knowledge/client-providers.md) page within the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section of the guide.

:::

## Secondary Devices

I installed my machine in a small home rack and connected the node to an 8-port switch, which in turn is linked to my router. This arrangement not only increases the number of available network ports but also allows for separation of servers and PCs across different rooms for improved network organization.

![Hardware Switch](/img/guides/hardware-setup/hardware-switch.png)

- **Switch:** TP-Link 8-Port Gigabit Network Switch - _Provides reliable connectivity and efficient data routing._
- **Network Setup:** Several RJ-45 Network cables - _Ensure high-quality, secure connections across your network._
- **Router**: Fritzbox 7590 AX - _Provides great bandwith, port configurations, and performance with fiber optic support_

:::tip

Further router and network information can be found in the [**Router Requirements**](/docs/theory/preparations/router-requirements.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

## Additional Considerations

This section provides additional strategies to ensure your node setup remains robust, efficient, and scalable. These considerations help you plan for future upgrades and safeguard your system against common challenges as your needs evolve.

| **Topic**                                  | **Description**                                                                                                                                                                                                                                                                                                                                                                                  |
| ------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| <nobr> **Energy Efficiency & UPS** </nobr> | For uninterrupted node operation, especially during power fluctuations or outages, consider investing in an Uninterruptible Power Supply. A UPS not only keeps your system running long enough to perform a safe shutdown but also protects against data corruption during sudden power loss. They generally range from 50‚Ç¨ to 150‚Ç¨ and should be chosen based on your node‚Äôs power consumption. |
| <nobr> **Cooling & Ventilation** </nobr>   | Even with a fanless design, ambient temperature control plays a crucial role in preserving hardware longevity. Ensure your node is positioned in a well-ventilated area to prevent heat build-up. In warmer climates or under heavy workload, additional passive cooling solutions or repositioning the device can significantly reduce the risk of overheating.                                 |
| <nobr> **Future Upgrades** </nobr>         | Keep in mind that while this guide outlines a high-performance configuration, entry-level setups are also possible. It‚Äôs important to match your hardware investment with your operational goals and growth plans. After all, you want to reach the point of break even with staking quite quickly.                                                                                              |

---

// File: guides/hardware-setup/mainboard-swap

# 2.2 Mainboard Swap

This section will walk you through the process of installing the mainboard into a new fanless enclosure for passive cooling.

:::warning

Before you start building, ground yourself by touching a metal object, like a heater, to discharge any static electricity and prevent damage to sensitive technical components.

:::

## Disassembling the Motherboard

**1. Open the Case**: _Remove the screws from the bottom of the NUC and gently open the case._

![Disassembling the Motherboard 1](/img/guides/hardware-setup/build_02.png)

**2. Unscrew the Motherboard**: _Unscrew the motherboard from the case to allow for complete removal._

![Disassembling the Motherboard 2](/img/guides/hardware-setup/build_03.png)

**3. Disconnect Cables**: _Disconnect all cables attached to the motherboard._

:::tip

Using a narrow wrench can improve your leverage when removing stubborn cables.

:::

![Disassembling the Motherboard 3](/img/guides/hardware-setup/build_04.png)

**4. Remove the Motherboard**: _Gently remove the motherboard from the case._

![Disassembling the Motherboard 4](/img/guides/hardware-setup/build_05.png)

**5. Set Aside Old Housing**: _Once the motherboard is removed, place the old housing aside for later reference._

![Disassembling the Motherboard 5](/img/guides/hardware-setup/build_06.png)

**6. Access the Fan Assembly**: _Turn the motherboard to expose the fan and its mounting frame._

![Disassembling the Motherboard 6](/img/guides/hardware-setup/build_07.png)

**7. Remove Fan Screws**: _Unscrew the fasteners securing the cooling fan. This step is essential for accessing the processor area._

![Disassembling the Motherboard 7](/img/guides/hardware-setup/build_08.png)

**8. Unplug Fan Cables**: _Carefully unplug the thin 4-pin fan cables to avoid any damage._

![Disassembling the Motherboard 8](/img/guides/hardware-setup/build_09.png)

**9. Remove the Processor Cooler Screws**: _The screws holding the fan also secure the old cooler that need to be unscrewed._

![Disassembling the Motherboard 9](/img/guides/hardware-setup/build_10.png)

**10. Detach the Processor Cooler**: _Gently pull the processor cooler upward and place it upside down to avoid smearing paste._

![Disassembling the Motherboard 10](/img/guides/hardware-setup/build_11.png)

**11. Clean Thermal Paste**: _Remove the thermal paste with an appropriate wipe and isopropyl alcohol._

![Disassembling the Motherboard 11](/img/guides/hardware-setup/build_12.png)

## Swapping the Enclosure

**1. Prepare the New Housing**: _Grab the new fanless housing, which also acts as a cooling block for the motherboard._

![Swapping the Enclosure 1](/img/guides/hardware-setup/build_13.png)

**2. Remove the Back Panel**: _Remove the back panel to access the mounting options for the motherboard._

![Swapping the Enclosure 2](/img/guides/hardware-setup/build_14.png)

**3. Turn the Case**: _Place the parts aside and turn the case around to facilitate the mounting process._

![Swapping the Enclosure 3](/img/guides/hardware-setup/build_15.png)

**4. Remove the Bottom Panel**: _Unscrew the fasteners securing the bottom panel of the enclosure._

![Swapping the Enclosure 4](/img/guides/hardware-setup/build_16.png)

**5. Clean the Motherboard**: _Clean the motherboard thoroughly to remove any residue before reinstalling._

![Swapping the Enclosure 5](/img/guides/hardware-setup/build_17.png)

**6. Apply New Thermal Paste**: _Apply and spread a thin, even layer of thermal paste on the processor._

:::tip

A modest amount is sufficient. Excess paste may be pressed out and cause staining or uneven cooling.

:::

![Swapping the Enclosure 6](/img/guides/hardware-setup/build_18.png)

**7. Clean the Cooling Surface**: _Clean the mating surface on the new enclosure that will contact the processor._

![Swapping the Enclosure 7](/img/guides/hardware-setup/build_19.png)

**8. Gather Mounting Accessories**: _Identify and set aside the correct screws and spacers required for securing the motherboard._

![Swapping the Enclosure 8](/img/guides/hardware-setup/build_20.png)

**9. Install the Motherboard**: _Carefully insert the motherboard into the new housing and ensure no paste is smeared._

![Swapping the Enclosure 9](/img/guides/hardware-setup/build_21.png)

**10. Secure the Motherboard**: _Tighten the screws gradually in opposite directions to ensure an even pressure distribution._

![Swapping the Enclosure 10](/img/guides/hardware-setup/build_22.png)

---

// File: guides/hardware-setup/component-assembly

# 2.3 Component Assembly

This sequence will walk you through all the steps I followed while installing the hardware components for my node and includes installing memory, storage devices, antennas, and hard disks.

:::warning

Before you start building, ground yourself by touching a metal object, like a heater, to discharge any static electricity and prevent damage to sensitive technical components.

:::

## Attaching the Components

**1. Open the Case**: _Remove the screws from the bottom of the NUC and gently open the case._

![Attaching the Components 1](/img/guides/hardware-setup/build_23.png)

**2. Unscrew the Memory Holder**: _Unpack the memory bars and insert them one on top of the other into the provided holder._

![Attaching the Components 2](/img/guides/hardware-setup/build_24.png)

**3. Unpack Antenna Connection Cables**: _If you plan to use the WiFi down the line, now is the time to insert the connectors._

![Attaching the Components 3](/img/guides/hardware-setup/build_25.png)

**4. Install Antenna Connection Cables**: _Carefully press each cable into the designated edge to ensure they are seated properly._

![Attaching the Components 4](/img/guides/hardware-setup/build_26.png)

**5. Install the Hard Disk**: _Insert the hard disk above the antenna. Place it diagonally from above and fasten it securely._

![Attaching the Components 5](/img/guides/hardware-setup/build_27.png)

## Adding Additional Storage

If you have an additional large hard drive that comes with its own frame, mount the 2.5" hard drive onto the provided frame. Then, screw the frame into the housing.

**1. Connect the Hard Drive Cable**: _Attach the hard drive cable to the mainboard using the cable included in the package._

**2. Secure the Hard Drive Frame**: _Screw the frame to the top of the case so that the hard drive faces downward._

:::tip

There is only one hard drive connector on the mainboard, so ensure you use it.

:::

:::info

The storage frame should sit flush under the edge of the case, leaving enough room for the backplate installation.

:::

![Attaching the Components 6](/img/guides/hardware-setup/build_28.png)

## Attaching the Backplate

**1. Fit the Backplate**: _Hold the motherboard against the back of the case. If antennas are present, attach them to the back panel._

![Attaching the Backplate 1](/img/guides/hardware-setup/build_29.png)

**2. Adjust for Clearance**: _Ensure the back panel sits directly against the motherboard connectors without pressure._

:::tip

If needed, readjust the motherboard slightly to account for minimal clearance, so nothing is pressed down with force.

:::

![Attaching the Backplate 2](/img/guides/hardware-setup/build_30.png)

**3. Fasten the Backplate**: _Once everything is aligned, screw in the back panel to secure the motherboard._

![Attaching the Backplate 3](/img/guides/hardware-setup/build_31.png)

## Adding the Storage Cooler

**1. Install the Hard Disk Cooler**: _Begin by installing the hard disk cooler._

![Adding the Storage Cooler 1](/img/guides/hardware-setup/build_32.png)

**2. Remove Protective Foil & Apply Rubber Mass**: _Remove the foil from the hard disk and place the heat-conducting rubber mass._

:::tip

The hard disk's sticker is made of thermally conductive film and adhesive. You do not have to remove it, as doing so might void the warranty of your disk. Keep it on in case there is an issue with reading or writing data to it.

:::

![Adding the Storage Cooler 2](/img/guides/hardware-setup/build_33.png)

**3. Prepare the Cooler Surface**: _Clean the metal piece with an alcohol wipe, then reapply a thin layer of thermal paste._

:::tip

Also, clean the inner surface of the housing where the cooler will be placed using a cotton swab and alcohol.

:::

![Adding the Storage Cooler 3](/img/guides/hardware-setup/build_34.png)

**4. Install the Cooler**: _Slowly insert the cooler from the top. Be cautious, as the rubber mass sticks and is difficult to re-adjust._

![Adding the Storage Cooler 4](/img/guides/hardware-setup/build_35.png)

## Assembling the Enclosure

**1. Attach the Final Side Panel**: _Secure the last side of the housing by screwing it on, being careful not to bend any cables._

:::info

If you have a second hard drive, ensure that its frame sits evenly and does not touch the lid.

:::

![Assembling the Enclosure 1](/img/guides/hardware-setup/build_36.png)

**2. Install Covers and Stands**: _Whether you prefer an upright or horizontal placement, install the appropriate covers and stands._

![Assembling the Enclosure 2](/img/guides/hardware-setup/build_37.png)

:::tip

For professional server racks, a horizontal position might be more suitable because it allows you to add multiple levels and arrange switch frames above and below. For regular shelfs, an upright position might safe space and offers less storage space for dust. However, the cooling capacity should remain constant.

:::

![Assembling the Enclosure 3](/img/guides/hardware-setup/build_38.png)

**3. Finalize the Assembly**: _Attach the antennas if desired. You may leave them unscrewed and store them until needed._

:::info

For regular server or node usage, a wired internet connection is strongly recommended.

:::

![Assembling the Enclosure 4](/img/guides/hardware-setup/build_39.png)

If you completed the hardware build, you can now proceed with configuring the BIOS and installing the operating system.

---

// File: guides/hardware-setup/os-installation

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 2.4 OS Installation

Installing the right operating system is crucial for your node's stability and performance. In the blockchain space, almost every node is either run using Ubuntu or Debian under the hood.
They're open-source and flexible, provide excellent stability, extensive community support, and seamless integration with software automation.

:::tip

If you are uncertain about which operating system and node setup to choose, you can find further details and comparisons on the [**Operating Systems**](/docs/theory/node-operation/operation-systems.md) and [**Client Setups**](/docs/theory/node-operation/client-setups.md) pages within the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

:::warning

If you want to become a validator and do not have a separate computer available to safely generate your validator keys, head over to the [**Validator Setup**](/docs/guides/validator-setup/precautions.md) and generate your keys using your node before flashing it and continuing with the OS installation.

:::

## Creating a Bootable Device

Both Ubuntu and Debian require a USB device with at least 2GB of capacity to create a bootable installer. Once downloaded, the bootable USB device is created on your personal computer. Once the update is complete, the USB device can be removed and inserted to your node to install the operation system on it's primary storage disk.

<Tabs>
<TabItem value="ubuntu" label="Ubuntu">
  
1. **Download the Ubuntu Server LTS**  
   Download [Ubuntu 22.04.2 Server](https://ubuntu.com/download/server) from the official website.

2. **Create a Bootable USB Drive**  
   Use the ISO file to create a bootable USB drive:

   - **Windows:** Follow the [Rufus Guide for Ubuntu](https://ubuntu.com/tutorials/create-a-usb-stick-on-windows#1-overview).
   - **Linux:** Use the [Disk Creator Guide for Ubuntu](https://ubuntu.com/tutorials/create-a-usb-stick-on-ubuntu#1-overview).
   - **MacOS:** Refer to the [Etcher Guide for Ubuntu](https://ubuntu.com/tutorials/create-a-usb-stick-on-macos#1-overview).

3. **Prepare the Installer**  
   Safely remove the USB drive from your current computer once the bootable USB drive is created.

4. **Connect to Your Node**  
   Insert the USB drive into your node to install Ubuntu Server on its storage disk.

</TabItem>
<TabItem value="debian" label="Debian">
  
1. **Download the Debian Server Version**  
   Download [Debian 11 Bullseye](https://www.debian.org/distrib/) from the official Debian website.

2. **Create a Bootable USB Drive**  
   Use the ISO file to create a bootable USB drive:

   - **Windows:** Follow the [Rufus Guide for Debian](https://rufus.ie/).
   - **Linux:** Use the [Etcher Guide for Debian](https://etcher.balena.io/#download-etcher).
   - **MacOS:** Refer to the [Etcher Guide for Debian](https://etcher.balena.io/#download-etcher).

3. **Prepare the Installer**  
   Safely remove the USB drive from your current computer once the bootable USB drive is created.

4. **Connect to Your Node**  
   Insert the USB drive into your node to install Debian on its storage disk.

</TabItem>
</Tabs>

---

// File: guides/hardware-setup/bios-setup

# 2.5 BIOS Setup

Proper BIOS configuration is critical for optimizing your node's energy consumption and overall performance. Adjusting the settings will ensure that your node machine runs smooth and efficient under various load scenarios and automatically restarts during power failures.

:::warning

BIOS settings vary depending on the CPU and motherboard. For further help, please refer to your device‚Äôs documentation.

:::

## 1. Enter BIOS

1. Connect your machine to power and attach a keyboard and monitor.
1. Connect your bootable USB device to the node.
1. Turn on the node using the power button.
1. Press `F2` on your keyboard during boot to enter the BIOS setup.

## 2. Power Settings

:::info

Auto-starts enable your node to restart after a power interruption, reducing downtime and maintaining network participation.

:::

1. Navigate to `Power` -> `Secondary Power Settings`.
2. Set **After Power Failure** to `Power On`.
3. Set **Wake on LAN from S4/S5** to `Power On - Normal Boot`.

## 3. CPU Settings

:::info

These settings optimize performance on load and general energy efficiency. If your node has fans, skip the cooling adjustment.

:::

1. Go to `Cooling` and set **Fan Control Mode** to `Fanless` (for fanless housing).
2. Navigate to `Performance` -> `Processor`:
   - Set **Hyper-Threading** to `Enabled`.
   - Enable **Intel Turbo Boost Technology**.
   - Set **Active Processor Cores** to `All`.
   - Enable **Real-Time Performance Tuning**.
3. Navigate to `Power`:

   - Enable **Max Performance Enabled**.
   - Set **Intel Dynamic Power Technology** to `Energy Efficient Performance`.
   - Set **Package Power Limit 1 (Sustained)** to `25`.
   - Set **Package Power Limit 2 (Burst Mode)** to `25`.
   - Set **Package Power Time Window (Tau)** to `0`.

## 4. LED Settings

:::info

For server installations, you might choose to disable the illuminated status indicators.

:::

1. Go to `Power` -> `Secondary Power Settings`.
2. Set **S0 Indicator Brightness (%)** to `0`.
3. Set **Modern Standby Indicator Brightness (%)** to `0`.
4. In `RGB LED`, set **Brightness (%)** to `0`.
5. In `HDD LED`, set **Brightness (%)** to `0`.

## 5. Boot Order

:::info

Establishing the correct boot order ensures that your node boots from the correct device after it's USB installation.

:::

1. Go to `Boot` -> `Boot Priority`.
2. Set **Boot Option #1** to your USB device.
3. Set **Boot Option #2** to your internal SSD.

## 6. Startup

Once the BIOS settings are correctly configured, you can proceed with the operating system installation. Saving and exiting the BIOS applies your configuration changes, and booting the installation media initiates the operating system setup process.

1. Press `F10` to save changes and exit the BIOS.
2. Wait for the system to boot from the USB stick.
3. Choose `Try or Install Ubuntu Server`.
4. Allow the installation setup to run through.

---

// File: guides/hardware-setup/ubuntu-configuration

# 2.6 Ubuntu Configuration

Configuring Ubuntu for your blockchain node is a crucial step to ensure stability, performance, and secure connectivity. In this guide, we document the complete process and considerations for installing and setting up Ubuntu Server on your node.

:::tip

For additional reference, you can view the official [**Ubuntu's Install Guide**](https://ubuntu.com/tutorials/install-ubuntu-server#1-overview).

:::

## System Settings

After completing the [BIOS Setup](./bios-setup.md) and connecting the prepared bootable USB device, you should be faced with the Ubuntu installation screen. You can select _Try or Install Ubuntu Server_ in order to boot up the operation system on the USB drive or copying and installing the full version on the primary hard drive.

![Try or Install Ubuntu Server](/img/guides/hardware-setup/install_01.png)

Connect your machine to the router using an Ethernet cable so that the installer can receive updates. A stable internet connection and low latency is also necessary for running the blockchain and monitoring system later on.

:::info

More details about network usage and connections can be found on the [**Network Demand**](/docs/theory/preparations/network-demand.md) page of the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

**1. System Language**: _Choose your operating system's language._

:::tip

It is recommended to select _English_, as most troubleshooting guides and support documentation are written in English.

:::

![Ubuntu System Language](/img/guides/hardware-setup/install_02.png)

**2. Keyboard Config**: _Select your keyboard layout or click on *Identify keyboard* and follow the on-screen guide._

:::tip

The correct configuration ensures that your command-line entries during setup and maintenance work as expected.

:::

![Ubuntu Keyboard Config](/img/guides/hardware-setup/install_03.png)

**3. Installation Type**: _Choose the regular Ubuntu Server installation for your node._

:::tip

Detailed differences of a minimal or regular installation can be found in the [**Operation Systems**](/docs/theory/node-operation/operation-systems.md) page of the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

![Ubuntu Installation Type](/img/guides/hardware-setup/install_04.png)

:::warning

Do not _Search for third-party drivers_. Additional services could potentially be a harm to security and ease of maintenance.

:::

**4. Network and Access Settings**: _Configure your network settings to allow external access to your node._

:::info

If your node is connected via Ethernet, set the network type to _eth_ and configure both IPv4 and IPv6 as _Automatic DHCP_.

:::

![Ubuntu Network and Access Settings](/img/guides/hardware-setup/install_05.png)

**5. Network Proxy**: _Here, you could select a proxy address. If you do not already have a proxy setup, leave the address blank._

:::info

The HTTP proxy and static IP addresses are usually configured later once the node is ready for operation.

:::

![Ubuntu Proxy Setup](/img/guides/hardware-setup/install_06.png)

**6. Download and Installer**: _Proceed with the installation using the official Ubuntu mirror address and press Enter._

:::tip

If a new installer update becomes available during this phase, download the latest version and resume once the update is complete. It's always recommended to use the latest official software release of the manufacturer in case important security updates have been implemented.

:::

![Ubuntu Download and Installer](/img/guides/hardware-setup/install_07.png)

**7. Storage Setup**: _For storage configuration, choose to use the entire disk and configure your LVM and encryption setup._

:::info

- Logical Volume Management (LVM) is recommended as it allows flexible resizing of storage volumes without downtime. This is particularly useful if you plan to run multiple blockchain nodes or add additional disks in the future. LVM groups multiple physical disks into a single logical volume, simplifying management.
- Full disk encryption is optional. While encryption can secure data, it may complicate remote access by requiring manual intervention at boot. Since your validator keys and wallet are already encrypted, full disk encryption is generally not recommended for this use case.

:::

:::tip

LVM is enabled by default on new DAppnode machines and has been the default option on Ubuntu since version 20.04.

:::

![Ubuntu Partition Config](/img/guides/hardware-setup/install_08.png)

:::note

On the storage screen, you will see your available disks along with their mount points. If you enabled LVM, a volume group (_ubuntu-vg_) with a logical volume (_ubuntu-lv_) will be created.

- To maximize your storage, set the logical volume size to the maximum available.
- Default naming conventions (e.g., _ubuntu-vg_ and _ubuntu-lv_) are recommended prevent confusion later.
- The storage format should be kept at _ext4_, supporting large file sizes, efficient disk allocation, and robust performance.

:::

:::tip

Further details about disks and volumes can be found on the [**Disk Management**](/docs/theory/node-operation/disk-management.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

## User and Software Settings

After the general device and operation system configuration, you will be faced with administrative settings for your node and the additional software to be installed.

**1. User Creation**: _Create your user account and assign a strong password. This account will be used to administer the node._

![Ubuntu User Config](/img/guides/hardware-setup/install_09.png)

:::note

It is advisable to avoid [Ubuntu Pro](https://ubuntu.com/pricing/pro), as this premium service is intended for enterprise use that comes with additional features, security updates, and support compared to the standard Ubuntu release. The primary target are businesses and organizations seeking a more comprehensive and secure Ubuntu experience.

:::

**2. SSH Installation**: _Install the OpenSSH server to enable secure remote access._

:::info

OpenSSH is essential for encrypted communication, command-line management, and key-based authentication, offering numerous benefits for remote node administration from your home environment or even global networks.

:::

:::tip

Further details about node connectivity can be found on the [**SSH and VPN Tunnel**](/docs/theory/node-operation/ssh-and-vpn-tunnel.md) page of the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

![Ubuntu SSH Install](/img/guides/hardware-setup/install_10.png)

:::note

If you do not have an SSH identity yet, leave the field blank. We will configure SSH once the operation system is installed.

:::

**3. Additional Software**: _Skip through the additional server snaps without enabling extra packages._

:::tip

It is best to manually install and configure software packages as needed for your specific node setup.

:::
![Ubuntu Additional Software](/img/guides/hardware-setup/install_11.png)

## Installation Process

Let the Ubuntu installation process run until it is fully complete. This might take some minutes depending on your hardware components or if you choose to encrypt or configure the disk with multiple logical volumes. Once done, remove the USB device and press _Enter_ to reboot your machine. After the reboot process is successful, you can continue with the system's core setup.

![Ubuntu Additional Software](/img/guides/hardware-setup/install_12.png)

:::tip

The USB device will no longer be needed. You could reformat it for regular use. However, its generally recommended to label the disk and keep it around in case there are problems and you want to create a fresh setup of your node again.

:::

---

// File: guides/system-setup/permission-management

# 3.1 Permission Management

Managing user permissions is a critical component for securing your node system. By locking direct root access and enforcing the use of superuser privileges, you create an auditable environment that minimizes the risk of accidental or malicious system changes. This guide explains how to disable direct root login and manage user passwords for better security.

| **Command** | **Description**                                                                                                                                                                                                                                                                                                                                                                                                                |
| ----------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `sudo`      | When the system is set up with a regular user account, certain commands require elevated privileges. The superuser command, allows a user to run commands with the privileges of another user, usually the root user, without exposing the root password. This controlled mechanism is essential for maintaining system security and accountability.                                                                           |
| `passwd`    | The password command is a fundamental utility in Unix-based operating systems for managing user passwords. With administrative rights, you can use _passwd_ to change passwords for any account on the system. Options include setting password expiry, locking/unlocking accounts, and forcing password resets on next login. This is essential for ensuring that only authorized users can access critical system functions. |

:::warning

Always be cautious when using _sudo_, as executing commands with root privileges can inadvertently harm your system.

:::

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Disable Root Access

To improve system security, it is best practice to disable direct root login Locking the root account prevents unauthorized direct access, forcing all administrative commands to go through superuser permissions, ensuring that no one can bypass the security policies of elevated privileges.

:::info

Using the `passwd` command with the lock `-l` option, disables the root account's ability to log in with a password.

:::

Open a terminal and type the following command:

```sh
sudo passwd -l root
```

The outcome should look like this:

```text
passwd: password expiry information changed.
```

## 2. Check Root Account

After locking the root account, you should verify the change. With the root account locked, any command requiring administrative rights will prompt you for your user password through superuser permissions.

:::info

Using the `passwd` command with the status `-S` option prints the current settings.

:::

In the terminal, type:

```sh
sudo passwd -S root
```

You should see an output similar to:

```text
root L [DATE] 0 99999 7 -1
```

:::tip

- Uppercase `L` signifies that the root account has been locked.
- Uppercase `P`, means that the account is still active with a valid password.

:::

---

// File: guides/system-setup/disk-volumes

# 3.2 Disk Volumes

This section explains how to manage and extend your disk volumes using the Logical Volume Manager. By default, during installation, LVM allocates only a conservative 100‚ÄØGB for the logical volume. The process ensures that the node utilizes the entire disk space without getting interruptions once the storage cap is hit.

:::tip

It is common practice to extend the default allocation to match the physical storage before new hard disks become necessary.

:::

:::warning

This page is only relevant if you set up the recommended logical disk management for your volume.

:::

## 1. Checking the Volume Group

LVM provides a flexible and powerful method for managing your disk storage. This subsection covers the basics of inspecting your volume groups, physical extents, and current disk usage. Before adding or extending any storage volumes, check the current status of your volume group. Use the following command to display details about your volume groups:

```sh
sudo vgdisplay
```

If you have not changed the LVM settings during installation, the output should be similar to:

```text
  --- Volume group ---
  VG Name               ubuntu-vg
  System ID
  Format                lvm2
  Metadata Areas        1
  Metadata Sequence No  2
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                1
  Open LV               1
  Max PV                0
  Cur PV                1
  Act PV                1
  VG Size               [VOLUME_GROUP_SIZE]
  PE Size               4.00 MiB
  Total PE              [TOTAL_PE]
  Alloc PE / Size       [ALLOCATED_PE] / 100.00 GiB
  Free  PE / Size       [FREE_PE] / [FREE_DISK_SPACE]
  VG UUID               [VOLUME_GROUP_UNIVERSALLY_UNIQUE_IDENTIFIER]
```

:::tip

If you are uncertain about storage or logical volumes, further information can be found on the [**Disk Management**](/docs/theory/node-operation/disk-management.md) page within the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section to ensure you have the fundamental knowledge.

:::

When a physical disk is added to an LVM group, it is divided into physical extents, which are uniform chunks of disk space, typically several megabytes each. The critical properties to monitor are:

- Total Physical Extents: The overall number of PEs allocated or available.
- Allocated PE / Size: How much space is currently used by the logical volume.
- Free PE / Size: The remaining unallocated space that is available for extension.

Check the amount of free disk space left on the physical volume. If you did not already extend the disk size during the installation, there should be plenty of storage left that we can add to the logical volume of the group.

:::info

If you have customized your installation, the name of the volume group may differ. Even if you extended your logical volume during installation, checking the volume group gives you useful insight into the available free physical extents.

If you already extended your logical volume to the maximum available capacity during installation, the `Free PE / Size` property will show `0 / 0`, meaning no more unreserved storage is left on the volume group for any partition to utilize.

:::

## 2. Checking Mounted Volumes

Additionally, you can check how the logical volume is mounted and used by running.

:::tip

You can use the disk filesystem command `df` using the `-h` flag to print the outcomes in a human-readable format.

:::

```sh
df -h
```

A typical output might look like:

```sh
Filesystem                         Size  Used Avail Use% Mounted on
tmpfs                              3.2G  1.6M  3.2G   1% /run
/dev/mapper/ubuntu--vg-ubuntu--lv  1.8T   11G  100G  11% /
tmpfs                               16G     0   16G   0% /dev/shm
tmpfs                              5.0M     0  5.0M   0% /run/lock
/dev/nvme0n1p2                     2.0G  131M  1.7G   8% /boot
/dev/nvme0n1p1                     1.1G  6.1M  1.1G   1% /boot/efi
tmpfs                              3.2G  4.0K  3.2G   1% /run/user/1000
```

:::info

Check the size of your volume group that is `Mounted On` the root `/` directory. If you did not extend your logical volume, the size of it will show as `100G`. The Ubuntu installation itself therefore takes up around `11%` of the volume.

:::

## 3. Adding a New Disk

If you have a second storage device that you want to add to your node, you can extend your volume group across multiple physical disks. Before proceeding, shut down your node properly using:

```sh
sudo shutdown now
```

Then, install the new disk into the appropriate frame.

:::tip

Further information about adding a hard drive to your node can be found in the [**Component Assambly**](/docs/guides/hardware-setup/component-assembly.md) page.

:::

Once your node is powered up, we have to determine the identifier of the new device. We can use the list block command tool to display information about all block device files, which specify storage devices such as hard drives, SSDs, and optical drives.

```sh
lsblk
```

The output should look similar if you have an NVM SSD and a 2.5" HDD, but sizes might differ to your build.

```text
NAME                      MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS
loop0                       7:0    0  63.3M  1 loop /snap/core20/1822
loop1                       7:1    0  63.3M  1 loop /snap/core20/1879
loop2                       7:2    0 111.9M  1 loop /snap/lxd/24322
loop3                       7:3    0  49.8M  1 loop /snap/snapd/18357
loop4                       7:4    0  53.2M  1 loop /snap/snapd/19122
nvme0n1                   259:0    0   1.8T  0 disk
‚îú‚îÄnvme0n1p1               259:1    0     1G  0 part /boot/efi
‚îú‚îÄnvme0n1p2               259:2    0     2G  0 part /boot
‚îî‚îÄnvme0n1p3               259:3    0   1.8T  0 part
  ‚îî‚îÄubuntu--vg-ubuntu--lv 253:0    0   1.8T  0 lvm  /
sda                         8:0    0   7.8T  0 disk
```

:::info

- `nvme0n1` is the disk identifier of the SSD used as the primary storage
- `sda` is the disk identifier of the HDD used as additional storage

:::

**3.1 Initializing the disk**: _Use the LVM tool to create a new physical volume._

```sh
sudo pvcreate /dev/<disk-identifier>
```

**3.2 Extend the Volume Group**: _Add the new disk to your existing volume group._

:::info

We can extend the existing volume group to include this new physical volume on top of the initial SSD's space. Therefore, we can use the volume group extension tool. We will have to input the volume group's name and the path to the newly added physical volume that we want to add.

:::

```sh
sudo vgextend <volume-group-name> /dev/<disk-identifier>
```

**3.3 Verify the Extension**: _Check the updated volume group size and details._

```sh
sudo vgdisplay
```

The output and volume group name should look similar to this:

```text
  --- Volume group ---
  VG Name               ubuntu-vg
  System ID
  Format                lvm2
  Metadata Areas        1
  Metadata Sequence No  2
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                1
  Open LV               1
  Max PV                0
  Cur PV                1
  Act PV                1
  VG Size               [VOLUME_GROUP_SIZE]
  PE Size               4.00 MiB
  Total PE              [TOTAL_PE]
  Alloc PE / Size       [ALLOCATED_PE] / [LOGICAL_VOLUME_SIZE]
  Free  PE / Size       [FREE_PE] / [FREE_DISK_SPACE]
  VG UUID               [VOLUME_GROUP_UNIVERSALLY_UNIQUE_IDENTIFIER]
```

:::info

The `Free PE / Size` should now reflect the additional capacity from the new disk.

:::

The capacity now has to be added to our logical volume to use in on our node.

## 4. Checking Logical Volumes

Before adding space to our logical volume, we have to check the properties of the logical volumes available on the device.

```sh
sudo lvdisplay
```

If you never changed the LVM settings during installation, the output and volume group name should look similar to this:

```text
  --- Logical volume ---
  LV Path                /dev/ubuntu-vg/ubuntu-lv
  LV Name                ubuntu-lv
  VG Name                ubuntu-vg
  LV UUID                [LOGICAL_VOLUME_UNIVERSALLY_UNIQUE_IDENTIFIER]
  LV Write Access        read/write
  LV Creation host, time ubuntu-server, [CREATION_DATE] +0000
  LV Status              available
  # open                 1
  LV Size                <100.00 GiB
  Current LE             [NUMBER_OF_LOGICAL_EXTENTS]
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     256
  Block device           253:0
```

:::info

Remember that the `LV Path`, `LV Name`, and `VG Name` properties might differ if you have been given a custom name during installation. If you previously extended your volume, the `LV Size` will match your initial physical disk size.

:::

## 5. Extending a Logical Volume

LVM itself comes with its own toolkit to increase the size of a logical volume.

:::note Toolkit Parameters

- `-l`: specifies the **size** that should be given to the logical volume **in extents**. We can use `+100%FREE` to tell the extension tool to use all the free Physical Extents in the volume group. It will then effectively extend the logical volume to use the remaining free space in the volume group. Use a lower amount to expand a volume group by a lower percentage.
- `-L`: specifies the **size** that should be given to the logical volume **in gigabytes**. We can use `+100G` to tell the extension tool to add 100 GB to the volume group. It will then effectively extend the logical volume to use the remaining free space in the volume group. You can change the number for different amounts or extend smaller amounts using `M` for megabytes and `T` for terabytes.
- `path`: defines the logical volume you want to extend on the volume group.

:::

:::info

Update the `<logical-volume-path>` with the `LV Path` property from the previous `lvdisplay` command.

:::

If you did not extend the storage before but want to use the full disk capacity, you can use the following command:

```sh
sudo lvextend -l +100%FREE <logical-volume-path>
```

The output should look like the following:

```sh
  Size of logical volume <volume-group-name>/<logical-volume-name> changed from [INITIAL_STORAGE_SPACE] GiB ([ALLOCATED_PE] extents) to [FINAL_STORAGE_SPACE] ([TOTAL_PE] extents).
  Logical volume <volume-group-name>/<logical-volume-name> successfully resized.
```

After running this command, the file system on the logical volume needs to be resized to take advantage of the newly added space.

## 6. Resizing a Volume Group

LVM itself has a utility for resizing file systems. We can pass the device file representing the logical volume we want to resize.

```sh
sudo resize2fs /dev/mapper/ubuntu--vg-ubuntu--lv
```

:::info

When `resize2fs` command will add the available space on the previously extended devices without a defined size.

:::

The output should look like the following:

```sh
resize2fs 1.46.5 ([DATE])
Filesystem at /dev/mapper/ubuntu--vg-ubuntu--lv is mounted on /; on-line resizing required
old_desc_blocks = [DESC_BLOCKS], new_desc_blocks = [NEW_DESC_BLOCKS]
The filesystem on /dev/mapper/ubuntu--vg-ubuntu--lv is now [TOTAL_BLOCKS] ([BLOCK_NUMBER]) blocks long.
```

:::tip

Further details about blocks and resizing can be found on the [**Disk Management**](/docs/theory/node-operation/disk-management.md) page of the üß† [**Theory Section**](/docs/theory/preparations/node-specifications.md) section.

:::

## 6. Verifying Storage Space

After the extension, verify that the volume group and logical volume have been updated correctly:

```sh
sudo vgdisplay
```

The output should be something like this:

```text
  --- Volume group ---
  VG Name               ubuntu-vg
  System ID
  Format                lvm2
  Metadata Areas        1
  Metadata Sequence No  3
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                1
  Open LV               1
  Max PV                0
  Cur PV                1
  Act PV                1
  VG Size               [VOLUME_GROUP_SIZE]
  PE Size               4.00 MiB
  Total PE              [TOTAL_PE]
  Alloc PE / Size       [ALLOCATED_PE] / [FULL_DISK_SPACE]
  Free  PE / Size       0 / 0
  VG UUID               [UNIVERSALLY_UNIQUE_IDENTIFIER]
```

:::info
During the checkup, ensure that:

- The group covers the whole disk space: `[VOLUME_GROUP_SIZE]` equals `[FULL_DISK_SPACE]`
- All physical extends got added to the volumes: `[ALLOCATED_PE]` equals `[TOTAL_PE]`
- All physical extends are registered: `Free PE / Size` is `0 / 0`

:::

You can also recheck the disk usage:

```sh
df -h
```

```text
Filesystem                         Size  Used Avail Use% Mounted on
tmpfs                              3.2G  1.6M  3.2G   1% /run
/dev/mapper/ubuntu--vg-ubuntu--lv  1.8T   11G  1.8T   1% /
tmpfs                               16G     0   16G   0% /dev/shm
tmpfs                              5.0M     0  5.0M   0% /run/lock
/dev/nvme0n1p2                     2.0G  131M  1.7G   8% /boot
/dev/nvme0n1p1                     1.1G  6.1M  1.1G   1% /boot/efi
tmpfs                              3.2G  4.0K  3.2G   1% /run/user/1000
```

:::info

- The storage `Mounted On` the `/` root directory should have increased
- The percentage of `Use` should have decreased relative to the increased size

:::

---

// File: guides/system-setup/ubuntu-updates

# 3.3 Ubuntu Updates

Keeping your Ubuntu system up to date is essential for security, stability, and performance. Regular updates ensure that all software packages and security patches are current, reducing vulnerabilities and maintaining optimal performance of your node. This section details how to update the package list, upgrade installed packages, remove obsolete dependencies, clean the package cache, and enable automatic security updates.

## Advanced Package Tool

APT is the package management system used in Ubuntu and other Debian-based distributions to install, upgrade, and remove software packages. Its command-line tool _apt_ handles dependencies automatically and provides a user-friendly way to manage software on your system.

:::tip

APT also ensures that your system receives timely security patches and performance improvements.

:::

## 1. Updating the Package List

Updating the package list fetches the latest package information from the repositories defined in your system's sources list. This step is crucial to ensure that you‚Äôre installing the most recent versions of software. Without an updated package list, your system cannot identify new updates or security fixes available from the Ubuntu repositories.

```sh
sudo apt update
```

## 2. Upgrading Packages

After updating the package list, you can upgrade the installed packages on your system to their latest versions. This ensures that you benefit from recent updates, security patches, and performance improvements. Keeping packages upgraded minimizes vulnerabilities and ensures the system is running the most efficient versions of all software components.

```sh
sudo apt upgrade
```

## 3. Removing Legacy Dependencies

Over time, the system may accumulate packages that were automatically installed as dependencies but are no longer required. Removing these legacy dependencies frees up disk space, reduces the risk of conflicts, and simplifies system maintenance.

```sh
sudo apt autoremove
```

## 4. Cleaning Local Package Cache

Cleaning the local package cache removes outdated package files that are no longer needed after installation. This step helps reclaim disk space and keeps your system lean. Regularly cleaning the cache prevents the build-up of obsolete cache files.

```sh
sudo apt autoclean
```

## 5. Enabling Security Updates

For a secure and stable server environment, it is important to apply critical updates automatically. It's possible to automate the installation of security updates and essential patches to ensure your system is up-to-date and protected against known vulnerabilities.

:::info

Using the `unattended-upgrades` package, node operators can reduce the manual effort involved in monitoring and applying updates while minimizing the risk of potential downtime or breaches caused by outdated software. The package offers various configuration options to tailor the upgrade process according to the specific needs of a system, such as the ability to select which packages to update, schedule the upgrade frequency, and control notifications.

:::

**1. Install Unattended Upgrades**: _Download the package using APT_

```sh
sudo apt install unattended-upgrades
```

**2. Configure Unattended Upgrades**: _Reconfigure the package to enable automatic updates._

```sh
sudo dpkg-reconfigure -plow unattended-upgrades
```

:::tip

Setting the priority to low using `plow` ensures that only essential questions are asked, and default options are applied.

:::

:::info

The `dpkg-reconfigure` command is a utility that reconfigures an already-installed package using user-provided values.
:::

You will get a screen prompt in the terminal. Agree with _Yes_ and continue the setup.

![Auto Update Screen](/img/guides/system-setup/setup-autoupdate.png)

---

// File: guides/system-setup/remote-access

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 3.4 Remote Access

Establishing secure remote access to your node is essential for system maintenance and monitoring. In this guide, we focus on configuring the OpenSSH Server by editing its main configuration file, selecting a non-standard port for added security, and verifying that the changes have been applied correctly.

:::info

OpenSSH Server was installed during the operation system setup, is located at `/etc/ssh/sshd_config`, and controls key parameters such as authentication methods, the listening port, and security directives. In comparison to the OpenSSH Client, which allows you tio connect and use a certain system, its a more lightway version simply granting access to a remote system.

:::

:::tip

Unlike the OpenSSH Client, which allows you to connect to and use a particular remote system, its server variant is a lighter tool only granting access. In this regard, the node cannot act as an active part.

:::

## 1. SSH Port Configuration

Changing the SSH port from its defaul to a non-standard port can reduce the risk of automated attacks and port scanning. Although changing the port is not a comprehensive security solution, it adds an extra layer of obscurity.

:::info

The default port number is `22`. It is recommended to choose a port number higher than `1024`, often above `50000`, to avoid conflicts with standard services. Always ensure the chosen port is not used by any other service on your system. The highest possible number is `65535`, as port numbers are 16-bit unsigned integers.

:::

Use your preferred text editor to open the SSH configuration file:

<Tabs>
<TabItem value="vim" label="Vim" default>

```sh
sudo vim /etc/ssh/sshd_config
```

</TabItem>
<TabItem value="nano" label="Nano">

```sh
sudo nano /etc/ssh/sshd_config
```

</TabItem>
</Tabs>

1. Locate the line `#Port 22`.
2. Remove the `#` in front to uncomment the line.
3. Change the number to your desired port value.
4. Save the file and exit the editor.

:::tip

This change instructs SSH to listen on the new port. You will need to specify this port number when connecting remotely. For example you could change it to `50022` or `60022`, both fulfilling all requirements of the numerical range.

:::

## 2. Managing the SSH Service

After modifying the configuration file, restart the SSH service to apply the changes.

**2.1 Verify the Configuration**: _Before restarting, test the updated configuration._

```sh
sudo sshd -t
```

If no output is returned, the configuration is valid.

**2.2 Restart the SSH Service**: _Restart the SSH daemon._

```sh
sudo systemctl restart sshd
```

:::info Daemon Services

Daemon services, like `sshd` are background processes that run continuously on Unix-like operating systems, including Linux. These services perform various tasks and provide essential functionalities without direct user interaction.

:::

:::tip

Further information about system control commands can be found on the [**Utility Tools**](/docs/theory/node-operation/utility-tools.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

**2.3 Check System Services**: _Inspect all system services to ensure SSH is running._

```sh
systemctl list-unit-files --type=service
```

:::info

- The command provides a list of services along with their status.
- Both `ssh` and `sshd` services should be active enabled.

:::

With these changes, remote access to your node will be securely configured with a custom port, and you can now connect to your node using your preferred SSH client.

---

// File: guides/system-setup/startup-utility

# 3.5 Startup Utility

Ensuring that the OpenSSH service starts automatically at system boot is critical for maintaining remote access to your node. We will verify that the SSH service is enabled at startup, meaning you dont have to log in manually each time the system reboots.

## 1. Check SSH Bootprocess

First, verify whether the OpenSSH service is already enabled to start at boot:

```sh
sudo systemctl is-enabled ssh
```

:::tip

Further information about system control commands can be found on the [**Utility Tools**](/docs/theory/node-operation/utility-tools.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

:::note

- If the service is `enabled`, it already starts during the boot process.
- If the service is `disabled`, you must configure a symbolic link.

:::

:::info Symbolic Links

A symbolic link is a special type of file that serves as a pointer to another file or directory. This means that services can be referenced without duplicating any files. In the context of system services, such a link must be created between the OpenSSH service file and the system directory. During the boot process, the operating system scans it's system directory and automatically launches all service files with a symbolic link.

:::

## 2. Enable SSH Startup

If the SSH service is not enabled, we can enable the automated OpenSSH startup during the boot process.

```sh
sudo systemctl enable ssh
```

:::info

After running this command, the `systemd` daemon will create the required symbolic link in the system directory.

:::

---

// File: guides/system-setup/firewall-configuration

# 3.6 Firewall Configuration

A properly configured firewall is essential for protecting your node from unwanted network access while allowing legitimate traffic, such as remote SSH connections. In this section, we will configure an firewall to secure your node by restricting incoming connections, enabling SSH over a specified TCP port, and managing firewall rules.

:::info Uncomplicated Firewall

The UFW is the name of a user-friendly command-line interface for managing firewall configurations on Linux systems. It simplifies configuring and maintaining a firewall by providing intuitive commands and options. UFW streamlines the process of setting up and managing firewall rules such as enforcing strict controls on incoming and outgoing network traffic.

:::

## 1. General Port Locking

The first step is to set up default rules. All outgoing traffic should be allowed because the node needs to send data out to the network. Conversely, all incoming traffic should be denied by default to block unwanted connection attempts.

```sh
sudo ufw default allow outgoing
sudo ufw default deny incoming
```

## 2. SSH Port Configuration

For secure remote access, you need to allow SSH connections through the firewall by opening the port. However, if you allow just the port number, both TCP and UDP protocol connections would be possible. By default, SSH only uses the TCP protocol, which is preferred due to its reliability and error-checking capabilities.

:::tip

Allow SSH connections on your desired port and replace `<desired-port-number>` with your actual port number.

:::

```sh
sudo ufw allow <desired-port-number>/tcp
```

:::info Internet Protocol Versioning

The Internet Protocol is responsible for identifying and locating network devices and routing traffic across the internet. If your node supports both `IPv4` and `IPv6`, `UFW` automatically manages rules for both protocols.

`IPv6` provides an expanded address space that helps accommodate the growing number of devices connected to the internet. On top, it has built-in security enhancements like encrypted communication. When you add a firewall rule, you might see confirmations for both `IPv4` and `IPv6`, ensuring comprehensive network protection.

:::

## 3. Firewall Checkup

After applying your firewall rules, you can verify their status. The changes take effect immediately, so there is no need to restart UFW manually.

**1. Verify whether the firewall is enabled**:

```sh
sudo systemctl is-enabled ufw
```

**2. Verify if the firewall is active and the rules are in place**:

```sh
sudo ufw status
```

**3. If the UFW is not enabled, activate the process**:

```sh
sudo ufw enable
```

Afterward, restart your node.

## 3. Port Rule Removal

If you need to modify the firewall rules, such as removing an unwanted port rule, you can list them all.

```sh
sudo ufw status
```

:::info

To `delete` a specific port rule using `UFW`, type the `<rule-number>` that is no longer required.

:::

```sh
sudo ufw delete <rule-number>
```

---

// File: guides/system-setup/bruteforce-protection

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 3.7 Bruteforce Protection

Bruteforce protection is a critical aspect of securing blockchain nodes and servers. As these systems handle sensitive data and valuable assets, they are prime targets for attackers attempting systematic login attempts. To mitigate such threats, we can use a security tool that monitors failed logins and automatically updates firewall rules.

:::tip

We'll install the famous security tool named `Fail2Ban`, that blocks offending IP addresses for a specified duration.

:::

## 1. Installation

First, we need to get the service installed using APT:

```sh
sudo apt install fail2ban
```

After the installation has been successful, we can continue its configuration.

## 2. Configuration

This sequence will add properties for the SSH daemon process. Protecting the SSH port on any blockchain node or server is recommended, as it is the only way to access our node.

:::info

The brutefore protection comes with separate configuration files:

- `/etc/fail2ban/jail.conf` : The updateble default configuration
- `/etc/fail2ban/jail.local`: An optional, static rules for each port and service

Its recommended to create the additional file, as those settings persist through any software updates.

:::

Open the configuration file in your preferred text editor:

<Tabs>
<TabItem value="vim" label="Vim" default>

```sh
sudo vim /etc/fail2ban/jail.local
```

</TabItem>
<TabItem value="nano" label="Nano">

```sh
sudo nano /etc/fail2ban/jail.local
```

</TabItem>
</Tabs>

Then, add the following configuration snippet to protect the SSH daemon:

```text
[sshd]
enabled=true
port=<desired-port-number>
filter=sshd
logpath=/var/log/auth.log
maxretry=3
findtime=300
bantime=28800
backend=auto
ignoreip=127.0.0.1/8
```

:::warning

Ensure there are no extra spaces between property names and their values to avoid syntax errors.

:::

:::note

Replace `<desired-port-number>` with the SSH port you configured for your node.

- **maxretry** = 3: Limits failed login attempts.
- **findtime** = 300: Specifies a time window of 5 minutes before failed attempts are reset.
- **bantime** = 28800: Bans an IP for 8 hours if the limit is exceeded.

:::

<details>
  <summary>Full Property Explanation</summary>

| **Option** | **Description**                                                                     | **Value**           |
| ---------- | ----------------------------------------------------------------------------------- | ------------------- |
| `[ ]`      | Tag for the service declaration.                                                    | `sshd`              |
| `enabled`  | Whether this rule is active when the SSH service is running.                        | `true`              |
| `port`     | Port number on which the SSH daemon listens.                                        | `22`                |
| `filter`   | Name of the filter definition used to parse log entries and detect failed attempts. | `sshd`              |
| `logpath`  | Full path to the log file to monitor for failed login attempts.                     | `/var/log/auth.log` |
| `maxretry` | Number of failed login attempts within the `findtime` window before banning the IP. | `3`                 |
| `findtime` | Time window in seconds during which `maxretry` failures are counted.                | `300`               |
| `bantime`  | Duration in seconds for which an IP is banned after exceeding `maxretry`            | `28800`             |
| `backend`  | Default backend type used to monitor the log file.                                  | `auto`              |
| `ignoreip` | Space‚Äëseparated list of IP addresses exempted from banning.                         | `127.0.0.1/8`       |

</details>

:::tip

Instead of just including the localhost range to the ignored IP addresses in order to avoid self‚Äëlockout, you can also append any trusted IP or VPN range if you are using a specific tunnel network.

:::

## 3. Startup

After configuring the brutefore protection for our SSH Port, we need to refresh our services to include newly set up rules.

**1. Reload the System Manager Configuration**: _Registers any new or updated service files._

```sh
sudo systemctl daemon-reload
```

**2. Start the Bruteforce Protection Tool**: _Launches the service file._

```sh
sudo systemctl start fail2ban
```

**3. Enable Automatic Startup**: _Creates a symbolic link to include the service in the boot process._

```sh
sudo systemctl enable fail2ban
```

**4. Verify Service Status**: _Checks the service's unit files, state, and log file._

```sh
sudo systemctl status fail2ban
```

The output should indicate that the service is active and running:

```text
‚óè fail2ban.service - Fail2Ban Service
     Loaded: loaded (/lib/systemd/system/fail2ban.service; enabled; vendor preset: enabled)
     Active: active (running) since [DATE]; [TIME] ago
       Docs: man:fail2ban(1)
   Main PID: 5875 (fail2ban-server)
      Tasks: 5 (limit: 38043)
     Memory: [USED_MEMORY]
        CPU: [EXECUTION_TIME]
     CGroup: /system.slice/fail2ban.service
             ‚îî‚îÄ5875 /usr/bin/python3 /usr/bin/fail2ban-server -xf start

[DATE] [USER] systemd[PID]: Started Fail2Ban Service.
[DATE] [USER] fail2ban-server[PID]: Server ready
```

---

// File: guides/router-setup/address-checkup

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 4.1 Address Checkup

Since many routers use different software, it‚Äôs important to know the device's network identifiers before setting up static access.

| **Name**                       | **Description**                                                                                                                                                                                                                      | **Example**         |
| ------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------- |
| <nobr> **IP Address** </nobr>  | Internet Protocol addresses are **logical, software‚Äëassigned** identifiers. IP addresses let routers move data packages between different networks, whether your local home network or across the Internet.                          | ` 192.168.1.10`     |
| <nobr> **MAC Address** </nobr> | The Media Access Control addresses are **permanent, globally-unique** identifiers built into each device's network interface. MAC addresses let switches and bridges forward data frames only within the same local network segment. | `00:1A:2B:3C:4D:5E` |

:::tip

Home networks typically assign dynamic IP addresses via DHCP, a protocol designed for automated device registering. Once a device boots, it requests and leases an IP address from the router‚Äôs DHCP address pool.

While DHCP eliminates the need for manual configuration and manages devices efficiently, it can cause the IP address to change over time once an assignment expired. For uninterrupted SSH access, its necessary to identify your node‚Äôs hardware address and set up reliable DHCP reservation or static assignment in your router.

:::

## 1. Resolve IP Address

<Tabs>
<TabItem value="local-ip" label="Local IP Check" default>

:::info

You can use the `ip` tool to display the system‚Äôs default package route and source IP when connecting to the router. The default gateway's IP address is the intermediate route the system takes when sending data to an IP address outside its local network.

:::

```sh
ip route show default
```

The output will look like this:

```sh
default via <GATEWAY_IP_ADDRESS> dev eno1 proto dhcp src <NODE_IP_ADDRESS> metric <ROUTING_WEIGHT>
```

</TabItem>
<TabItem value="public-ip" label="Public IP Check">

:::info

You can use the `ip` tool to query a stable external address like the Google DNS address `8.8.8.8` to reveal your source IP and further filter the IP parameter from the server's response using the text-processing tool `awk`.

:::

```sh
ip route get 8.8.8.8 | awk '{print $7}'
```

</TabItem>
</Tabs>

## 2. Resolve Hardware Address

:::info

You can list all network interfaces and their MAC addresses using the previously known `ip` command-line tool. Look for an interface name like `eno1` or `eth0`, typically used to broadcast information to the Internet using an Ethernet connection.

:::

```sh
ip link show
```

The entry should look like this:

```sh
<NETWORK_INFERFACE_NAME>: <BROADCAST,MULTICAST,UP,LOWER_UP> ...
    link/ether <MAC_ADDRESS> brd <BROADCAST_ADDRESS>
```

:::warning

Write down both **IP** and **MAC** addresses so you can **identify your node** while configuring your router.

:::

---

// File: guides/router-setup/static-ip-assignment

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 4.2 Static IP Assignment

Assigning a static IP or reserving your node‚Äôs existing DHCP lease prevents connectivity issues and simplifies router port forwarding, firewall rules, and remote access to your node. In this step, we will configure the router of the home network it is connected to.

:::note

Terminology and steps vary heavily depending on your router model. For help, refer to your router's documentation.

:::

:::info

The following steps are performed on your üíª **personal computer** that's connected to the same home network as the node.

:::

## 1. Address Reservation

To ensure your node always uses the same IP address, we'll reserve it on the router.

:::tip

If you want to assign a totally new IP address instead of reserving one, choose a free address within your router's IP address range but outside the scope of IP addresses that are automatically allocated by the DHCP server to prevent conflicts.

:::

**1.1 Log into Router‚Äôs Web Interface**: _Open a browser to your router‚Äôs IP or hostname, then enter your admin credentials._

:::note Fritzbox Router

Navigate to `http://192.168.178.1` to open the local user interface.

:::

**1.2 Locate DHCP or LAN Settings**: _Navigate to the router section of DHCP, Network Connectivity or LAN settings._

:::note Fritzbox Router

Navigate to `Home Network` > `Network` > `Network Connections`.

:::

**1.3 Open Device Settings**: _Find the device setting windows for your specific IP addresses._

:::note Fritzbox Router

Browse the device list to find you node's `IP` and `MAC` address. Hit `Edit` to open the reservation window.

:::

**1.4 Add a Reservation Rule**: _Find the IP assignment or reservation option for your device._

:::note Fritzbox Router

Within the device menu, select `General` > `Home Network` and enable `Permanent IPv4 address`.

:::

**1.5 Apply and Save**: _Apply the static IP rule to the DHCP service of the router._

:::note Fritzbox Router

On the bottom right side of the device menu, click `Apply`.

:::

After applying the changes, restartyour node for the automated IP assignment to take effect.

## 2. Address Verification

Once the node is back online, we can confirm if the IP matches your reservation:

<Tabs>
<TabItem value="local-ip" label="Local IP Check" default>

:::info

You can use the `ip` tool to display the system‚Äôs default package route and source IP when connecting to the router. The default gateway's IP address is the intermediate route the system takes when sending data to an IP address outside its local network.

:::

```sh
ip route show default
```

The output will look like this:

```sh
default via <GATEWAY_IP_ADDRESS> dev eno1 proto dhcp src <NODE_IP_ADDRESS> metric <ROUTING_WEIGHT>
```

</TabItem>
<TabItem value="public-ip" label="Public IP Check">

:::info

You can use the `ip` tool to query a stable external address like the Google DNS address `8.8.8.8` to reveal your source IP. You can further filter the IP parameter from the server's response using the text-processing tool `awk`.

:::

```sh
ip route get 8.8.8.8 | awk '{print $7}'
```

</TabItem>
</Tabs>

:::warning

If the IP differs, recheck your router‚Äôs reservation settings.

:::

## 3. Switch to Remote Connection

With a fixed IP in place, you can relocate the node into a server rack or shelf.

```sh
sudo shutdown now
```

:::info

Once the node is offline, disconnect the monitor, keyboard, as well as power and network cables. Once power is restored, your node will **automatically boot** through the configured [**BIOS Settings**](/docs/guides/hardware-setup/bios-setup.md) and should be reachable at its reserved IP address within 15‚Äì60 seconds.

:::

---

// File: guides/ssh-setup/initialization

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 5.1 Initialization

This page will cover your SSH client preparation for seamless access to your node. You will verify that SSH is installed on your personal computer, create a convenient host alias in your SSH configuration, and perform a test connection.

:::info

The following steps are performed on your üíª **personal computer**.

:::

## 1. Check SSH Installation

Before verifying basic access, we must check if SSH is already installed. Open the terminal and check your SSH client version:

```sh
ssh -V
```

You should see an output similar to:

```sh
OpenSSH_9.0p1, LibreSSL 3.3.6
```

:::warning

If SSH is not installed, follow your operating system‚Äôs documentation to install the latest OpenSSH client.

:::

## 2. Configure SSH

To avoid typing full connection details each time, define a host entry in the SSH config file.

:::info

The default SSH configuration file should be located at `~/.ssh/config`. The file is a user-specific SSH file to customize various settings for the SSH client on a per-host basis. It allows you to define different options for each remote host you connect to via SSH, such as hostname, username, port, identity files, and other preferences.

:::

**2.1 Create the Directory**: _Ensure that the SSH directory exists with proper permissions._

```sh
mkdir -p ~/.ssh/
chmod 700 ~/.ssh
```

:::info

You can use the `mkdir` command to create a directory. Adding the `p` flag will create any necessary parent directories.

:::

**2.2 Open the Configuration File**: _Open your SSH config file with your preferred text editor._

<Tabs>
<TabItem value="vim" label="Vim" default>

```sh
vim ~/.ssh/config
```

</TabItem>
<TabItem value="nano" label="Nano">

```sh
nano ~/.ssh/config
```

</TabItem>
</Tabs>

**2.3 Add the Node Connection**: _Add a host snippet for your node and replace placeholders._

```text
Host <ssh-device-alias>
  User <node-username>
  HostName <node-ip-address>
  Port <ssh-port>
```

:::info

- `<ssh-device-alias>`: a memorable short name
- `<node-username>`: your node‚Äôs administrative login user
- `<node-ip-address>`: your node‚Äôs static IP
- `<ssh-port>`: the custom SSH port you configured

:::

:::warning

Ensure each property line is indented by two spaces and safe the file.

:::

## 3. Trial Connection

Now verify the connection by opening the first connection to your node:

```sh
ssh <ssh-device-alias>
```

- onfirm the host fingerprint by typing yes.
- Enter your node password when prompted.

You should see the Ubuntu welcome banner:

```text
Welcome to Ubuntu 22.04.2 LTS [BUILD]

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

  System information as of [DATE]

  System load:           1.0
  Usage of /:            1.2% of 997.87GB
  Memory usage:          1%
  Swap usage:            0%
  Temperature:           36.0 C
  Processes:             219
  Users logged in:       0
  IPv4 address [Connection Type]: [IPv4 IP Address]
  IPv6 address [Connection Type]: [IPv6 IP Address]

[NEWS]

[SECURITY_NOTICES]

0 updates can be applied immediately.

[EMS_NOTICE]


Last login: [DATE] from [IP_FROM_PERSONAL_COMPUTER]
```

To end the session, run:

```sh
exit
```

:::warning

Always confirm you‚Äôve fully disconnected before continuing further terminal steps.

:::

---

// File: guides/ssh-setup/key-login

# 5.2 Key Login

Using SSH key authentication greatly enhances your node‚Äôs security by replacing password-based logins with cryptographic keys. In this section, you will generate and configure a authentication key to allow a more secure and passwordless login.

:::note Key Pair Usage

SSH keys use public‚Äëkey cryptography to authenticate without sending passwords over the network. You generate a private key, which will be kept secret, and a public key, that will be copied to the node. When you connect, the server challenges your client to prove you hold the private key‚Äîwithout ever exposing it. SSH key authentication is resistant to brute‚Äëforce attacks, since an attacker cannot guess your private key in the same way they could guess a password.

:::

## 1. Check for Existing Keys

Before creating a new key, you can check whether you already have one in the default SSH key directory.

:::info

By default, SSH keys are located in the `~/.ssh` directory. The file names of the keys will depend on their encryption type:

- RSA keys: `~/.ssh/id_rsa`
- ECDSA keys: `~/.ssh/id_ecdsa`
- Ed25519 keys: `~/.ssh/id_ed25519`

Use the `ls` command to list the contents of a directory and serach for all public key files ending on `.pub`.

:::

```sh
ls ~/.ssh/*.pub
```

:::tip

If you see `id_rsa.pub`, `id_ecdsa.pub`, or `id_ed25519.pub` keys, you could reuse an existing key. However, best practice is to generate a separate key pair for each service to limit exposure if one key is compromised.

:::

## 2. Generate Key Pair

:::tip

You could alternatively consider generating a **hardware token** instead of generating a regular key file for maximum security. Such USB devices store your private key physically and must be plugged into the computer for a secure connection, protected from digital piracy.

Great examples would be üü° [**YubiKey**](https://developers.yubico.com/SSH/Securing_SSH_with_FIDO2.html) or other devices like üî≤ [**Ledger**](https://support.ledger.com/article/115005198545-zd) supporting üë§ [**FIDO U2F**](https://fidoalliance.org/).

:::

:::info

The following steps are performed on your üíª **personal computer**.

:::

To create a new key, we can use the SSH Key Generation Tool. It is a widely used and integral part of the OpenSSH suite to generate, manage, and convert SSH public and private key pairs. First, we must decide which type of key to generate:

| Key Type | Security  | Efficiency | Compatibility        | Size  |
| -------- | --------- | ---------- | -------------------- | ----- |
| RSA      | Very High | Slower     | Widely supported     | Large |
| ECDSA    | High      | Fast       | Moderately supported | Small |
| Ed25519  | Very High | Very fast  | Mostly supported     | Small |

RSA is generally recommended for its strong security and wide compatibility.

**2.1 Create a new key pair**:

```sh
ssh-keygen -t rsa -b 4096
```

<details>
    <summary>Full Property Explanation</summary>

| **Option** | **Description**                                                                                                                                                                                                                        | **Value** |
| ---------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------- |
| `-t`       | Specifies the cryptographic key type.                                                                                                                                                                                                  | `rsa`     |
| `-b`       | Specifies the number of bits in the key. A higher number of bits usually results in better security. The default key length for RSA keys is `2048` bits, but using a `4096` bits provides contemporary security for a blockchain node. | `4096`    |

</details>

**2.2 Enter file directory, name, and passphrase**:

```sh
/Users/<your-username>/.ssh/<your-chosen-keyname>
```

:::tip

Setting a passphrase is highly recommended for extra protection. This will mean you will be prompted to enter an additional password each time you connect to your node. The passphrase setup can be skipped by pressing _Enter_.

:::

:::warning

Never share or expose your private key. Treat it as your highest‚Äëvalue secret.

:::

## 3. Set Key Permissions

After its generation, set strict permissions to protect your private key:

```sh
chmod 600 ~/.ssh/<your-chosen-keyname>
```

:::info

The command `chmod 600` sets the permissions of your private key file so that only the owner can read and write into it. Without this restriction, anyone with access to your system could potentially misuse your private key.

:::

## 4. Create Key Backup

Generate a backup before setting up the node authentication, otherwise you might not be able to remotely access your node. It's crucial to ensure the key is safety stored, especially while traveling or when your device may be damaged or lost.

| **Precaution** | **Description**                                                                                                                                                                                                                        |
| -------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Backup**     | Always create a backup and store it in a secure and separate location like an encrypted USB drive or a cloud.                                                                                                                          |
| **Encryption** | Protect your private key with a strong passphrase or create an encrypted archive of the file to add an extra layer of security before the key can be used, even if someone gains access to the machine, USB drive, or cloud container. |

After backing up the generated key, we can continue using it in production.

## 5. Transfer Public Key

Install your public key on the node for passwordless login:

```sh
ssh-copy-id -i ~/.ssh/<your-chosen-keyname>.pub <ssh-device-alias>
```

:::info

Exchange `<your-chosen-keyname>` and `<ssh-device-alias>` with your generated key's file path and node's SSH alias.

:::

You will be prompted for your node‚Äôs password one last time. Afterward, this should be your final output:

```sh
Number of key(s) added:        1
```

## 6. Key Verification

Test to log into your node only using the newly deployed key:

```sh
ssh <ssh-device-alias>
```

You should connect without entering your node password.

:::info

The following steps are performed on your üìü **node server**.

:::

Ensure your public key file got added to the list of authorized keys:

```sh
ls -al ~/.ssh/authorized_keys
```

---

// File: guides/ssh-setup/authentication

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 5.3 Authentication

In this section, you will lock down SSH on the node to accept only key‚Äëbased logins. We will adjust the config file, test that password logins are disabled, and update your personal computer's configuration file to include your private key for automated authentication.

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Enable Secure Authentication

**1.1 Open the Configuration File**: _Open the SSH daemon's file with your preferred text editor._

<Tabs>
<TabItem value="vim" label="Vim" default>

```sh
sudo vim /etc/ssh/sshd_config
```

</TabItem>
<TabItem value="nano" label="Nano">

```sh
sudo nano /etc/ssh/sshd_config
```

</TabItem>
</Tabs>

**1.2 Locate the Settings**: _Search for specific setting entries that are inactive by default._

```text
#PermitRootLogin prohibit-password

#PubkeyAuthentication yes

#AuthorizedKeysFile .ssh/authorized_keys ./ssh/authored_keys2

#PasswordAuthentication yes
#PermitEmptyPasswords no

#KbdInteractiveAuthentication no
```

<details>
    <summary>Full Property Explanation</summary>

| **Directive**                | **Description**                                          | **Value**            |
| ---------------------------- | -------------------------------------------------------- | -------------------- |
| PermitRootLogin              | Allows root login by public‚Äëkey only, not by password.   | prohibit-password    |
| PubkeyAuthentication         | Enables authentication with authorized public keys.      | yes                  |
| AuthorizedKeysFile           | Specifies the single file to read for valid public keys. | .ssh/authorized_keys |
| PasswordAuthentication       | Disables login with a password entirely.                 | no                   |
| PermitEmptyPasswords         | Ensures accounts with blank passwords cannot log in.     | no                   |
| KbdInteractiveAuthentication | Disables challenge‚Äìresponse authentication methods.      | no                   |

</details>

**1.3 Update the Settings**: _Uncomment the entries and change their values._

- Remove any leading _#_ to uncomment each line.
- Set _PasswordAuthentication_ no.
- Ensure only the first _AuthorizedKeysFile_ entry remains.

**1.4 Verify the Changes**: _Check for spelling mistakes or unneeded spaces._

```text
PermitRootLogin prohibit-password
...
PubkeyAuthentication yes
...
AuthorizedKeysFile .ssh/authorized_keys
...
PasswordAuthentication no
PermitEmptyPasswords no
...
KbdInteractiveAuthentication no
```

**1.5 Save and Exit**: _Apply changes and close the file._

**1.6 Test the new Configuration**: _Validate your file changes using the SSH daemon. A blank output indicates no syntax errors._

```sh
sudo sshd -t
```

:::danger

Testing is crucial as you cannot use the regular password login after applying the changes on the main service.

:::

**1.7 Restart the Service**: _Restart the running SSH daemon for the new adjustments to take effect._

```sh
sudo systemctl restart sshd
```

**1.8 Log Out of the Node**: _Exit the node's terminal and SSH session._

```sh
exit
```

## 2. Testing Password Login

:::info

The following steps are performed on your üíª **personal computer**.

:::

Attempt to SSH with your user password to confirm it is now disabled:

```sh
ssh <ssh-device-alias>
```

:::info

Exchange `<ssh-device-alias` with your actual SSH device name of the node.

:::

You should see:

```sh
ssh: connect to host <ssh-device-alias> port 22: Connection refused
```

:::warning

If you can still log in with a password, verify your configuration file again.

:::

## 3. Update SSH Login Key

To connect to your node again, we need to add the previously generated SSH key to the SSH client.

**3.1 Open the Configuration File**: _Open the SSH client's file with your preferred text editor._

<Tabs>
<TabItem value="vim" label="Vim" default>

```sh
vim ~/.ssh/config
```

</TabItem>
<TabItem value="nano" label="Nano">

```sh
nano ~/.ssh/config
```

</TabItem>
</Tabs>

**3.2 Add the Identity Reference**: _Under the host block of your node, add your private key._

```text
  IdentityFile ~/.ssh/<chosen-keyname>
```

:::info

Ensure that your `IdentityFile` points to your private `<chosen-keyname>` without the `.pub` extension behind its name.

:::

The final host block should look like this:

```text
Host <ssh-device-alias>
  User <node-username>
  HostName <node-ip>
  Port <ssh-port>
  IdentityFile ~/.ssh/<chosen-keyname>
```

:::info

- `<ssh-device-alias>`: your nodes SSH device name
- `<node-username>`: your node's username
- `<node-ip-address>`: your node's static IP address
- `<ssh-port>`: your opened port number
- `<chosen-keyname>`: your SSH key

:::

**3.3 Save and Exit**: _Apply changes and close the file._

## 4. Testing Key Login

Now connect using your SSH alias:

```sh
ssh <ssh-device-alias>
```

After entering the correct passphrase, you will end up on the Ubuntu server welcoming printout.

:::info

Instead, of the password promt, the SSH client should ask to encrypt the private key with the passphrase.

:::

:::tip

If you did not set up any password for the key, you will connect automatically.

:::

---

// File: guides/client-setup/firewall-settings

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 6.1 Firewall Settings

A tightly controlled firewall lets your node participate in peer-to-peer networks while blocking unsolicited traffic. This page lists the mandatory ports for each supported blockchain client of the LUKSO network, followed by firewall commands to open their communication channels and check current their current status.

:::tip

Please ensure you have a basic understanding of blockchain networks before operating a node. If you're not yet familiar with [**Proof of Stake**](/docs/theory/blockchain-knowledge/proof-of-stake.md), [**Tokenomics**](/docs/theory/blockchain-knowledge/tokenomics.md), [**Panelties**](/docs/theory/blockchain-knowledge/slashing-and-panelties.md), [**Client Types**](/docs/theory/blockchain-knowledge/client-types.md) or [**Client Providers**](/docs/theory/blockchain-knowledge/client-providers.md), please refer to the üß† [**Theory**](/docs/theory/blockchain-knowledge/proof-of-stake.md) section.

:::

## 1. Open Network Ports

Your node needs specific inbound ports open so that execution and consensus clients can exchange blocks, transactions, and peer‚Äëdiscovery messages. Below is a list of the TCP and UDP ports each client uses. By opening these ports on your node‚Äôs firewall, you ensure that your client stays in sync and reachable by the wider network.

:::info

Consensus clients rely on broad outbound connectivity to discover other nodes, meaning only inbound traffic will be restricted.
:::

| PORT  | CLIENT                                                          | DESCRIPTION                        | TCP | UDP |
| ----- | --------------------------------------------------------------- | ---------------------------------- | --- | --- |
| 30303 | [Geth] ‚Üó <br />[Erigon] ‚Üó <br /> [Nethermind] ‚Üó <br /> [Besu] ‚Üó | Execution Chain Data & Discovery   | ‚úîÔ∏è  | ‚úîÔ∏è  |
| 9000  | [Lighthouse] ‚Üó <br /> [Teku] ‚Üó <br /> [Nimbus-Eth2] ‚Üó <br />    | Beacon Gossip & Data               | ‚úîÔ∏è  | ‚úîÔ∏è  |
| 13000 | [Prysm] ‚Üó                                                       | Beacon Gossip, Requests, Responses | ‚úîÔ∏è  |     |
| 12000 | [Prysm] ‚Üó                                                       | Beacon Discovery, Data Exchange    |     | ‚úîÔ∏è  |

:::tip

Clients use extra ports for monitoring, which don't need firewall exposure. Check the [**Monitoring**](/docs/guides/monitoring/port-configuration.md) chapter for details.

:::

## 2. Configure Firewall

You can apply the specific port settings to your firewall.

:::info

The following step is performed on your üíª **personal computer**.

:::

**2.1 Node Connection**: _Log in to your node if you are not already connected._

```sh
ssh <ssh-device-alias>
```

:::info

The following steps are performed on your üìü **node server**.

:::

**2.2 Add Port Rules**: _Allow the TCP and UDP ports depending on which clients you want to operate._

:::tip

You will have to chose one execution client and one consensus client.

- **Execution Clients**: Geth, Erigon, Nethermind, Besu
- **Consensus Clients**: Prysm, Lighthouse, Teku, Nimbus-Eth2

Further details about [**Client Types**](/docs/theory/blockchain-knowledge/client-types.md) and [**Client Providers**](/docs/theory/blockchain-knowledge/client-providers.md) can be found in the üß† [**Theory**](/docs/theory/blockchain-knowledge/proof-of-stake.md) section.

:::

<Tabs>
<TabItem value="execution" label="Geth, Erigon, Nethermind, Besu">

```sh
sudo ufw allow 30303/tcp
sudo ufw allow 30303/udp
```

</TabItem> <TabItem value="consensus" label="Lighthouse, Teku, Nimbus-Eth2">

```sh
sudo ufw allow 9000/tcp
sudo ufw allow 9000/udp
```

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
sudo ufw allow 13000/tcp
sudo ufw allow 12000/udp
```

</TabItem> 
</Tabs>

The output of each command should always show:

```sh
Rule added
Rule added (v6)
```

**2.3 Check Configuration**: _Verify the new firewall rules._

```sh
sudo ufw status
```

The output should look similar to this:

<Tabs>
<TabItem value="lh-teku-nimbus" label="Execution Client + Lighthouse, Teku, or Nimbus-Eth2">

```text
Status: active

To                               Action      From
--                               ------      ----
<preferred-ssh-port>/tcp         ALLOW       Anywhere
30303/tcp                        ALLOW       Anywhere
30303/udp                        ALLOW       Anywhere
9000/tcp                         ALLOW       Anywhere
<preferred-ssh-port>/tcp (v6)    ALLOW       Anywhere (v6)
30303/tcp (v6)                   ALLOW       Anywhere (v6)
30303/udp (v6)                   ALLOW       Anywhere (v6)
9000/tcp (v6)                    ALLOW       Anywhere (v6)
```

</TabItem> 
<TabItem value="prysm" label="Execution Client + Prysm">

```text
Status: active

To                               Action      From
--                               ------      ----
<preferred-ssh-port>/tcp         ALLOW       Anywhere
30303/tcp                        ALLOW       Anywhere
30303/udp                        ALLOW       Anywhere
13000/tcp                        ALLOW       Anywhere
12000/udp                        ALLOW       Anywhere
<preferred-ssh-port>/tcp (v6)    ALLOW       Anywhere (v6)
30303/tcp (v6)                   ALLOW       Anywhere (v6)
30303/udp (v6)                   ALLOW       Anywhere (v6)
13000/tcp (v6)                   ALLOW       Anywhere (v6)
12000/udp (v6)                   ALLOW       Anywhere (v6)
```

</TabItem> 
</Tabs>

:::info

The `<preferred-ssh-port>` property will be exchanged with your actual SSH port.

:::

:::warning

If something is missing, retry to apply the above rules or have a look into the [firewall configuration](/docs/guides/system-setup/firewall-configuration.md) for further details.

:::

:::tip

If all required ports are featured with the `ALLOW` property, your node‚Äôs local firewall is correctly configured. To expose these ports at the network level, you will have to proceed to configure the router‚Äôs port forwarding rules.

:::

If you need to modify the firewall rules, such as removing an unwanted port rule, you can list them all.

```sh
sudo ufw status
```

:::info

To `delete` a specific port rule using `UFW`, type the `<rule-number>` that is no longer required.

:::

```sh
sudo ufw delete <rule-number>
```

[Geth]: https://github.com/ethereum/go-ethereum#configuration
[Erigon]: https://github.com/ledgerwatch/erigon#default-ports-and-firewalls
[Nethermind]: https://www.quicknode.com/guides/infrastructure/node-setup/how-to-run-nethermind-node#firewall-configuration
[Besu]: https://besu.hyperledger.org/stable/public-networks/how-to/connect/configure-ports#:~:text=To%20enable%20Prometheus%20to%20access,defaults%20are%209545%20and%209001%20.
[Lighthouse]: https://lighthouse-book.sigmaprime.io/faq.html?highlight=9000#do-i-need-to-set-up-any-port-mappings
[Prysm]: https://docs.prylabs.network/docs/prysm-usage/p2p-host-ip#configure-your-firewall
[Teku]: https://docs.teku.consensys.io/how-to/find-and-connect/improve-connectivity#configure-ports
[Nimbus-Eth2]: https://nimbus.guide/networking.html

---

// File: guides/client-setup/router-port-arrangement

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 6.2 Router Port Arrangement

To expose your node‚Äôs open ports to the internet, you must forward them on your home router. This allows external peers to connect through your network‚Äôs public IP and reach your node‚Äôs static IP and ports.

:::tip

Additionally to opening the router ports, you must configure the [**Firewall Settings**](./firewall-settings.md) of your node to allow data throughput.

:::

:::info

You will have to know both **IP** and **MAC** addresses from the [**Router Setup**](/docs/guides/router-setup/address-checkup) to identify your node while configuring the router.

:::

## 1. Log into the Router

In a browser, navigate to your router‚Äôs admin interface and log into your router's dashboard with its admin credentials.

:::info

The following steps are performed on your üíª **personal computer**.

:::

:::note

Router interfaces are typically located at [`192.168.0.1`](https://192.168.0.1/), [`192.168.1.1`](https://192.168.1.1/) or [`192.168.178.1`](http://192.168.178.1/).

:::

## 2. Add Port Forwarding Rules

**2.1 Navigate to Port Forwarding**: _In your router's web interface, navigate to the firewall or port forwarding settings._

:::note Fritzbox Router

Navigate to `Internet` > `Permit Access` > `Port Sharing`

:::

**2.2 Select the Device**: _Select or configure your node device to create new port forwarding rules._

:::note Fritzbox Router

`Port Sharing` > `Add Device for Sharing`

:::

```text
---------------------------------------------------------------------------------
| DEVICE:               <device-name>                                           |
| IPV4 ADDRESS:         <ip-address>                                            |
| MAC ADDRESS:          <mac-address>                                           |
| IPV6 INTERFACE ID:    <ipv6-interface-id>     (assigned automatically)        |
---------------------------------------------------------------------------------
| ‚ñ° Permit independent port sharing for this device                             |
---------------------------------------------------------------------------------
| IPV4                                                                          |
| ‚ñ° Open this device completely for internet sharing via IPv4 (exposed host)    |
---------------------------------------------------------------------------------
| IPv6                                                                          |
| Enable PING6                                                                  |
| Open firewall for delegated IPv6 prefixes of this device                      |
| Open this device completely for internet sharing via IPv6 (exposed host)      |
---------------------------------------------------------------------------------
```

:::info

The `<device-name>`, `<ip-address>`, `<mac-address>`, and `<ipv6-interface-id>` will reflect your node's properies.

:::

**2.3 Add Execution Port Forwarding Rules**: _Set multiple port access rules for UDP and TCP connections._

```text
RULE 1
        -------------------------------------------------------------------------
        | NAME:                         execution-tcp-30303                     |
        | PROTOCOL:                     TCP                                     |
        | PORT TO DEVICE:               30303   THROUGH PORT:       3030        |
        | PORT REQUESTED EXTERNALLY:    30303                                   |
        | (IPv4 only)                                                           |
        -------------------------------------------------------------------------
        | ‚ä† Enable sharing                                                      |
        -------------------------------------------------------------------------
        | IPV4 ADDRESS IN THE INTERNET: <internet-ip-address>                   |
        | PORT ASSIGNED EXTERNALLY:     30303   THROUGH PORT:       3030        |
        -------------------------------------------------------------------------
```

```text
RULE 2
        -------------------------------------------------------------------------
        | NAME:                         execution-udp-30303                     |
        | PROTOCOL:                     UDP                                     |
        | PORT TO DEVICE:               30303   THROUGH PORT:       3030        |
        | PORT REQUESTED EXTERNALLY:    30303                                   |
        | (IPv4 only)                                                           |
        -------------------------------------------------------------------------
        | ‚ä† Enable sharing                                                      |
        -------------------------------------------------------------------------
        | IPV4 ADDRESS IN THE INTERNET: <internet-ip-address>                   |
        | PORT ASSIGNED EXTERNALLY:     30303   THROUGH PORT:       3030        |
        -------------------------------------------------------------------------
```

<details>
    <summary>Full Property Explanation</summary>

| **Setting**    | **Description**                                                       |
| -------------- | --------------------------------------------------------------------- |
| Service Name   | A label to categorize and find the forwarding rule.                   |
| External Port  | The port number for incoming traffic.                                 |
| Port to Device | Port on your device to handle traffic, usually same as external port. |
| Protocol       | Indicator if the network protocol is TCP, UDP, or both.               |

</details>

**2.4 Add Consensus Port Forwarding Rules**: _Set multiple port access rules for UDP and TCP connections._

<Tabs>
<TabItem value="execution" label="Lighthouse, Teku, or Nimbus-Eth2">

```text
RULE 3
        -------------------------------------------------------------------------
        | NAME:                         consensus-tcp-9000                      |
        | PROTOCOL:                     TCP                                     |
        | PORT TO DEVICE:               9000   THROUGH PORT:       9000         |
        | PORT REQUESTED EXTERNALLY:    9000                                    |
        | (IPv4 only)                                                           |
        -------------------------------------------------------------------------
        | ‚ä† Enable sharing                                                      |
        -------------------------------------------------------------------------
        | IPV4 ADDRESS IN THE INTERNET: <internet-ip-address>                   |
        | PORT ASSIGNED EXTERNALLY:     9000   THROUGH PORT:       9000         |
        -------------------------------------------------------------------------
```

```text
RULE 4
        -------------------------------------------------------------------------
        | NAME:                         consensus-udp-9000                      |
        | PROTOCOL:                     UDP                                     |
        | PORT TO DEVICE:               9000   THROUGH PORT:       9000         |
        | PORT REQUESTED EXTERNALLY:    9000                                    |
        | (IPv4 only)                                                           |
        -------------------------------------------------------------------------
        | ‚ä† Enable sharing                                                      |
        -------------------------------------------------------------------------
        | IPV4 ADDRESS IN THE INTERNET: <internet-ip-address>                   |
        | PORT ASSIGNED EXTERNALLY:     9000   THROUGH PORT:       9000         |
        -------------------------------------------------------------------------
```

</TabItem> 
<TabItem value="prysm" label="Prysm">

```text
RULE 3
        -------------------------------------------------------------------------
        | NAME:                         consensus-tcp-13000                     |
        | PROTOCOL:                     TCP                                     |
        | PORT TO DEVICE:               13000   THROUGH PORT:       13000       |
        | PORT REQUESTED EXTERNALLY:    13000                                   |
        | (IPv4 only)                                                           |
        -------------------------------------------------------------------------
        | ‚ä† Enable sharing                                                      |
        -------------------------------------------------------------------------
        | IPV4 ADDRESS IN THE INTERNET: <internet-ip-address>                   |
        | PORT ASSIGNED EXTERNALLY:     13000   THROUGH PORT:       13000       |
        -------------------------------------------------------------------------
```

```text
RULE 4
        -------------------------------------------------------------------------
        | NAME:                         consensus-udp-12000                     |
        | PROTOCOL:                     UDP                                     |
        | PORT TO DEVICE:               12000   THROUGH PORT:       12000       |
        | PORT REQUESTED EXTERNALLY:    12000                                   |
        | (IPv4 only)                                                           |
        -------------------------------------------------------------------------
        | ‚ä† Enable sharing                                                      |
        -------------------------------------------------------------------------
        | IPV4 ADDRESS IN THE INTERNET: <internet-ip-address>                   |
        | PORT ASSIGNED EXTERNALLY:     12000   THROUGH PORT:       12000       |
        -------------------------------------------------------------------------
```

</TabItem> 
</Tabs>

<details>
    <summary>Full Property Explanation</summary>

| **Setting**    | **Description**                                                       |
| -------------- | --------------------------------------------------------------------- |
| Service Name   | A label to categorize and find the forwarding rule.                   |
| External Port  | The port number for incoming traffic.                                 |
| Port to Device | Port on your device to handle traffic, usually same as external port. |
| Protocol       | Indicator if the network protocol is TCP, UDP, or both.               |

</details>

**2.5 Apply Forwarding Rules**: _Save each rule and apply changes._

## 3. Verify Open Ports

Check back to your port sharing screen of the router to find a list with all added rules.

<Tabs>
<TabItem value="execution" label="Execution Client + Lighthouse, Teku, or Nimbus-Eth2">

```text
DEVICE SCREEN

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
| DEVICE / NAME      | IP ADDRESS          | SHARING                           | PORT ASSIGNED EXTERNALLY IPV4 | PORT ASSIGNED EXTERNALLY IPC6 | INDIPENDENT PORT SHARING |
|--------------------|---------------------|-----------------------------------|-------------------------------|-------------------------------|--------------------------|
| <device-name>      | <ip-address>        | active: execution-tcp-30303       | 30303                         |                               | ‚ñ°                        |
|                    | <ipv6-interface-id> | active: consensus-tcp-9000        | 9000                          |                               | 0 enabled                |
|                    |                     | active: consensus-udp-9000        | 9000                          |                               |                          |
|                    |                     | active: execution-udp-30303       | 30303                         |                               |                          |
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
```

```text
PORT RULES SCREEN

---------------------------------------------------------------------------------------------------------
| STATUS | NAME                      | PROTOCOL | IP ADDRESS IN THE INTERNET | PORT ASSIGNED EXTERNALLY |
|--------|---------------------------|----------|----------------------------|--------------------------|
| active | execution-tcp-30303       | TCP      | <internet-ip-address>      | 30303                    |
| active | consensus-tcp-9000        | TCP      | <internet-ip-address>      | 9000                     |
| active | consensus-udp-9000        | UDP      | <internet-ip-address>      | 9000                     |
| active | execution-udp-30303       | UDP      | <internet-ip-address>      | 30303                    |
---------------------------------------------------------------------------------------------------------
```

</TabItem> 
<TabItem value="prysm" label="Execution Client + Prysm">

```text
DEVICE SCREEN

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
| DEVICE / NAME      | IP ADDRESS          | SHARING                           | PORT ASSIGNED EXTERNALLY IPV4 | PORT ASSIGNED EXTERNALLY IPC6 | INDIPENDENT PORT SHARING |
|--------------------|---------------------|-----------------------------------|-------------------------------|-------------------------------|--------------------------|
| <device-name>      | <ip-address>        | active: execution-tcp-30303       | 30303                         |                               | ‚ñ°                        |
|                    | <ipv6-interface-id> | active: consensus-tcp-13000       | 13000                         |                               | 0 enabled                |
|                    |                     | active: consensus-udp-12000       | 12000                         |                               |                          |
|                    |                     | active: execution-udp-30303       | 30303                         |                               |                          |
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
```

```text
PORT RULES SCREEN

---------------------------------------------------------------------------------------------------------
| STATUS | NAME                      | PROTOCOL | IP ADDRESS IN THE INTERNET | PORT ASSIGNED EXTERNALLY |
|--------|---------------------------|----------|----------------------------|--------------------------|
| active | execution-tcp-30303       | TCP      | <internet-ip-address>      | 30303                    |
| active | consensus-tcp-13000       | TCP      | <internet-ip-address>      | 13000                    |
| active | consensus-udp-12000       | UDP      | <internet-ip-address>      | 12000                    |
| active | execution-udp-30303       | UDP      | <internet-ip-address>      | 30303                    |
---------------------------------------------------------------------------------------------------------
```

</TabItem> 
</Tabs>

:::info

It might take a few seconds until port sharing rules are applied, some routers even require a reboot.

:::

---

// File: guides/client-setup/lukso-cli-installation

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 6.3 LUKSO CLI Installation

The [LUKSO CLI](https://github.com/lukso-network/tools-lukso-cli) is a unified command-line tool for installing, configuring, and running all officially supported execution and consensus clients on the LUKSO network with additional utility. It simplifies multi-client management by generating a single working directory with separate configs per network. This section explains, how to install and configure the LUKSO CLI to manage your blockchain clients and validators.

:::tip

Please ensure you have a basic understanding of blockchain networks before operating a node. If you're not yet familiar with [**Proof of Stake**](/docs/theory/blockchain-knowledge/proof-of-stake.md), [**Tokenomics**](/docs/theory/blockchain-knowledge/tokenomics.md), [**Panelties**](/docs/theory/blockchain-knowledge/slashing-and-panelties.md), [**Client Types**](/docs/theory/blockchain-knowledge/client-types.md) or [**Client Providers**](/docs/theory/blockchain-knowledge/client-providers.md), please refer to the üß† [**Theory**](/docs/theory/blockchain-knowledge/proof-of-stake.md) section.

:::

:::note Platform Support

The [LUKSO CLI](https://github.com/lukso-network/tools-lukso-cli) is officially supported on Mac, Ubuntu, and Debian with the following architectures:

- `x86` and `x86_64`: Intel and AMD Processors
- `ARM` and `aarch64`: Silicon or Single-Board Processors

:::

:::note Flags and Runtime

The clients started from the CLI run in the `/usr/local/bin` directory of the operating system:

- All client flags and additional configurations can be passed down to the services.
- The CLI is bound to the operating system, meaning only a single node can be operated on one device.

:::

:::tip

If you want to use üê≥ [**Docker**](https://github.com/lukso-network/network-docker-containers) or manual configuration, have a look at the [**Client Setups**](/docs/theory/node-operation/client-setups.md) page in the üß† [**Theory**](/docs/theory/blockchain-knowledge/proof-of-stake.md) section.

:::

## 1. Install the LUKSO CLI

Download and run the official installation script.

:::info

The following steps are performed on your üìü **node server**.

:::

```sh
sudo curl https://install.lukso.network | sh
```

:::note

The executable files of the `lukso` service will be downloaded to the `/usr/local/bin/lukso` directory.

:::

## 2. Create a Working Directory

Choose a directory to house all node data and configs.

**2.1 Access the Home Directory**: _It's recommended to place all blockchain data in the home environment._

```sh
cd
```

**2.2 Create a Node Folder**: _Choose a directory to house all blockchain, configuration, and node data._

:::info

Replace `<lukso-working-directory>` with a specific name for your node folder.

:::

```sh
mkdir <lukso-working-directory>
```

**2.3 Navigate into the Folder**: _Move into the working directory to initialize your node clients._

```sh
cd ./<lukso-working-directory>
```

## 3. Initialize the Working Directory

Using the LUKSO CLI, you can download all dependencies and configuration files for all network types with one initialization.

:::info

The `init` command generates a `cli-config.yaml` file and a `config` folder within the node directory, containing the genesis files, network properties, and client-specific configurations for the bootnodes of the related LUKSO networks.

:::

:::tip

To learn about bootnodes and the architecture, have a look at the [**Peer Networks**](/docs/theory/blockchain-knowledge/peer-networks.md) page in the üß† [**Theory**](/docs/theory/blockchain-knowledge/proof-of-stake.md) section.

:::

```sh
lukso init
```

:::note

When asked to add your _public IP address_ to the configuration file to improve connectivity, you can decline for now. Your public IP address may change frequently, depending on your internet provider, even if you've previously [assigned a static IP](/docs/guides/router-setup/static-ip-assignment.md) on the router level. While adding your IP is a temporary improvement, this setting is overwritten once [setting up a dynamic DNS](/docs/guides/modifications/dynamic-dns.md) for stable and long-term connectivity without ongoing maintenance.

:::

:::info

During setup, a file named `jwt.hex` is created at at `./configs/shared/secrets/`. The [**JSON Web Token**](https://en.wikipedia.org/wiki/JSON_Web_Token) key will be used to sign and verify the communication between the execution and consensus client of your node.

:::

:::note Folder Structure

The configuration folder will have separate folders for the mainnet and testnet networks.

```text
lukso-node
‚îÇ
‚îú‚îÄ‚îÄ‚îÄconfigs
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ[network]
‚îÇ   |   ‚îú‚îÄ‚îÄ‚îÄbesu                              // Config Files for Besu Client
‚îÇ   |   ‚îú‚îÄ‚îÄ‚îÄerigon                            // Config Files for Erigon Client
‚îÇ   |   ‚îú‚îÄ‚îÄ‚îÄgeth                              // Config Files for Geth Client
‚îÇ   |   ‚îú‚îÄ‚îÄ‚îÄlighthouse                        // Config Files for Lighthouse Client
‚îÇ   |   ‚îú‚îÄ‚îÄ‚îÄnethermind                        // Config Files for Nethermind Client
‚îÇ   |   ‚îú‚îÄ‚îÄ‚îÄnimbus2                           // Config Files for Nimbus-Eth2 Client
‚îÇ   |   ‚îú‚îÄ‚îÄ‚îÄprysm                             // Config Files for Prysm Client
‚îÇ   |   ‚îú‚îÄ‚îÄ‚îÄteku                              // Config Files for Teku Client
‚îÇ   |   ‚îî‚îÄ‚îÄ‚îÄshared
|   |       ‚îú‚îÄ‚îÄ‚îÄconfig.yaml                   // Global Client Config
|   |       ‚îú‚îÄ‚îÄ‚îÄdeploy_block.txt              // Block Deployment Number
|   |       ‚îú‚îÄ‚îÄ‚îÄdeploy_contract_block.txt     // Contract Deployment Number
|   |       ‚îú‚îÄ‚îÄ‚îÄgenesis.json                  // Genesis JSON Data
|   |       ‚îî‚îÄ‚îÄ‚îÄgenesis.ssz                   // Genesis Validator File
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄshared
‚îÇ       ‚îî‚îÄ‚îÄ‚îÄsecrets
‚îÇ           ‚îî‚îÄ‚îÄ‚îÄjwt.hex                       // Global Communication Secret
|
‚îî‚îÄ‚îÄ‚îÄcli-config.yaml                           // Global CLI Configuration
```

:::

## 4. Install Blockchain Clients

After the initialization of the node's working directory, you will be able to select which clients clients to run in the setup.

:::info

Clients will be installed globally at `/usr/local/bin/` and set as default within your working directory.

:::

:::tip

Please inform yourself about [**Client Providers**](/docs/theory/blockchain-knowledge/client-providers.md) and [**Client Diversity**](/docs/theory/blockchain-knowledge/client-diversity.md) to ensure your node's and the network stability.

:::

:::warning Staking Notice

If you want to run a validator and stake funds, choose between the `Prysm`, `Lighthouse`, or `Teku` consensus client.

:::

```sh
lukso install
```

Check if the clients were installed correctly using their version commands:

<Tabs>
<TabItem value="geth" label="Geth">

```sh
geth --version
```

</TabItem> 
<TabItem value="erigon" label="Erigon">

```sh
erigon --version
```

</TabItem> 
<TabItem value="nethermind" label="Nethermind">

```sh
nethermind --version
```

</TabItem> 
<TabItem value="besu" label="Besu">

```sh
besu --version
```

</TabItem> 
<TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
nimbus_beacon_node --version
```

</TabItem> 
<TabItem value="lighthouse" label="Lighthouse">

```sh
# Consensus Client
lighthouse --version

# Validator Client
lighthouse vc --version
```

</TabItem> 
<TabItem value="teku" label="Teku">

```sh
# Consensus Client
teku --version

# Validator Client
teku validator-client --version
```

</TabItem> 
<TabItem value="prysm" label="Prysm">

```sh
# Consensus Client
prysm --version

# Validator Client
prysm validator --version
```

</TabItem> 
</Tabs>

:::info

If you encounter errors during the download or checkups, re-do the installation process.

:::

## 5. Node Startup

Controlling the LUKSO CLI to start and stop your node can be done with easy commands and flags.

:::tip

As the LUKSO networks are running [since 2023](https://medium.com/lukso/genesis-validators-start-your-clients-fe01db8f3fba), synchronizing the full blockchain state of the network can take multiple days. Validators can utilize checkpoints to start staking with the minimum required state proofs, while the full data set is downloaded in the background. Using such checkpoints significantly reduces downtime and penalties when doing maintenance.

:::

| Synchronization Mode    | Initial Sync Time | Description                                                                                                                                                                                                                                                                             |
| ----------------------- | ----------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Regular Synchronization | 4 to 20 Hours     | - Dowloads the full data from genesis block using other peers <br /> - Must wait for complete download before validator is usable <br /> - Ideal for regular or archive nodes without staking                                                                                           |
| Automated Checkpoints   | 15 to 60 Minutes  | - Fetches the recently finalized checkpoint from an service endpoint <br /> - Back‚Äëfills historical blocks and data until genesis in the background <br /> - Quick start for fresh installs, migrations, or recovery for stakers <br /> - Relies on access to the public checkpoint API |
| Manual Checkpoints      | 15 to 60 Minutes  | - Operator inputs flags and entry values manually via client flags <br /> - Back‚Äëfills historical blocks and data until genesis in the background <br /> - Quick start for fresh installs, migrations, or recovery for stakers <br /> - Risk of stale or mistyped checkpoint values     |

:::warning

_Automated Checkpoints_ are only available in the [LUKSO CLI](https://github.com/lukso-network/tools-lukso-cli) from version¬†`0.8` and above.

:::

<Tabs>
<TabItem value="regular-sync" label="Regular Synchronization">

```sh
# Starting the Mainnet Node without Staking
lukso start

# Starting the Testnet Node without Staking
lukso start --testnet
```

</TabItem> 
<TabItem value="automated-checkpoints" label="Automated Checkpoints">

```sh
# Starting the Mainnet Node without Staking
lukso start --checkpoint-sync

# Starting the Testnet Node without Staking
lukso start --testnet --checkpoint-sync
```

</TabItem> 
<TabItem value="manual-checkpoints" label="Manual Checkpoints">

- Visit the [Mainnet Checkpoint Explorer](https://checkpoints.mainnet.lukso.network/) or [Testnet Checkpoint Explorer](https://checkpoints.testnet.lukso.network/)
- Pass the latest **Block Root** and **Epoch** values to the consensus client flags

<Tabs>
<TabItem value="lighthouse" label="Lighthouse">

```sh
# Starting the Mainnet Node without Staking
lukso start \
  --lighthouse-checkpoint-sync-url=https://checkpoints.mainnet.lukso.network \
  --lighthouse-genesis-state-url=https://checkpoints.mainnet.lukso.network \
  --lighthouse-wss-checkpoint=$<BLOCK_ROOT>:$<EPOCH>

# Starting the Testnet Node without Staking
lukso start --testnet \
  --lighthouse-checkpoint-sync-url=https://checkpoints.testnet.lukso.network \
  --lighthouse-genesis-state-url=https://checkpoints.testnet.lukso.network \
  --lighthouse-wss-checkpoint=$<BLOCK_ROOT>:$<EPOCH>
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
# Starting the Mainnet Node without Staking
lukso start \
  --teku-checkpoint-sync-url=https://checkpoints.mainnet.lukso.network \
  --teku-ws-checkpoint=$<BLOCK_ROOT>:$<EPOCH>

# Starting the Testnet Node without Staking
lukso start --testnet \
  --teku-checkpoint-sync-url=https://checkpoints.testnet.lukso.network \
  --teku-ws-checkpoint=$<BLOCK_ROOT>:$<EPOCH>
```

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
# Starting the Mainnet Node without Staking
lukso start \
  --prysm-checkpoint-sync-url=https://checkpoints.mainnet.lukso.network \
  --prysm-genesis-beacon-api-url=https://checkpoints.mainnet.lukso.network \
  --prysm-weak-subjectivity-checkpoint=$<BLOCK_ROOT>:$<EPOCH>

# Starting the Testnet Node without Staking
lukso start --testnet \
  --prysm-checkpoint-sync-url=https://checkpoints.testnet.lukso.network \
  --prysm-genesis-beacon-api-url=https://checkpoints.testnet.lukso.network \
  --prysm-weak-subjectivity-checkpoint=$<BLOCK_ROOT>:$<EPOCH>
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
# Starting the Mainnet Node without Staking
lukso start \
  --nimbus2-external-beacon-api-url=https://checkpoints.mainnet.lukso.network \
  --nimbus2-trusted-block-root=$<BLOCK_ROOT> \
  --nimbus2-weak-subjectivity-checkpoint=$<BLOCK_ROOT>:$<EPOCH>

# Starting the Testnet Node without Staking
lukso start --testnet \
  --nimbus2-external-beacon-api-url=https://checkpoints.testnet.lukso.network
  --nimbus2-trusted-block-root=$<BLOCK_ROOT> \
  --nimbus2-weak-subjectivity-checkpoint=$<BLOCK_ROOT>:$<EPOCH>
```

</TabItem> 
</Tabs>

:::info

Replace the `<BLOCK_ROOT>` and `<EPOCH>` placeholders with the current hash and number while keeping the `$` sign.

:::

</TabItem> 
</Tabs>

:::tip

Details about logging client outputs can be found on the [**Problem Scanning**](/docs/guides/maintenance/problem-scanning.md) page of the [**Maintenance**](/docs/guides/maintenance/software-updates.md) section.

:::

:::note Folder Structure

After starting the node once, new folders were added, storing the fetched blockchain data and logs of the related network.

```text
lukso-node
‚îÇ
‚îú‚îÄ‚îÄ‚îÄconfigs                                   // Configuration Files
‚îú‚îÄ‚îÄ‚îÄ[network]-logs                            // Network's Logged Status Messages
‚îú‚îÄ‚îÄ‚îÄ[network]-data                            // Network's Blockchain Data
‚îÇ   ‚îú‚îÄ‚îÄ‚îÄconsensus                             // Storage for used Consensus Client
‚îÇ   ‚îú‚îÄ‚îÄ‚îÄexecution                             // Storage for used Execution Client
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄvalidator                             // Storage for Validator Client
|
‚îî‚îÄ‚îÄ‚îÄcli-config.yaml                           // Global CLI Configuration
```

:::

## 6. Node Shutdown

Similar to initializing and starting the node from a working directory, you can stop all running clients at once.

```sh
# Stopping the Node
lukso stop
```

:::info

Ensure to stop the node before configuring the validator keys or apply further modifications within the next steps.

:::

---

// File: guides/client-setup/validator-configuration

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 6.4 Validator Configuration

After your [node setup](/docs/guides/client-setup/lukso-cli-installation.md) is working as intended, you can activate its staking functionality by importing your validator keys. Running a validator node means you're actively participating in the blockchain's consensus on top of providing a synchronized data peer of the network. The [LUKSO CLI](https://github.com/lukso-network/tools-lukso-cli) provides unified commands to manage staking for mainnet and testnet and various clients.

:::tip

Please ensure you have a basic understanding of blockchain networks and staking before running a validator node. If you're not yet familiar with [**Proof of Stake**](/docs/theory/blockchain-knowledge/proof-of-stake.md), [**Tokenomics**](/docs/theory/blockchain-knowledge/tokenomics.md), [**Slashing and Panelties**](/docs/theory/blockchain-knowledge/slashing-and-panelties.md), [**Validator Credentials**](/docs/theory/node-operation/validator-credentials.md) and [**Client Providers**](/docs/theory/blockchain-knowledge/client-providers.md), please refer to the üß† [**Theory**](/docs/theory/blockchain-knowledge/proof-of-stake.md) section.

:::

:::warning

Depending on if you are participating in the mainnet or testnet, running a validator requires 32 LYX or 32 LYXt per validator key. Ensure you have completed the [**Key Generation**](/docs/guides/validator-setup/wagyu-key-generation.md) and [**Deposit Process**](/docs/guides/validator-setup/launchpad-walkthrough.md) before importing keys.
:::

## 1. Transfer Validator Keys

Once you've completed the [validator setup](/docs/guides/validator-setup/precautions.md), you will be left with one or multiple folders containing the encrypted validator key files, depending on if you split the deposits or withdrawals to multiple wallets. These deposit files will first have to be sent from your personal computer to your node, before they can be imported into the consensus client.

:::tip SCP

The [Secure Copy Protocol](https://en.wikipedia.org/wiki/Secure_copy_protocol) is used for secure file transfers between hosts on a network. It operates over SSH, leveraging its authentication and encryption mechanisms to ensure both the authenticity and confidentiality of the data during transfer. SCP is a reliable choice for data transfers, offering secure transmission even over unsecured networks.

:::

Build and execute the entire command. You will be prompted to log in again before the process is started.

:::info

The following steps are performed on your üíª **personal computer**.

:::

```sh
scp -P <ssh-port> -i ~/.ssh/<ssh-key> -r <key-folder> <user-name>@<node-ip>:<lukso-working-directory>/<keyfolder>
```

:::warning

The command uses quite a few properties and flags. Replace all properties with specific values of your SSH and node configuration. Opening up a text editor before copying the contents into the terminal is recommended.

:::

| **Property**                              | **Description**                                        | **Retrieval**                                                                                                                                             |
| ----------------------------------------- | ------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr>`<ssh-key>`</nobr>                  | SSH key file used for authentication.                  | Run `ls ~/.ssh/` in your personal computer's terminal to list the files in the SSH folder and find the correct key file name for your node login.         |
| <nobr>`<key-folder>`</nobr>               | Local path to the keystore folder with validator keys. | Use your file explorer to locate the folder of your validator keys on your personal computer and right-click the folder and copy it's path.               |
| <nobr>`<ssh-port>` </nobr>                | The SSH port of your node.                             | Open the `~/.ssh/config` file using your preferred text editor on your personal computer and find the port that is used for the node's SSH communication. |
| <nobr>`<user-name>`</nobr>                | The SSH user for your node.                            | Open the `~/.ssh/config` file using your preferred text editor on your personal computer and find the admin user name for your node.                      |
| <nobr>`<node-ip>` </nobr>                 | The IP address of your node.                           | Open the `~/.ssh/config` file using your preferred text editor on your personal computer and find the host IP address of your node.                       |
| <nobr>`<lukso-working-directory>` </nobr> | The full path to your node's working directory.        | Use SSH to connect to your node, enter your node's working directory, and run the `pwd` command to get it's full path.                                    |
| <nobr>`<keyfolder>` </nobr>               | Name for the validator folder.                         | Define a name for the copied file's folder on your node, either the same as your personal computer or a new one.                                          |

:::tip

If you have multiple deposit folders, copy one folder at the time and perform this step several times.

:::

## 2. Import Validator Keys

Once all validator key files got transferred over, import your keys within the LUKSO CLI. You will be asked for the path of the previously defined name of the key folder.

:::warning

During the first import process, a new password for starting your validator node must be defined to secure the consensus client's wallet. Make sure to use a strong passphrase. It will be used to startup the staking process of your node.

:::

:::info

The following steps are performed on your üìü **node server**.

:::

<Tabs groupId="network-type">
  <TabItem value="mainnet" label="Mainnet" default>

```sh
lukso validator import --validator-keys "<lukso-working-directory>/<keyfolder>"
```

</TabItem> <TabItem value="testnet" label="Testnet">

```sh
lukso validator import --testnet --validator-keys "<lukso-working-directory>/<keyfolder>"
```

</TabItem>
</Tabs>

:::tip

During the import of the keys, you will be promted to enter the password of the [generated deposit keys](/docs/guides/validator-setup/wagyu-key-generation.md).

:::

:::info

If you have multiple deposit folders, import one folder at the time and re-type both wallet andkey passwords on each round.

:::

:::note Folder Structure

The import command will generate a new keystore folder within the working directory housing all imported validator accounts.

```text
lukso-node
‚îÇ
‚îú‚îÄ‚îÄ‚îÄconfigs                                   // Configuration Files
‚îú‚îÄ‚îÄ‚îÄ[network]-logs                            // Network's Logged Status Messages
‚îú‚îÄ‚îÄ‚îÄ[network]-data                            // Network's Blockchain Data
‚îú‚îÄ‚îÄ‚îÄ[network]-keystore                        // Network's Validator Keystore List
|
‚îî‚îÄ‚îÄ‚îÄcli-config.yaml                           // Global CLI Configuration
```

:::

## 3. Verify Imported Accounts

After importing one or multiple folders, you can check your imported keys.

<Tabs groupId="network-type">
  <TabItem value="mainnet" label="Mainnet" default>

```sh
# LUKSO CLI v. 0.6.0+
lukso validator list --mainnet

# Lukso CLI v. <0.6.0
validator accounts list --wallet-dir "mainnet-keystore"
```

</TabItem> <TabItem value="testnet" label="Testnet">

```sh
# LUKSO CLI v. 0.6.0+
lukso validator list --testnet

# Lukso CLI v. <0.6.0
validator accounts list --wallet-dir "testnet-keystore"
```

</TabItem>
</Tabs>

## 4. Remove the Key Folder

If the imported keys match the ones in the original deposits, you can delete the folder with the deposit keys.

:::info

You can use the `rm` command to remove files and directories while using the `-r` recursive method. The flag will ensure to remove directories and their contents. You can further skip the confirmation questions or file errors using `-rf` instead.
:::

```sh
rm -rf <lukso-working-directory>/<keyfolder>
```

:::info

Make sure to adjust the path to your key-folder and repeat the process for every folder that was transferred.

:::

## 5. Start the Validator

After importing your keys, you can rstart the node with the validator functionality to begin staking.

:::info

To start the validator, you have to pass a minimum of two flags:

- `--validator`: Starts the configured clients and their validator client.
- `--transaction-fee-recipient`: Defines the address to which block rewards and transaction tips will be paid out.

:::

:::tip

The recipient can be any Ethereum address of a wallet you have control over and is able to connect with custom networks. Ledger accounts, for instance, are secure hardware-wallets and can be imported into MetaMask to send transactions on custom networks. If you withdraw or transfer the money regularly, you can also store the funds in a browser wallet. The address can be updated every time the node is restarted.

:::

<Tabs>
<TabItem value="regular-sync" label="Regular Synchronization">

```sh
# Starting the Mainnet Node as Validator
lukso start --validator --transaction-fee-recipient "<transaction-fee-recipient-address>"

# Starting the Testnet Node as Validator
lukso start --validator --transaction-fee-recipient "<transaction-fee-recipient-address>" --testnet
```

:::info

Replace `<transaction-fee-recipient-address>` with your actual withdrawal address.

:::

</TabItem> 
<TabItem value="automated-checkpoints" label="Automated Checkpoints">

```sh
# Starting the Mainnet Node as Validator
lukso start --validator --transaction-fee-recipient "<transaction-fee-recipient-address>" --checkpoint-sync

# Starting the Testnet Node as Validator
lukso start --validator --testnet --transaction-fee-recipient "<transaction-fee-recipient-address>" --checkpoint-sync
```

:::info

Replace `<transaction-fee-recipient-address>` with your actual withdrawal address.

:::

</TabItem> 
<TabItem value="manual-checkpoints" label="Manual Checkpoints">

- Visit the [Mainnet Checkpoint Explorer](https://checkpoints.mainnet.lukso.network/) or [Testnet Checkpoint Explorer](https://checkpoints.testnet.lukso.network/)
- Pass the latest **Block Root** and **Epoch** values to the consensus client flags

<Tabs>
<TabItem value="lighthouse" label="Lighthouse">

```sh
# Starting the Mainnet Node as Validator
lukso start --validator \
  --transaction-fee-recipient "<transaction-fee-recipient-address>" \
  --lighthouse-checkpoint-sync-url=https://checkpoints.mainnet.lukso.network \
  --lighthouse-genesis-state-url=https://checkpoints.mainnet.lukso.network \
  --lighthouse-wss-checkpoint=$<BLOCK_ROOT>:$<EPOCH>

# Starting the Testnet Node as Validator
lukso start --validator --testnet \
  --transaction-fee-recipient "<transaction-fee-recipient-address>" \
  --lighthouse-checkpoint-sync-url=https://checkpoints.testnet.lukso.network \
  --lighthouse-genesis-state-url=https://checkpoints.testnet.lukso.network \
  --lighthouse-wss-checkpoint=$<BLOCK_ROOT>:$<EPOCH>
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
# Starting the Mainnet Node as Validator
lukso start --validator \
  --transaction-fee-recipient "<transaction-fee-recipient-address>" \
  --teku-checkpoint-sync-url=https://checkpoints.mainnet.lukso.network \
  --teku-ws-checkpoint=$<BLOCK_ROOT>:$<EPOCH>

# Starting the Testnet Node as Validator
lukso start --validator --testnet \
  --transaction-fee-recipient "<transaction-fee-recipient-address>" \
  --teku-checkpoint-sync-url=https://checkpoints.testnet.lukso.network \
  --teku-ws-checkpoint=$<BLOCK_ROOT>:$<EPOCH>
```

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
# Starting the Mainnet Node as Validator
lukso start --validator \
  --transaction-fee-recipient "<transaction-fee-recipient-address>" \
  --prysm-checkpoint-sync-url=https://checkpoints.mainnet.lukso.network \
  --prysm-genesis-beacon-api-url=https://checkpoints.mainnet.lukso.network \
  --prysm-weak-subjectivity-checkpoint=$<BLOCK_ROOT>:$<EPOCH>

# Starting the Testnet Node as Validator
lukso start --validator --testnet \
  --transaction-fee-recipient "<transaction-fee-recipient-address>" \
  --prysm-checkpoint-sync-url=https://checkpoints.testnet.lukso.network \
  --prysm-genesis-beacon-api-url=https://checkpoints.testnet.lukso.network \
  --prysm-weak-subjectivity-checkpoint=$<BLOCK_ROOT>:$<EPOCH>
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
# Starting the Mainnet Node as Validator
lukso start --validator \
  --transaction-fee-recipient "<transaction-fee-recipient-address>" \
  --nimbus2-external-beacon-api-url=https://checkpoints.mainnet.lukso.network \
  --nimbus2-trusted-block-root=$<BLOCK_ROOT> \
  --nimbus2-weak-subjectivity-checkpoint=$<BLOCK_ROOT>:$<EPOCH>

# Starting the Testnet Node as Validator
lukso start --validator --testnet \
  --transaction-fee-recipient "<transaction-fee-recipient-address>" \
  --nimbus2-external-beacon-api-url=https://checkpoints.testnet.lukso.network
  --nimbus2-trusted-block-root=$<BLOCK_ROOT> \
  --nimbus2-weak-subjectivity-checkpoint=$<BLOCK_ROOT>:$<EPOCH>
```

</TabItem> 
</Tabs>

:::info

Replace the following parameters of the commands:

- `<BLOCK_ROOT>` and `<EPOCH>` with the current hash and number while keeping the `$` sign.
- `<transaction-fee-recipient-address>` with your actual withdrawal address.

:::

</TabItem> 
</Tabs>

---

// File: guides/modifications/slasher-configuration

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 7.1 Slasher Configuration

Running a slasher service helps monitor and report malicious validator behavior, contributing to the overall health and security of the network. This guide explains how to enable or disable the slasher for regular nodes and validators.

:::tip

Further details can be found on the [**Slashing and Panelties**](/docs/theory/blockchain-knowledge/slashing-and-panelties.md) and [Slasher Service](/docs/theory/node-operation/slasher-service.md) pages in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Stop Node Operation

Depending on your setup method, there are different ways to stop your node before applying updates.

<Tabs groupId="setup">
  <TabItem value="cli" label="LUKSO CLI" default>

```sh
cd <lukso-working-directory>
lukso stop
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl stop lukso-validator
```

</TabItem>
</Tabs>

<details>
<summary>Force Client Shutdown</summary>

<Tabs>
<TabItem value="geth" label="Geth">

```sh
sudo pkill geth
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
sudo pkill erigon
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
sudo pkill nethermind
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
sudo pkill besu
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
sudo pkill teku
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
sudo pkill nimbus_beacon_node
sudo pkill nimbus_validator_client
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```sh
sudo pkill lighthouse
```

:::tip

The Lighthouse client uses a single binary for both the consensus and validator processes.

:::

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
sudo pkill prysm
sudo pkill validator
```

</TabItem>
</Tabs>

</details>

## 2. Configure Slasher Service

If you are running a validator node using the [LUKSO CLI](/docs/theory/node-operation/client-setups.md) setup, the slasher is activated by default to increase watchers for malicious events during network downtimes of bigger services. For regular nodes or custom setups, the slasher service is disabled.

If you are runnning on lower end hardware or prefer to safe disk space, you can disable it. Regular nodes can use the similar process to activate the additional service without participating in the consensus.

:::tip

The **Teku** and **Nimbus-Eth2** clients do not have separate [slasher services](/docs/theory/node-operation/slasher-service.md) that create a database and keep track of the historical misbehaviours. Instead, they only come with validator precautions such as [`slashing-protection`](https://docs.teku.consensys.io/how-to/prevent-slashing/use-a-slashing-protection-file) or [`doppelganger-detection`](https://nimbus.guide/doppelganger-detection.html) that check against their own keys before committing validator duties.

:::

<Tabs groupId="slasher">
  <TabItem value="disable" label="Disable Slasher for Validator Node" default>

Depending on your setup method, there are different ways to start your staking node without the slasher service.

<Tabs groupId="setup">
<TabItem value="cli" label="LUKSO CLI" default>

```sh
cd <lukso-working-directory>

# Start Mainnet Validator without Slasher
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync -no-slasher

# Start Testnet Validator without Slasher
lukso start --testnet --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync -no-slasher
```

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path of the node folder
- `<your-fee-recipient-address>` with the wallet address receiving staking profits

:::

</TabItem> <TabItem value="automation" label="Service Automation">

Open the startup script within your node directory with your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
sudo vim <lukso-working-directory>/static/lukso_startup.sh
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
sudo nano <lukso-working-directory>/static/lukso_startup.sh
```

</TabItem>
</Tabs>

:::info

Exchange `<lukso-working-directory>` with the path to the node folder.

:::

Add the flag to disable the slasher service as a new line to the start command, then save and exit the file.

```text
exec /usr/local/bin/lukso start \
        --validator \
        --validator-wallet-password ./static/<your-generic-password-file> \
        --transaction-fee-recipient "<your-fee-recipient-address>" \
        --checkpoint-sync \
        --no-slasher
```

After the startup script was updated, you can restart the node by executing the related service.

```sh
sudo systemctl start lukso-validator
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="activate" label="Activate Slasher for Regular Node">

Depending on your setup method, there are different ways to start your regular node with the slasher service flags. The custom flags provided during startup will be passed down from the [LUKSO CLI](https://github.com/lukso-network/tools-lukso-cli) to the consensus clients.

<Tabs groupId="setup">
<TabItem value="cli" label="LUKSO CLI" default>

```sh
cd <lukso-working-directory>
```

:::info

Exchange `<lukso-working-directory>` with the path to the node folder.

:::

<Tabs groupId="client">
<TabItem value="lighthouse" label="Lighthouse">

```sh
# Start Mainnet Slasher Node
lukso start --checkpoint-sync --lighthouse-slasher

# Start Testnet Slasher Node
lukso start --testnet --checkpoint-sync --lighthouse-slasher
```

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
# Start Mainnet Slasher Node
lukso start --checkpoint-sync --prysm-slasher

# Start Testnet Slasher Node
lukso start --testnet --checkpoint-sync --prysm-slasher
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="automation" label="Service Automation">

Open the startup script within your node directory with your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/static
vim lukso_startup.sh
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/static
nano lukso_startup.sh
```

</TabItem>
</Tabs>

:::info

Exchange `<lukso-working-directory>` with the path to the node folder.

:::

Add the flag to activate the slasher service as a new line to the start command, then save and exit the file.

<Tabs groupId="client">
<TabItem value="lighthouse" label="Lighthouse">

```text
exec /usr/local/bin/lukso start \
        --validator \
        --validator-wallet-password ./static/<your-generic-password-file> \
        --transaction-fee-recipient "<your-fee-recipient-address>" \
        --checkpoint-sync \
        --lighthouse-slasher
```

</TabItem> <TabItem value="prysm" label="Prysm">

```text
exec /usr/local/bin/lukso start \
        --validator \
        --validator-wallet-password ./static/<your-generic-password-file> \
        --transaction-fee-recipient "<your-fee-recipient-address>" \
        --checkpoint-sync \
        --prysm-slasher
```

</TabItem>
</Tabs>

After the startup script was updated, you can restart the node by executing the related service.

```sh
sudo systemctl start lukso-validator
```

</TabItem>
</Tabs>

</TabItem>
</Tabs>

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

## 4. Remove Slasher Data

If you previously ran a slasher service, you can delete the unused database from your node directory and free storage space.

```sh
cd <lukso-working-directory>

# Remove Slasher Database for Mainnet Node
rm -rf /mainnet-data/consensus/beaconchaindata/slasher.db

# Remove Slasher Database for Testnet Node
rm -rf /testnet-data/consensus/beaconchaindata/slasher.db
```

:::info

Exchange `<lukso-working-directory>` with the path to the node folder.

:::

## üé® DAppNode

On a DAppNode setup, the Prysm client can be adjusted from the user interface.

**1. Stop Node Operation**: Stop the execution and consensus client within the _Node Operation View_.

**2. Navigate to Staker Menu**: Open the _LUKSO Stakers_ menu and move into the _Lukso Prysm Package_.

**3. Adjust Slasher Value**: Navigate to the _Configs_ window and add the slasher flag in the _EXTRA_OPTS_ field.

<Tabs groupId="slasher">
  <TabItem value="disable" label="Disable Slasher for Validator Node" default>

```sh
--no-slasher
```

</TabItem> <TabItem value="activate" label="Activate Slasher for Regular Node">

```sh
--slasher
```

</TabItem>
</Tabs>

**4. Restart the Node**: Restart the execution and consensus client within the _Node Operation View_.

---

// File: guides/modifications/custom-node-name

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 7.2 Custom Node Name

To personalize your node's appearance, you can assign a custom name thats publically displayed on the [execution status panel](https://stats.execution.mainnet.lukso.network/).

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Stop Node Operation

Depending on your setup method, there are different ways to stop your node before setting a custom name.

<Tabs groupId="setup">
  <TabItem value="cli" label="LUKSO CLI" default>

```sh
cd <lukso-working-directory>
lukso stop
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl stop lukso-validator
```

</TabItem>
</Tabs>

<details>
<summary>Force Client Shutdown</summary>

<Tabs>
<TabItem value="geth" label="Geth">

```sh
sudo pkill geth
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
sudo pkill erigon
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
sudo pkill nethermind
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
sudo pkill besu
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
sudo pkill teku
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
sudo pkill nimbus_beacon_node
sudo pkill nimbus_validator_client
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```sh
sudo pkill lighthouse
```

:::tip

The Lighthouse client uses a single binary for both the consensus and validator processes.

:::

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
sudo pkill prysm
sudo pkill validator
```

</TabItem>
</Tabs>

</details>

## 2. Add Node Name

You can either set the node name via startup flags or persistently within the configuration files of your execution client. If you want to set a temporary name, using the flag is recommended, as it will only persist until the next restart of the node.

<Tabs groupId="configuration">
  <TabItem value="flag" label="Setting a Startup Flag" default>

Depending on your setup method, there are different ways to pass down the name flag using the [LUKSO CLI](https://github.com/lukso-network/tools-lukso-cli).

<Tabs groupId="setup">
<TabItem value="clinode" label="LUKSO CLI Node" default>

Every execution client has a individual flag to set the node name during startup.

<Tabs>
<TabItem value="geth" label="Geth">

```sh
cd <lukso-working-directory>

# Start the Mainnet Node with Custom Name
lukso start --checkpoint-sync --geth-identity "<your-node-name>"

# Start the Testnet Node with Custom Name
lukso start --testnet --checkpoint-sync --geth-identity "<your-node-name>"
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
cd <lukso-working-directory>

# Start the Mainnet Node with Custom Name
lukso start --checkpoint-sync --erigon-identity "<your-node-name>"

# Start the Testnet Node with Custom Name
lukso start --testnet --checkpoint-sync --erigon-identity "<your-node-name>"
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
cd <lukso-working-directory>

# Start the Mainnet Node with Custom Name
lukso start --checkpoint-sync --nethermind-ethstats-name "<your-node-name>"

# Start the Testnet Node with Custom Name
lukso start --testnet --checkpoint-sync --nethermind-ethstats-name "<your-node-name>"
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
cd <lukso-working-directory>

# Start the Mainnet Node with Custom Name
lukso start --checkpoint-sync --besu-ethstats="<your-node-name>:<ethstats-secret>@<ethstats-server-url>"

# Start the Testnet Node with Custom Name
lukso start --testnet --checkpoint-sync --besu-ethstats="<your-node-name>:<ethstats-secret>@<ethstats-server-url>"
```

:::warning

The Besu client embeds the node name directly within the Eth-Stats connection string, meaning you must also exchange and provide the `<ethstats-secret>` and `<ethstats-server-url>` as a flag. Other execution clients have those set separately within their config files.

:::

</TabItem>
</Tabs>

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path of the node folder
- `<your-node-name>` with the custom description or name of the node

:::

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

</TabItem> <TabItem value="clivalidator" label="LUKSO CLI Validator" default>

Every execution client has a individual flag to set the node name during startup.

<Tabs>
<TabItem value="geth" label="Geth">

```sh
cd <lukso-working-directory>

# Start the Mainnet Validator Node with Custom Name
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --geth-identity "<your-node-name>"

# Start the Testnet Validator Node with Custom Name
lukso start --testnet --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync  --geth-identity "<your-node-name>"
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
cd <lukso-working-directory>

# Start the Mainnet Validator Node with Custom Name
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --erigon-identity "<your-node-name>"

# Start the Testnet Validator Node with Custom Name
lukso start --testnet --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --erigon-identity "<your-node-name>"
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
cd <lukso-working-directory>

# Start the Mainnet Validator Node with Custom Name
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --nethermind-ethstats-name "<your-node-name>"

# Start the Testnet Validator Node with Custom Name
lukso start --testnet --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --nethermind-ethstats-name "<your-node-name>"
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
cd <lukso-working-directory>

# Start the Mainnet Validator Node with Custom Name
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --besu-ethstats="<your-node-name>:<ethstats-secret>@<ethstats-server-url>"

# Start the Testnet Validator Node with Custom Name
lukso start --testnet --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --besu-ethstats="<your-node-name>:<ethstats-secret>@<ethstats-server-url>"
```

:::warning

The Besu client embeds the node name directly within the Eth-Stats connection string, meaning you must also exchange and provide the `<ethstats-secret>` and `<ethstats-server-url>` as a flag. Other execution clients have those set separately within their config files.

:::

</TabItem>
</Tabs>

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path of the node folder
- `<your-fee-recipient-address>` with the wallet address receiving staking profits
- `<your-node-name>` with the custom description or name of the node

:::

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

</TabItem> <TabItem value="automation" label="Service Automation">

Open the startup script within your node directory with your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
sudo vim <lukso-working-directory>/static/lukso_startup.sh
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
sudo nano <lukso-working-directory>/static/lukso_startup.sh
```

</TabItem>
</Tabs>

:::info

Exchange `<lukso-working-directory>` with the path to the node folder.

:::

Add the name flag new line to the start command, then save and exit the file.

<Tabs>
<TabItem value="geth" label="Geth">

```text
exec /usr/local/bin/lukso start \
        --validator \
        --validator-wallet-password ./static/<your-generic-password-file> \
        --transaction-fee-recipient "<your-fee-recipient-address>" \
        --checkpoint-sync \
        --geth-identity "<your-node-name>"
```

</TabItem> <TabItem value="erigon" label="Erigon">

```text
exec /usr/local/bin/lukso start \
        --validator \
        --validator-wallet-password ./static/<your-generic-password-file> \
        --transaction-fee-recipient "<your-fee-recipient-address>" \
        --checkpoint-sync \
        --erigon-identity "<your-node-name>"
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```text
exec /usr/local/bin/lukso start \
        --validator \
        --validator-wallet-password ./static/<your-generic-password-file> \
        --transaction-fee-recipient "<your-fee-recipient-address>" \
        --checkpoint-sync \
        --nethermind-ethstats-name "<your-node-name>"
```

</TabItem> <TabItem value="besu" label="Besu">

```text
exec /usr/local/bin/lukso start \
        --validator \
        --validator-wallet-password ./static/<your-generic-password-file> \
        --transaction-fee-recipient "<your-fee-recipient-address>" \
        --checkpoint-sync \
        --besu-ethstats="<your-node-name>:<ethstats-secret>@<ethstats-server-url>"
```

:::warning

The Besu client embeds the node name directly within the Eth-Stats connection string, meaning you must also exchange and provide the `<ethstats-secret>` and `<ethstats-server-url>` as a flag. Other execution clients have those set separately within their config files.

:::

</TabItem>
</Tabs>

:::info

The following properties need to be exchanged:

- `<your-generic-password-file>` with the name of your validator password file
- `<your-fee-recipient-address>` with the wallet address receiving staking profits
- `<your-node-name>` with the actual node name

:::

After the startup script was updated, you can restart the node by executing the related service.

```sh
sudo systemctl start lukso-validator
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="file" label="Modifying the Client Configuration">

Depending on your execution client, the name can be set with different properties.

<Tabs groupId="client">
<TabItem value="geth" label="Geth">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/geth/
vim geth.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/geth/
nano geth.toml
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="erigon" label="Erigon">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/erigon/
vim erigon.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/erigon/
nano erigon.toml
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="nethermind" label="Nethermind">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/nethermind/
vim nethermind.cfg
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/nethermind/
nano nethermind.cfg
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="besu" label="Besu">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/besu/
vim besu.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/besu/
nano besu.toml
```

</TabItem>
</Tabs>

</TabItem>
</Tabs>

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path to the node folder.
- `<network>` with the name of your node's network.

:::

Add the node name as a new line within the settings, then save and exit the file.

<Tabs groupId="client">
<TabItem value="geth" label="Geth">

Search for the _Node_ section and add the _UserIdent_ property under it.

```text
[Node]
UserIdent = "<your-node-name>"
```

</TabItem> <TabItem value="erigon" label="Erigon">

Set the _identity_ property at the end of the file.

```text
"identity" = "<your-node-name>"
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

Set the _EthStats_ object and _Name_ property at the ending bracket of the _Network_ object.

```text
"EthStats": {
  "Name": "<your-node-name>"
}
```

</TabItem> <TabItem value="besu" label="Besu">

Set the _ethstats_ property at the end of the file.

```text
'ethstats'='<your-node-name>:<secret>@<server-url>'
```

:::warning

The Besu client embeds the node name directly within the Eth-Stats connection string, meaning you must also exchange and provide the `<ethstats-secret>` and `<ethstats-server-url>` as a flag. Other execution clients have those set separately within their config files.

:::

</TabItem>
</Tabs>

:::info

Exchange `<your-node-name>` with the custom description or name of the node

:::

:::warning

Ensure there are no missing spaces, characters or unintended linebreaks before saving the configuration file.

:::

Depending on your setup method, there are different ways to start your node after setting the node name.

<Tabs groupId="setup">
  <TabItem value="clinode" label="LUKSO CLI Node" default>

```sh
cd <lukso-working-directory>
lukso start --checkpoint-sync
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="clivalidator" label="LUKSO CLI Validator" default>

```sh
cd <lukso-working-directory>
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync
```

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path of the node folder
- `<your-fee-recipient-address>` with the wallet address receiving staking profits

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl start lukso-validator
```

</TabItem>
</Tabs>

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

</TabItem>
</Tabs>

## üé® DAppNode

On a DAppNode setup, the Geth client can be adjusted from the user interface.

**1. Stop Node Operation**: Stop the execution and consensus client within the _Node Operation View_.

**2. Navigate to Staker Menu**: Open the _LUKSO Stakers_ menu and move into the _Lukso Geth Package_.

**3. Adjust Slasher Value**: Navigate to the _Configs_ window and add the name flag in the _EXTRA_OPTS_ field.

```sh
--identity "<your-node-name>"
```

:::info

Exchange `<your-node-name>` with the custom description or name of the node.

:::

**4. Restart the Node**: Restart the execution and consensus client within the _Node Operation View_.

---

// File: guides/modifications/validator-graffiti

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 7.3 Validator Graffiti

To personalize your validator's appearance, you can assign a custom graffiti thats publically displayed on the [consensus slot page](https://explorer.consensus.mainnet.lukso.network/slots). Adding graffiti to a block gives validators a unique way to mark their contributions to the network. The content of the graffiti can vary greatly. Some validators might use this space to include their validator name or identifier, while others might use it for fun.

Within an EVM-blockchain, the graffiti refers to a customizable field where validators can inscribe a short message of up to 32 bytes into the block's metadata. These messages are permanently stored on the blockchain. Each ASCII character uses 1 byte, but special characters or emojis can up take more.

:::note

Although the graffiti allows for freedom of expression, it should be used responsibly. It's part of the blockchain's permanent record and repeated with every block proposal. The community generally encourages respectful and appropriate usage.

:::

:::tip

Check if your message is [within the byte limit](https://mothereff.in/byte-counter) before attaching it to the client. Emojis take up several bytes.

:::

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Stop Node Operation

Depending on your setup method, there are different ways to stop your node before setting a graffiti.

<Tabs groupId="setup">
  <TabItem value="cli" label="LUKSO CLI" default>

```sh
cd <lukso-working-directory>
lukso stop
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl stop lukso-validator
```

</TabItem>
</Tabs>

<details>
<summary>Force Client Shutdown</summary>

<Tabs>
<TabItem value="geth" label="Geth">

```sh
sudo pkill geth
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
sudo pkill erigon
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
sudo pkill nethermind
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
sudo pkill besu
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
sudo pkill teku
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
sudo pkill nimbus_beacon_node
sudo pkill nimbus_validator_client
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```sh
sudo pkill lighthouse
```

:::tip

The Lighthouse client uses a single binary for both the consensus and validator processes.

:::

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
sudo pkill prysm
sudo pkill validator
```

</TabItem>
</Tabs>

</details>

## 2. Add Validator Graffiti

You can either set the graffiti via startup flags or persistently within the configuration files of your execution client. If you want to set a temporary graffiti, using the flag is recommended, as it will only persist until the next restart of the node.

<Tabs groupId="configuration">
  <TabItem value="flag" label="Setting a Startup Flag" default>

Depending on your setup method, there are different ways to pass down the graffiti using the [LUKSO CLI](https://github.com/lukso-network/tools-lukso-cli).

<Tabs groupId="setup">
<TabItem value="clinode" label="LUKSO CLI Node" default>

Every consensus client has a individual flag to set the graffiti during startup.

<Tabs>
<TabItem value="prysm" label="Prysm">

```sh
cd <lukso-working-directory>

# Start the Mainnet Node with Custom Graffiti
lukso start --checkpoint-sync --prysm-graffiti "<your-graffiti>"

# Start the Testnet Node with Custom Graffiti
lukso start --testnet --checkpoint-sync --prysm-graffiti "<your-graffiti>"
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
cd <lukso-working-directory>

# Start the Mainnet Node with Custom Graffiti
lukso start --checkpoint-sync --teku-validators-graffiti="<your-graffiti>"

# Start the Testnet Node with Custom Graffiti
lukso start --testnet --checkpoint-sync ---teku-validators-graffiti="<your-graffiti>"
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```sh
cd <lukso-working-directory>

# Start the Mainnet Node with Custom Graffiti
lukso start --checkpoint-sync --lighthouse-graffiti "<your-graffiti>"

# Start the Testnet Node with Custom Graffiti
lukso start --testnet --checkpoint-sync --lighthouse-graffiti "<your-graffiti>"
```

</TabItem> <TabItem value="Nimbus-Eth2" label="Nimbus-Eth2">

```sh
cd <lukso-working-directory>

# Start the Mainnet Node with Custom Graffiti
lukso start --checkpoint-sync --nimbus2-graffiti="<your-graffiti>"

# Start the Testnet Node with Custom Graffiti
lukso start --testnet --checkpoint-sync --nimbus2-graffiti="<your-graffiti>"
```

</TabItem>
</Tabs>

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path of the node folder
- `<your-graffiti>` with the custom graffiti of your node.

:::

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

</TabItem> <TabItem value="clivalidator" label="LUKSO CLI Validator" default>

Every consensus client has a individual flag to set the graffiti during startup.

<Tabs>
<TabItem value="prysm" label="Prysm">

```sh
cd <lukso-working-directory>

# Start the Mainnet Validator Node with Custom Graffiti
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --prysm-graffiti "<your-graffiti>"

# Start the Testnet Validator Node with Custom Graffiti
lukso start --testnet --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --prysm-graffiti "<your-graffiti>"
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
cd <lukso-working-directory>

# Start the Mainnet Validator Node with Custom Graffiti
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --teku-validators-graffiti="<your-graffiti>"

# Start the Testnet Validator Node with Custom Graffiti
lukso start --testnet --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --teku-validators-graffiti="<your-graffiti>"
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```sh
cd <lukso-working-directory>

# Start the Mainnet Validator Node with Custom Graffiti
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --lighthouse-graffiti "<your-graffiti>"

# Start the Testnet Validator Node with Custom Graffiti
lukso start --testnet --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --lighthouse-graffiti "<your-graffiti>"
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
cd <lukso-working-directory>

# Start the Mainnet Validator Node with Custom Graffiti
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --nimbus2-graffiti="<your-graffiti>"

# Start the Testnet Validator Node with Custom Graffiti
lukso start --testnet --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --nimbus2-graffiti="<your-graffiti>"
```

</TabItem>
</Tabs>

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path of the node folder
- `<your-fee-recipient-address>` with the wallet address receiving staking profits
- `<your-graffiti>` with the custom graffiti of your node.

:::

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

</TabItem> <TabItem value="automation" label="Service Automation">

Open the startup script within your node directory with your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
sudo vim <lukso-working-directory>/static/lukso_startup.sh
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
sudo nano <lukso-working-directory>/static/lukso_startup.sh
```

</TabItem>
</Tabs>

:::info

Exchange `<lukso-working-directory>` with the path to the node folder.

:::

Add the graffiti flag as a new line to the start command, then save and exit the file.

<Tabs>
<TabItem value="prysm" label="Prysm">

```text
exec /usr/local/bin/lukso start \
        --validator \
        --validator-wallet-password ./static/<your-generic-password-file> \
        --transaction-fee-recipient "<your-fee-recipient-address>" \
        --checkpoint-sync \
        --geth-graffiti "<your-graffiti>"
```

</TabItem> <TabItem value="teku" label="Teku">

```text
exec /usr/local/bin/lukso start \
        --validator \
        --validator-wallet-password ./static/<your-generic-password-file> \
        --transaction-fee-recipient "<your-fee-recipient-address>" \
        --checkpoint-sync \
        --teku-validators-graffiti="<your-graffiti>"
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```text
exec /usr/local/bin/lukso start \
        --validator \
        --validator-wallet-password ./static/<your-generic-password-file> \
        --transaction-fee-recipient "<your-fee-recipient-address>" \
        --checkpoint-sync \
        --lighthouse-graffiti "<your-graffiti>"
```

</TabItem> <TabItem value="nimbus-2" label="Nimbus-Eth2">

```text
exec /usr/local/bin/lukso start \
        --validator \
        --validator-wallet-password ./static/<your-generic-password-file> \
        --transaction-fee-recipient "<your-fee-recipient-address>" \
        --checkpoint-sync \
        --nimbus2-graffiti="<your-graffiti>"
```

</TabItem>
</Tabs>

:::info

The following properties need to be exchanged:

- `<your-generic-password-file>` with the name of your validator password file
- `<your-fee-recipient-address>` with the wallet address receiving staking profits
- `<your-graffiti>` with the actual graffiti description of your node

:::

After the startup script was updated, you can restart the node by executing the related service.

```sh
sudo systemctl start lukso-validator
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="file" label="Modifying the Client Configuration">

Depending on your consensus client, the graffiti can be set with different properties.

<Tabs groupId="client">
<TabItem value="prysm" label="Prysm">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/prysm/
vim validator.yaml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/prysm/
nano validator.yaml
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="teku" label="Teku">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/teku/
vim validator.yaml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/teku/
nano validator.yaml
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/lighthouse/
vim validator.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/lighthouse/
nano validator.toml
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/nimbus2/
vim validator.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/nimbus2/
nano validator.toml
```

</TabItem>
</Tabs>

</TabItem>
</Tabs>

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path to the node folder.
- `<network>` with the name of your node's network.

:::

Add the graffiti as a new line within the settings, then save and exit the file.

<Tabs groupId="client">
<TabItem value="prysm" label="Prysm">

Add the _graffiti_ as a new line at the end of the file.

```text
graffiti: '<your-graffiti>'
```

</TabItem> <TabItem value="teku" label="Teku">

Add the _validators-graffiti_ as a new line at the end of the file.

```text
validators-graffiti: 'your-graffiti'
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

Add the _graffiti_ as a new line at the end of the file.

```text
graffiti: "<your-graffiti>"
```

</TabItem> <TabItem value="nimbus2" label="Nimbus">

Add the _graffiti_ as a new line at the end of the file.

```text
graffiti = "<your-graffiti>"
```

</TabItem>
</Tabs>

:::info

Exchange `<your-graffiti>` with the custom graffiti of your node.

:::

:::warning

Ensure there are no missing spaces, characters or unintended linebreaks before saving the configuration file.

:::

Depending on your setup method, there are different ways to start your node after setting the graffiti.

<Tabs groupId="setup">
  <TabItem value="clinode" label="LUKSO CLI Node" default>

```sh
cd <lukso-working-directory>
lukso start --checkpoint-sync
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="clivalidator" label="LUKSO CLI Validator" default>

```sh
cd <lukso-working-directory>
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync
```

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path of the node folder
- `<your-fee-recipient-address>` with the wallet address receiving staking profits

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl start lukso-validator
```

</TabItem>
</Tabs>

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

</TabItem>
</Tabs>

## üé® DAppNode

On a DAppNode setup, the Prysm client can be adjusted from the user interface.

**1. Stop Node Operation**: Stop the execution and consensus client within the _Node Operation View_.

**2. Navigate to Staker Menu**: Open the _LUKSO Stakers_ menu and move into the _Lukso Prysm Package_.

**3. Adjust Slasher Value**: Navigate to the _Configs_ window and add the graffiti flag in the _EXTRA_OPTS_ field.

```sh
--graffiti "<your-graffiti>"
```

:::info

Exchange `<your-graffiti>` with the custom graffiti of your node.

:::

**4. Restart the Node**: Restart the execution and consensus client within the _Node Operation View_.

---

// File: guides/modifications/public-ip-setup

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 7.4 Public IP Setup

To ensure your node is discoverable and can establish a healthy number of peer connections, you may need to manually set or update your node‚Äôs public IP address. This is particularly important for validators, where lower peer counts are an obsticle for accurate block proposals and attestations.

:::tip

Further details about connectivity can be found on the [**Peer Networks**](/docs/theory/blockchain-knowledge/peer-networks.md) and [**Peer Connectivity**](/docs/theory/node-operation/peer-discovery.md) pages of the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Check Peer Connections

To get insights into the current connections, you can check the peer connections from your local node. Every node operates two independent peer-to-peer networks: the execution and the consensus layer. Each of these networks handles communication with other nodes differently and maintains separate sets of peers. Monitoring both layers is essential to ensure healthy connectivity and network participation.

<Tabs groupId="network-type">
<TabItem value="execution" label="Execution Peers" default>

The execution endpoint allows to fetch the peer counts and lots of [other client-specific intormation](/docs/guides/maintenance/problem-scanning.md#attach-execution-clients).

:::info JSON RPC

JSON-RPC is a lightweight communication protocol encoded in JSON, allowing calls to be sent to a service or server. Each execution client exposes a related interface at port `8545` to retreive calls to interact with the Ethereum network though the local node.

:::

:::tip

By default, the [LUKSO Network Configuration](https://github.com/lukso-network/network-configs) allows to retrieve network data for all execution clients.

:::

**1.1 Install Querying Tool**: _Install the JSON query service for data processing from the RPC endpoint._

```sh
sudo apt install jq
```

**1.2 Call Execution Endpoint**: _While the node is running, call the JSON RPC of the execution client._

```sh
# Retrieve Execution Peers
curl -s -X POST -H "content-type: application/json" \
  --data '{"jsonrpc":"2.0","method":"net_peerCount","params":[],"id":1}' \
  http://localhost:8545 | jq -r '.result' | xargs printf '%d\n'
```

<details>
    <summary>Full Command Explanation</summary>

| **Command**                                                               | **Description**                                                                                                                                     |
| ------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> `curl -s -X POST -H <text> ` <br /> `--data <text> <port>` </nobr> | Executes `-X` a silent `-s` HTTP `POST` request to the given `<port>`, while attaching custom header `-H` and `--data` content as `<text>` payload. |
| <nobr> `jq -r '.result'` </nobr>                                          | Filters the raw `-r` JSON object and extracts the `.result` value of the data object.                                                               |
| <nobr> `xargs printf '%d\n'` </nobr>                                      | Converts the hexadecimal result to a human-readable decimal `%d` number.                                                                            |

</details>

The output should be something in the range from 5 to 50 peers.

```text
37
```

:::warning

If the command couldn't be executed, have a look at the [**Problem Scanning**](/docs/guides/maintenance/problem-scanning.md) page to learn how to [attach execution clients](/docs/guides/maintenance/problem-scanning.md#attach-execution-clients).

:::

</TabItem> <TabItem value="consensus" label="Consensus Peers">

The consensus endpoint allows to fetch the peer counts and lots of [other client-specific intormation](/docs/guides/maintenance/problem-scanning.md#fetch-consensus-api).

:::info REST API

A REST API is a web-based interface for querying structured data. Ethereum consensus clients expose their status and internal metrics on various ports like `3500`, `5051`, or `5052`, to allow users to access information such as synchronization progress, network stability, node metadata, or the current chain head.

:::

:::tip

By default, the [LUKSO Network Configuration](https://github.com/lukso-network/network-configs) opens the REST API ports for all consensus clients.

:::

**1.1 Install Querying Tool**: _Install the JSON query service for data processing from the REST API endpoint._

```sh
sudo apt install jq
```

**1.2 Call Endpoints**: _While the node is running, call the REST endpoint of the consensus client._

<Tabs>
  <TabItem value="teku" label="Teku">

```sh
# Check Number of Consensus Peers
curl -s http://localhost:5051/eth/v1/node/peer_count | jq
```

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
# Check Number of Consensus Peers
curl -s http://localhost:3500/eth/v1/node/peer_count | jq
```

</TabItem> <TabItem value="lighthouse-nimbus2" label="Lighthouse and Nimbus-Eth2">

```sh
# Check Number of Consensus Peers
curl -s http://localhost:5052/eth/v1/node/peer_count | jq
```

</TabItem>
</Tabs>

The output should be something in the range from 5 to 70 peers.

```text
59
```

</TabItem>
</Tabs>

If you have low or volatile peer counts, continue to stop the node and configure your public IP address.

## 2. Stop Node Operation

Depending on your setup method, there are different ways to stop your node before configuring the IP or raising the peer limits.

<Tabs groupId="setup">
  <TabItem value="cli" label="LUKSO CLI" default>

```sh
cd <lukso-working-directory>
lukso stop
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl stop lukso-validator
```

</TabItem>
</Tabs>

<details>
<summary>Force Client Shutdown</summary>

<Tabs groupId="client">
<TabItem value="geth" label="Geth">

```sh
sudo pkill geth
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
sudo pkill erigon
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
sudo pkill nethermind
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
sudo pkill besu
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
sudo pkill teku
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
sudo pkill nimbus_beacon_node
sudo pkill nimbus_validator_client
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```sh
sudo pkill lighthouse
```

:::tip

The Lighthouse client uses a single binary for both the consensus and validator processes.

:::

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
sudo pkill prysm
sudo pkill validator
```

</TabItem>
</Tabs>

</details>

## 3. Node IP Setup

Once you retrieve your current public IP, you can configure your clients to advertise this IP address.

:::info IP Addresses

Internet Protocol addresses are logical, software‚Äëassigned identifiers. IP addresses let routers move data packages between different networks, whether your local home network or across the Internet. The public IP address is how device and nodes communicate with each other to exchange data.

:::

:::tip IP Changes

There are two types of public IP addresses: dynamic and static ones. An active IP address changes over time, while a static IP address remains constant. Most residential users are assigned a dynamic IP address, which can change whenever the internet service provider sees fit. Some ISPs may change the IP address every time the router is rebooted, while others change it at intervals, like once a week. If you want to further set a permanent connection, you can follow the [**Dynamic DNS**](/docs/guides/modifications/dynamic-dns.md) guide.

:::

:::note

The [LUKSO CLI](/docs/guides/client-setup/lukso-cli-installation.md) allows to set the current IP during installation, but need to be updated on a regular basis.

:::

We can use a simple IP echo service to retrieve the node's current IP address and write it to an editor or notepad.

```sh
curl -s https://ipecho.net/plain
```

Depending on your consensus client, this public IP can be set with different properties.

<Tabs groupId="client">
<TabItem value="prysm" label="Prysm">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/prysm/
vim prysm.yaml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/prysm/
nano prysm.yaml
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="teku" label="Teku">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/teku/
vim teku.yaml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/teku/
nano teku.yaml
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/lighthouse/
vim lighthouse.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/lighthouse/
nano lighthouse.toml
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/nimbus2/
vim nimbus.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/nimbus2/
nano nimbus.toml
```

</TabItem>
</Tabs>

</TabItem>
</Tabs>

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path to the node folder.
- `<network>` with the name of your node's network.

:::

Add or update the following client properties, then save and exit the file.

<Tabs groupId="client">
<TabItem value="prysm" label="Prysm">

Update or add the _p2p-host-ip_ property at the end of the file.

```text
# Previous Value Examples
p2p-host-ip: '0.0.0.0'
p2p-host-ip: '<your-previous-ip>'


# Updated Value
p2p-host-ip: '<your-current-ip-address>'
```

</TabItem> <TabItem value="teku" label="Teku">

Update or add the _p2p-advertised-ip_ property.

```text
# Previous Value Examples
p2p-advertised-ip: 0.0.0.0
p2p-advertised-ip: <your-previous-ip>

# Updated Value
p2p-advertised-ip: <your-current-ip-address>
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

Update the _enr-address_ property.

```text
# Previous Value Examples
enr-address = "0.0.0.0"
enr-address = "<your-previous-ip>"

# Updated Value
enr-address = "<your-current-ip-address>"
```

</TabItem> <TabItem value="nimbus2" label="Nimbus">

Update or add the _extip_ and _enr-auto-update_ properties at the end of the file.

```text
# Previous Value Examples
nat = "extip:0.0.0.0"
nat = "extip:<your-previous-ip>"

# Updated Value
nat = "extip:<your-current-ip-address>"
enr-auto-update = true
```

:::tip

By adding the `enr-auto-update` property, the **Nimbus-Eth2** client automatically detects and updates your public IP address upon changes, meaning you dont have to [set up a dynamic DNS](/docs/guides/modifications/dynamic-dns.md) to permanently stay connected with the network.

:::

</TabItem>
</Tabs>

:::info

Exchange `<your-current-ip-address>` with the public IP address of your node.

:::

:::warning

Ensure there are no missing spaces, characters or unintended linebreaks before saving the configuration file.

:::

## 5. Restart the Node

Depending on your setup method, there are different ways to start your node after the IP address or peer limits have changed.

<Tabs groupId="setup">
  <TabItem value="clinode" label="LUKSO CLI Node" default>

```sh
cd <lukso-working-directory>
lukso start --checkpoint-sync
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="clivalidator" label="LUKSO CLI Validator" default>

```sh
cd <lukso-working-directory>
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync
```

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path of the node folder
- `<your-fee-recipient-address>` with the wallet address receiving staking profits

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl start lukso-validator
```

</TabItem>
</Tabs>

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

:::tip

You should always have more than 15 peers after a setup time of 4 to 6 hours. If your peer count is not improving, it indicates a misconfiguration. Check that all mandatory client ports allow data throughput as described within the [Firewall Settings](/docs/guides/client-setup/firewall-settings.md).

:::

---

// File: guides/modifications/peer-count-limits

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 7.5 Peer Count Limits

Peers in blockchain networks are other nodes your client connects to for data synchronization and message propagation. Maintaining a healthy number of peer connections is essential for exchanging block and transaction data and attesting other node's messages. Depending on your hardware and the volatility of your connections, peer limits can be adjusted.

:::tip

Further details about connectivity can be found on the [**Peer Networks**](/docs/theory/blockchain-knowledge/peer-networks.md) and [**Peer Connectivity**](/docs/theory/node-operation/peer-discovery.md) pages of the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

:::warning

It's not recommended to set network peer limits higher than 100 for homestakers, as it can have negative impacts on the [network's topology](/docs/theory/node-operation/peer-discovery.md#adjustment-effects) while gaining [little to none propagation rate](/docs/theory/node-operation/peer-discovery.md#adjustment-effects) or stability.

:::

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Check Peer Connections

To get insights into the current connections, you can check the peer connections from your local node. Every node operates two independent peer-to-peer networks: the execution and the consensus layer. Each of these networks handles communication with other nodes differently and maintains separate sets of peers. Monitoring both layers is essential to ensure healthy connectivity and network participation.

<Tabs groupId="network-type">
<TabItem value="execution" label="Execution Peers" default>

The execution endpoint allows to fetch the peer counts and lots of [other client-specific intormation](/docs/guides/maintenance/problem-scanning.md#attach-execution-clients).

:::info JSON RPC

JSON-RPC is a lightweight communication protocol encoded in JSON, allowing calls to be sent to a service or server. Each execution client exposes a related interface at port `8545` to retreive calls to interact with the Ethereum network though the local node.

:::

:::tip

By default, the [LUKSO Network Configuration](https://github.com/lukso-network/network-configs) allows to retrieve network data for all execution clients.

:::

**1. Install Querying Tool**: _Install the JSON query service for data processing from the RPC endpoint._

```sh
sudo apt install jq
```

**2. Call Execution Endpoint**: _While the node is running, call the JSON RPC of the execution client._

```sh
# Retrieve Execution Peers
curl -s -X POST -H "content-type: application/json" \
  --data '{"jsonrpc":"2.0","method":"net_peerCount","params":[],"id":1}' \
  http://localhost:8545 | jq -r '.result' | xargs printf '%d\n'
```

<details>
    <summary>Full Command Explanation</summary>

| **Command**                                                               | **Description**                                                                                                                                     |
| ------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> `curl -s -X POST -H <text> ` <br /> `--data <text> <port>` </nobr> | Executes `-X` a silent `-s` HTTP `POST` request to the given `<port>`, while attaching custom header `-H` and `--data` content as `<text>` payload. |
| <nobr> `jq -r '.result'` </nobr>                                          | Filters the raw `-r` JSON object and extracts the `.result` value of the data object.                                                               |
| <nobr> `xargs printf '%d\n'` </nobr>                                      | Converts the hexadecimal result to a human-readable decimal `%d` number.                                                                            |

</details>

The output should be something in the range from 5 to 50 peers.

```text
37
```

:::warning

If the command couldn't be executed, have a look at the [**Problem Scanning**](/docs/guides/maintenance/problem-scanning.md) page to learn how to [attach execution clients](/docs/guides/maintenance/problem-scanning.md#attach-execution-clients).

:::

</TabItem> <TabItem value="consensus" label="Consensus Peers">

The consensus endpoint allows to fetch the peer counts and lots of [other client-specific intormation](/docs/guides/maintenance/problem-scanning.md#fetch-consensus-api).

:::info REST API

A REST API is a web-based interface for querying structured data. Ethereum consensus clients expose their status and internal metrics on various ports like `3500`, `5051`, or `5052`, to allow users to access information such as synchronization progress, network stability, node metadata, or the current chain head.

:::

:::tip

By default, the [LUKSO Network Configuration](https://github.com/lukso-network/network-configs) opens the REST API ports for all consensus clients.

:::

**1. Install Querying Tool**: _Install the JSON query service for data processing from the REST API endpoint._

```sh
sudo apt install jq
```

**2. Call Endpoints**: _While the node is running, call the REST endpoint of the consensus client._

<Tabs>
  <TabItem value="teku" label="Teku">

```sh
# Check Number of Consensus Peers
curl -s http://localhost:5051/eth/v1/node/peer_count | jq
```

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
# Check Number of Consensus Peers
curl -s http://localhost:3500/eth/v1/node/peer_count | jq
```

</TabItem> <TabItem value="lighthouse-nimbus2" label="Lighthouse and Nimbus-Eth2">

```sh
# Check Number of Consensus Peers
curl -s http://localhost:5052/eth/v1/node/peer_count | jq
```

</TabItem>
</Tabs>

The output should be something in the range from 5 to 70 peers.

```text
59
```

</TabItem>
</Tabs>

If you have low or volatile peer counts, continue to stop the node and raise the peer count limits.

## 2. Stop Node Operation

Depending on your setup method, there are different ways to stop your node before configuring the IP or raising the peer limits.

<Tabs groupId="setup">
  <TabItem value="cli" label="LUKSO CLI" default>

```sh
cd <lukso-working-directory>
lukso stop
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl stop lukso-validator
```

</TabItem>
</Tabs>

<details>
<summary>Force Client Shutdown</summary>

<Tabs groupId="client">
<TabItem value="geth" label="Geth">

```sh
sudo pkill geth
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
sudo pkill erigon
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
sudo pkill nethermind
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
sudo pkill besu
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
sudo pkill teku
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
sudo pkill nimbus_beacon_node
sudo pkill nimbus_validator_client
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```sh
sudo pkill lighthouse
```

:::tip

The Lighthouse client uses a single binary for both the consensus and validator processes.

:::

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
sudo pkill prysm
sudo pkill validator
```

</TabItem>
</Tabs>

</details>

## 4. Raise Peer Limits

Most clients come with conservative default peer limits, which can be increased to maintain more simultaneous connections and improved stability and data propagation. However, peer counts above 100 can negatively affect the network topology and are not recommended.

:::tip

You should always have more than 15 stable peers after a setup time of 4 to 6 hours. If your peer count is not raising, it indicates a misconfiguration. Check that your firewall allows [all necessary client ports ](/docs/guides/client-setup/firewall-settings.md) to receive data.

:::

:::warning

Ensure your router is capable of handling higher loads and requests when raising the peer limit above the default.

:::

<Tabs groupId="network-type">
<TabItem value="execution" label="Execution Peers" default>

Depending on your execution client, the peer limit can be adjusted with different properties.

<Tabs groupId="client">
<TabItem value="geth" label="Geth">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/geth/
vim geth.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/geth/
nano geth.toml
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="erigon" label="Erigon">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/erigon/
vim erigon.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/erigon/
nano erigon.toml
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="nethermind" label="Nethermind">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/nethermind/
vim nethermind.cfg
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/nethermind/
nano nethermind.cfg
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="besu" label="Besu">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/besu/
vim besu.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/besu/
nano besu.toml
```

</TabItem>
</Tabs>

</TabItem>
</Tabs>

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path to the node folder.
- `<network>` with the name of your node's network.

:::

Change the peer limit within the settings, then save and exit the file.

<Tabs groupId="client">
<TabItem value="geth" label="Geth">

Update the _MaxPeers_ property.

```text
# Default Value
MaxPeers = 50

# Updated Value
MaxPeers = <custom-peer-limit>
```

</TabItem> <TabItem value="erigon" label="Erigon">

Update the _maxpeers_ property.

```text
# Default Value
"maxpeers" = 100

# Updated Value
"maxpeers" = <custom-peer-limit>
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

Update the _MaxActivePeers_ property within the _Network_ object.

```text
# Default Value
  "Network": {
    "MaxActivePeers": 50
  }

# Updated Value
  "Network": {
    "MaxActivePeers": <custom-peer-limit>
  }
```

</TabItem> <TabItem value="besu" label="Besu">

Update the _max-peers_ property.

```text
# Default Value
'max-peers' = 25

# Updated Value
'max-peers' = <custom-peer-limit>
```

</TabItem>
</Tabs>

:::info

Exchange `<custom-peer-limit>` with the maximum number of active peers maintained by your node.

:::

:::warning

Ensure there are no missing spaces, characters or unintended linebreaks before saving the configuration file.

:::

</TabItem> <TabItem value="consensus" label="Consensus Peers">

Depending on your consensus client, the peer limit can be adjusted with different properties.

<Tabs groupId="client">
<TabItem value="prysm" label="Prysm">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/prysm/
vim prysm.yaml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/prysm/
nano prysm.yaml
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="teku" label="Teku">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/teku/
vim teku.yaml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/teku/
nano teku.yaml
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/lighthouse/
vim lighthouse.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/lighthouse/
nano lighthouse.toml
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/nimbus2/
vim nimbus.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/nimbus2/
nano nimbus.toml
```

</TabItem>
</Tabs>

</TabItem>
</Tabs>

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path to the node folder.
- `<network>` with the name of your node's network.

:::

Change the peer count within the settings, then save and exit the file.

<Tabs groupId="client">
<TabItem value="prysm" label="Prysm">

Update the _p2p-max-peers_ property.

```text
# Default Value
p2p-max-peers: 70

# Updated Value
p2p-max-peers: <custom-peer-limit>
```

</TabItem> <TabItem value="teku" label="Teku">

Update the _p2p-peer-upper-bound_ property.

```text
# Default Value
p2p-peer-upper-bound: 100

# Updated Value
p2p-peer-upper-bound: <custom-peer-limit>
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

Update the _target-peers_ property.

```text
# Default Value
target-peers = 100

# Updated Value
target-peers = <custom-peer-limit>
```

</TabItem> <TabItem value="nimbus2" label="Nimbus">

Set the _max-peers_ property in a new line at the end of the file.

```text
max-peers = <custom-peer-limit>
```

</TabItem>
</Tabs>

:::info

Exchange `<custom-peer-limit>` with the maximum number of active peers maintained by your node.

:::

:::warning

Ensure there are no missing spaces, characters or unintended linebreaks before saving the configuration file.

:::

</TabItem>
</Tabs>

## 5. Restart the Node

Depending on your setup method, there are different ways to start your node after the IP address or peer limits have changed.

<Tabs groupId="setup">
  <TabItem value="clinode" label="LUKSO CLI Node" default>

```sh
cd <lukso-working-directory>
lukso start --checkpoint-sync
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="clivalidator" label="LUKSO CLI Validator" default>

```sh
cd <lukso-working-directory>
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync
```

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path of the node folder
- `<your-fee-recipient-address>` with the wallet address receiving staking profits

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl start lukso-validator
```

</TabItem>
</Tabs>

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

---

// File: guides/modifications/dynamic-dns

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 7.6 Dynamic DNS

Blockchain clients typically do not remain a persistent connection and rely on static or temporary IP addresses that can change over time and cause connection issues to other peers in the network. Instead of using IP addresses, Dynamic DNS can be used to link your changing IP to a fixed hostname.

:::tip

Further details about **DDNS**, setups, and providers can be found on the [**Dynamic DNS**](/docs/theory/node-operation/dynamic-dns.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

:::warning

The **Nimbus-Eth2** client does not support DDNS, as it's able to automatically detect public IP changes to update it's address accordingly. Instead of a dynamic DNS, please refer to the [**Public IP Setup**](/docs/guides/modifications/public-ip-setup.md) to configure automatic IP updates.

:::

## 1. Registration

[NO-IP](https://www.noip.com/) is one of the free and recommended DDNS providers. The service comes with plug-and-play installation and scripts, ideal for regular node setups. Within the free service, you will receive emails to extend the hostname once a month that needs to be confirmed to keep the hostname active. For little money, the domain ownership will be extended without further maintenance.

**1.1 Register on the Page**: Use _email_ and _password_ to create a new account on the [NO-IP Webpage](https://www.noip.com/).

**1.2 Choose a Hostname**: Choose a _hostname_ of your choice from the _ddns.net_ category.

**1.3 Verify your Email**: Complete the registration by confirming your email and optional payment.

**1.4 Improve Security**: Set _2FA_, a _username_, and add a _security question_ to protect against malicious actors.

:::info

Once the account is set up, the following steps are performed on your üìü **node server**.

:::

## 2. Installation

To connect your node with the [NO-IP](https://www.noip.com/) service, you have to install their package.

**2.1 Download the NOIP Software**: Get the [latest stable build](https://www.noip.com/download) of _DUC_ for _Linux_ and install it within the source directory.

```sh
# Move to Home Directory
cd

# Download Software
sudo wget --content-disposition https://www.noip.com/download/linux/latest
```

The output should be similar to this:

```sh
[DATE] [TIME] (11.8 MB/s) - ‚Äònoip-duc_3.3.0.tar.gz‚Äô saved [4896895/4896895]
```

:::tip

Always sick to stable releases. As of July 2025, _Version 3.3.0_ is the latest stable release.

:::

**2.2 Extract the Tape Archive**: Unpack the archive file using the downloaded build tool and move into it's binary.

```sh
sudo tar xf noip-duc_3.3.0.tar.gz
cd noip-duc_3.3.0/binaries
```

:::info

The `tar` command will extract `x` the tape archive into its previous packaged files `f`.

:::

:::warning

The folder name will vary depending on the installed version.

:::

**2.3 Install the Binary**: Install the executable binary file of your architecture using the system's package manager.

<Tabs groupId="architecture">
  <TabItem value="amd" label="AMD" default>

```sh
# Enhence Permissions for Local Installation
sudo chown _apt /var/lib/update-notifier/package-data-downloads/partial/

# Install Binary
sudo apt install ./noip-duc_3.3.0_amd64.deb

# Return to Home Directory
cd
```

</TabItem> <TabItem value="arm" label="ARM">

```sh
# Enhence Permissions for Local Installation
sudo chown _apt /var/lib/update-notifier/package-data-downloads/partial/

# Install Binary
sudo apt install ./noip-duc_3.3.0_arm64.deb

# Return to Home Directory
cd
```

</TabItem>
</Tabs>

:::info

You will have to enhence the permissions for the package manager's default `_apt` user to be able to write into the partial download directory, used for installing local packages that have been pre-downloaded to the system.

:::

**2.4 Verify Installation**: Check the installation folder and service files of the installed package.

```sh
dpkg -L noip-duc
```

The output should look similar to:

```text
/usr
/usr/share
/usr/share/doc
/usr/share/doc/noip-duc
/usr/share/doc/noip-duc/README.md
/lib
/lib/systemd
/lib/systemd/system
/lib/systemd/system/noip-duc.service
/usr/share/doc/noip-duc/copyright
/usr/bin
/usr/bin/noip-duc
```

**2.5 Check Executable**: Try to call the service directly from the terminal to ensure it can be called by the system.

```sh
noip-duc
```

The output should look similar to:

```text
USAGE:
    noip-duc [OPTIONS] --username <USERNAME> --password <PASSWORD>

For more information try --help
```

**2.6 Delete Installation Files**: After the installed package and executable have been verified, delete the installation files.

```sh
sudo rm -rf noip-duc_3.3.0 noip-duc_3.3.0.tar.gz
```

:::warning

The folder name will vary depending on the installed version.

:::

## 3. User Configuration

Since the service will be automatically starting and running, we need to set login credentials and preferences.

**3.1 Create User Config File**: Create the file with all your DDNS credentials and preferences using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
sudo vim /etc/default/noip-duc
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
sudo nano /etc/default/noip-duc
```

</TabItem>
</Tabs>

**3.2 Write User Configurations**: Input all your preferences and DDNS update interval, then save and exit the file.

```text
NOIP_USERNAME=<your-noip-username>
NOIP_PASSWORD=<your-noip-password>
NOIP_HOSTNAMES=<your-ddns-hostname>
NOIP_CHECK_INTERVAL=5m
```

:::info

The following properties need to be exchanged:

- `<your-noip-username>` with your NOIP email
- `<your-noip-password>` with your NOIP password
- `<your-ddns-hostname>` with your DDNS hostname ending on `.ddns.net`

:::

**3.3 Update Permissions**: For better security, locking down the permissions so only the root user can access credentials.

```sh
sudo chmod 600 /etc/default/noip-duc
sudo chown root:root /etc/default/noip-duc
```

## 4. Service Configuration

The setup already installed a default NOIP service file that can be used to allow automatic startups during boot and restarts on failures. We can further modify the default service file to also check for logging, an online network connection.

**4.1 Open Service Config File**: Further customize the service file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
sudo vim /lib/systemd/system/noip-duc.service
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
sudo nano /lib/systemd/system/noip-duc.service
```

</TabItem>
</Tabs>

**4.2 Update Service Configurations**: Add further preferences for network autages and restarts, then save and exit the file.

:::tip

Further details on Journal and System Logging can be found on the [**Utility Tools**](/docs/theory/node-operation/utility-tools.md) page in the the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

<Tabs groupId="logging-tool">
  <TabItem value="journal" label="Journal Logging" default>

```text
[Unit]
Description=No-IP Dynamic Update Client
After=network.target auditd.service syslog.target network-online.target
Wants=network-online.target

[Service]
EnvironmentFile=/etc/default/noip-duc
ExecStart=/usr/bin/noip-duc
Restart=on-failure
Type=simple
StandardOutput=journal
StandardError=journal

[Install]
WantedBy=multi-user.target
```

</TabItem> <TabItem value="system" label="System Logging">

```text
[Unit]
Description=No-IP Dynamic Update Client
After=network.target auditd.service syslog.target network-online.target
Wants=network-online.target

[Service]
EnvironmentFile=/etc/default/noip-duc
ExecStart=/usr/bin/noip-duc
Restart=on-failure
Type=simple
StandardOutput=syslog
StandardError=syslog

[Install]
WantedBy=multi-user.target
```

</TabItem>
</Tabs>

<details>
    <summary>Full Property Explanation</summary>

| Property          | Description                                                                                                                                                                                                                                                                                                                                                      |
| ----------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `Description`     | A human-readable description of the service shown in `systemctl status`.                                                                                                                                                                                                                                                                                         |
| `After`           | - `network.target`: Ensures networking setup enabled before service is started. <br /> - `auditd.service`: Ensures audit daemon is initialized before service is started. <br /> - `syslog.target`: Ensures system logging is ready before service is started. <br /> - `network-online.target`: Waits for network to be fully online before service is started. |
| `Wants`           | Tries to fullfil `network-online.target` but might start even if there is a temporary downtime.                                                                                                                                                                                                                                                                  |
| `EnvironmentFile` | Path to the `/lib/systemd/system/noip-duc.service` configuration file.                                                                                                                                                                                                                                                                                           |
| `ExecStart`       | Link to binary at `/usr/bin/noip-duc`, started with the terminal command of the service.                                                                                                                                                                                                                                                                         |
| `Restart`         | Restarts the service `on-failure` for a variety of reasons.                                                                                                                                                                                                                                                                                                      |
| `Type`            | Indicates running at a `simple` service in the foreground without forking.                                                                                                                                                                                                                                                                                       |
| `StandardOutput`  | Sends regular service logs to the journal or syslog system.                                                                                                                                                                                                                                                                                                      |
| `StandardError`   | Sends error service logs to the journal or syslog system.                                                                                                                                                                                                                                                                                                        |
| `WantedBy`        | Starts the service automatically during the system's normal multi-user boot.                                                                                                                                                                                                                                                                                     |

</details>

:::warning

Ensure there are no missing or unintended spaces, characters or linebreaks before saving the service configuration.

:::

## 5. DDNS Startup

After both, the user and service configuration are set in place, we can start the DDNS tool.

**5.1 Reaload Service Configs**: Reload the previously modified system manager configuration for all services.

```sh
sudo systemctl daemon-reload
```

**5.2 Enable Autostarts**: Use the system control to create a symbolic link to enable startups during boot.

```sh
sudo systemctl enable noip-duc
```

The output should be similar to:

```text
Created symlink /etc/systemd/system/noip.service ‚Üí /lib/systemd/system/noip-duc.service.
Created symlink /etc/systemd/system/multi-user.target.wants/noip-duc.service ‚Üí /lib/systemd/system/noip-duc.service.
```

**5.3 Start the Service**: Use the system control to start the DDNS service with the configured user credentials and preferences.

```sh
sudo systemctl start noip-duc
```

**5.4 Verify Status**: Use the system control to fetch the current status and check if it's running correctly.

```sh
sudo systemctl status noip-duc
```

:::info

The status will display whether it is active, enabled, or disabled and show any recent log entries.

:::

The output should look similar to this:

```text
‚óè noip-duc.service - No-IP Dynamic Update Client
     Loaded: loaded (/lib/systemd/system/noip-duc.service; enabled; vendor preset: enabled)
     Active: active (running) since [DATE] UTC; [TIME] ago
   Main PID: 288425 (noip-duc)
      Tasks: 1 (limit: 38033)
     Memory: 388.0K
        CPU: 7ms
     CGroup: /system.slice/noip-duc.service
             ‚îî‚îÄ288425 /usr/bin/noip-duc

[DATE] [TIME] [USER] systemd[1]: Started No-IP Dynamic Update Client.
[DATE] [TIME] [USER] noip-duc[288425]: [DATE-TIME INFO  noip_duc::public_ip] Attempting to get IP with method Dns(No-IP Anycast DNS Tools)
[DATE] [TIME] [USER] noip-duc[288425]: [DATE-TIME INFO  noip_duc::observer] got new ip; current=[YOUR_PUBLIC_IP], previous=0.0.0.0
[DATE] [TIME] [USER] noip-duc[288425]: [DATE-TIME INFO  noip_duc::observer] update successful; current=[YOUR_PUBLIC_IP], previous=0.0.0.0
[DATE] [TIME] [USER] noip-duc[288425]: [DATE-TIME INFO  noip_duc::observer] checking ip again in 5m
...
```

Remember your DDNS hostname or copy it to a notepad, as it will be necessary for the client updates.

## 6. Stop Node Operation

Depending on your setup method, there are different ways to stop your node before linking your DDNS hostname.

<Tabs groupId="setup">
  <TabItem value="cli" label="LUKSO CLI" default>

```sh
cd <lukso-working-directory>
lukso stop
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl stop lukso-validator
```

</TabItem>
</Tabs>

<details>
<summary>Force Client Shutdown</summary>

<Tabs>
<TabItem value="geth" label="Geth">

```sh
sudo pkill geth
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
sudo pkill erigon
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
sudo pkill nethermind
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
sudo pkill besu
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
sudo pkill teku
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```sh
sudo pkill lighthouse
```

:::tip

The Lighthouse client uses a single binary for both the consensus and validator processes.

:::

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
sudo pkill prysm
sudo pkill validator
```

</TabItem>
</Tabs>

</details>

## 7. Client DNS Update

Depending on your consensus client, the DDNS hostname can be set with different properties.

<Tabs groupId="client">
<TabItem value="prysm" label="Prysm">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/prysm/
vim prysm.yaml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/prysm/
nano prysm.yaml
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="teku" label="Teku">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/teku/
vim teku.yaml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/teku/
nano teku.yaml
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/lighthouse/
vim lighthouse.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/lighthouse/
nano lighthouse.toml
```

</TabItem>
</Tabs>

</TabItem>
</Tabs>

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path to the node folder.
- `<network>` with the name of your node's network.

:::

Set the DDNS hostname within the settings, then save and exit the file.

<Tabs groupId="client">
<TabItem value="prysm" label="Prysm">

In case the _p2p-host-ip_ property is set, disable it by putting a hash _#_ in front:

```text
# Previous Value Examples
p2p-host-ip: '0.0.0.0'
p2p-host-ip: '<your-ip-address>'

# Updated Value
#p2p-host-ip: '0.0.0.0'
#p2p-host-ip: '<your-ip-address>'
```

Then add the _p2p-host-dns_ property into a new line of the file:

```text
# Added Property
p2p-host-dns: '<your-ddns-hostname>'
```

</TabItem> <TabItem value="teku" label="Teku">

Update the _p2p-advertised-ip_ property.

```text
# Default Value Examples
p2p-advertised-ip: 0.0.0.0
p2p-advertised-ip: '<your-ip-address>'

# Updated Value
p2p-advertised-ip: '<your-ddns-hostname>'
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

Update the _enr-address_ property.

```text
# Default Value Examples
enr-address = "0.0.0.0"
enr-address = '<your-ip-address>'

# Updated Value
enr-address = '<your-ddns-hostname>'
```

</TabItem>
</Tabs>

:::info

Exchange `<your-ddns-hostname>` with the actual address of the DDNS hostname ending on `.ddns.net`.

:::

:::warning

Ensure there are no missing spaces, characters or unintended linebreaks before saving the configuration file.

:::

## 8. Restart the Node

Depending on your setup method, there are different ways to start your node after the DDNS hostname was added.

<Tabs groupId="setup">
  <TabItem value="clinode" label="LUKSO CLI Node" default>

```sh
cd <lukso-working-directory>
lukso start --checkpoint-sync
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="clivalidator" label="LUKSO CLI Validator" default>

```sh
cd <lukso-working-directory>
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync
```

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path of the node folder
- `<your-fee-recipient-address>` with the wallet address receiving staking profits

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl start lukso-validator
```

</TabItem>
</Tabs>

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

:::tip

You should now have a stable and permanent blockchain connection. Wait some hours before [rechecking your peer count](/docs/guides/modifications/peer-count-limits.md).

:::

## Maintenance

Proper maintenance ensures that all the components are working as intended and can be updated on the fly.

**Logging**: Check the latest status of the system service.

<Tabs groupId="logging-tool">
  <TabItem value="journal" label="Journal Logging" default>

```sh
sudo journalctl -f -u noip-duc
```

</TabItem> <TabItem value="system" label="System Logging">

```sh
sudo tail -f /var/log/syslog | grep noip-duc
```

</TabItem>
</Tabs>

:::tip

Further details about checking client logs files can be found on the [**Problem Scanning**](/docs/guides/maintenance/problem-scanning.md) page.

:::

**Starting**: If you made any changes or updates to configuration, reload the system daemon and start the node.

```sh
sudo systemctl daemon-reload
sudo systemctl restart noip-duc
```

**Stopping**: You can stop all the node clients and parent processes using the system control.

```sh
sudo systemctl stop noip-duc
```

:::tip

Further information about system control or logging can be found on the [**Utility Tools**](/docs/theory/node-operation/utility-tools.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

## Revert Setup

If something went wrong, you can remove the service and related files all together.

**1. Stop and Disable Service**: Stop the tool and remove it's service link from the system's boot.

```sh
sudo systemctl stop noip-duc
sudo systemctl disable noip-duc
```

**2. Remove the Service File**: Delete the configuration and reload the system daemon.

```sh
sudo rm /lib/systemd/system/noip-duc.service
sudo systemctl daemon-reload
```

**3. Remove Software Package**: Delete the binary and optional configuration files using the package management tool.

```sh
# Remove Software
sudo apt remove noip-duc

# Remove Software and Configuration
sudo apt purge noip-duc
```

**4. Update Client Configuration**: Stop the node, update your DDNS or IP address, and restart the clients.

---

// File: guides/modifications/service-automation

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 7.7 Service Automation

By default, blockchain clients are not automatically starting whenever there has been a power outage or crash on your node system. This means additional manual work by logging into the node and restarting clients or services. As the [LUKSO CLI](https://github.com/lukso-network/tools-lukso-cli) manages all blockchain clients in the background, we can add a startup script to run every time on boot.

:::tip

Automatically restarting individual execution, consensus, or validator clients after failure requires a üê≥ [Docker](/docs/theory/node-operation/client-setups.md) or üóÇÔ∏è [Custom Setup](/docs/theory/node-operation/client-setups.md). However, [**Grafana Notifications**](/docs/guides/alert-systems/grafana-notifications.md) will inform you when specific processes stopped working.

:::

:::warning

Automation is only possible from [LUKSO CLI](https://github.com/lukso-network/tools-lukso-cli) _Version 0.8.1_ onwards. Make sure to [update to the latest version](http://localhost:3000/docs/guides/maintenance/client-updates).

:::

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Stop Node Operation

Depending on your setup method, there are different ways to stop your node before applying updates.

<Tabs groupId="setup">
  <TabItem value="cli" label="LUKSO CLI" default>

```sh
cd <lukso-working-directory>
lukso stop
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl stop lukso-validator
```

</TabItem>
</Tabs>

<details>
<summary>Force Client Shutdown</summary>

<Tabs>
<TabItem value="geth" label="Geth">

```sh
sudo pkill geth
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
sudo pkill erigon
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
sudo pkill nethermind
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
sudo pkill besu
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
sudo pkill teku
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
sudo pkill nimbus_beacon_node
sudo pkill nimbus_validator_client
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```sh
sudo pkill lighthouse
```

:::tip

The Lighthouse client uses a single binary for both the consensus and validator processes.

:::

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
sudo pkill prysm
sudo pkill validator
```

</TabItem>
</Tabs>

</details>

## 2. Create System User

As the staking node requests the validator wallet's password every time during startup, we have to write the password into a file, similar to how credentials are handled within the [Dynamic DNS](/docs/guides/modifications/dynamic-dns.md) setup. To mitigate security risks, a separate user will be added to exclusively run the node service and read the password file.

Running services as a system user with minimal privileges is a typical best practice, as the service is not allowed to write outside of the specific client folders. It limits the potential damage if the software is somehow compromised, and hides the private credentials for the rest of the system. The node's user won't be able to write to directories on the system or execute commands. Use the system's user creation tool to add a new one.

```sh
sudo adduser --system lukso-validator-worker --group --no-create-home
```

<details>
    <summary>Full Command Explanation</summary>

| Flag                              | Description                                                                                     |
| --------------------------------- | ----------------------------------------------------------------------------------------------- |
| <nobr> `--system` </nobr>         | Creates a system user, used to run services and daemons rather than for people to log in with.  |
| <nobr> `--group` </nobr>          | Creates a new group with the same name as the user.                                             |
| <nobr> `--no-create-home` </nobr> | Prevents the creation of a home directory, as the user is only meant to run a specific service. |

</details>

If you want to confirm that the user has been created, you can search for it within the password file, housing all essential information for each user account. Using the search tool _grep_, we can check if the user exists within the file.

```sh
grep "lukso-validator-worker" /etc/passwd
```

The output should look similar to this:

```text
lukso-validator-worker:x:120:126::/home/lukso-validator-worker:/usr/sbin/nologin
```

## 3. Add Password File

If you run a validator node, you will need to create two new files: one for the password and one for the service automation. Start by creating a new directory for these service files directly within your node folder, where the new system user will have access to.

:::tip

This step can be skipped for regular nodes that do not run validators.

:::

```sh
# Move to Home Directory
cd

# Open Node Folder
cd <lukso-working-directory>

# Create Service Folder
mkdir static

# Move into Folder
cd static
```

Continue to add a password file using your preferred text editor, write down your password on a single line, then save and exit.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
# Create Password File
vim ./<your-filename>

# Example Name
vim ./client_dependencies
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
# Create Password File
nano ./<your-filename>

# Example Name
nano ./client_dependencies
```

</TabItem>
</Tabs>

:::info

Exchange `<your-filename>` with a generic name, so even with access, users dont immediately know there is's a password.

:::

:::tip

Access to this password file will be restricted within the [Configure Access Rights](#5-restrict-access-rights) section.

:::

## 4. Add Startup Script

After creating the password file, you can create the second service automation file, starting up the LUKSO CLI with your preferred settings and checking the network connection before doing so. Verifying that the internet connection is up before the clients are started is essential to avoid stalls or manual interventions.

If there was a power outage, the node might resume work before the router was restarted or could even connect to the internet service provider. Instead, the startup script can try to ping a public Google service first and resume work once the request was fulfilled. Otherwise, the script will wait retry. Start by creating the startup file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
vim ./lukso_startup.sh
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
nano ./lukso_startup.sh
```

</TabItem>
</Tabs>

Then continue to write down or paste the startup schedule:

<Tabs groupId="network-type">
  <TabItem value="mainnet-node" label="Mainnet Node" default>

```sh
#!/bin/bash
# Try to ping Google Server
while ! ping -c1 google.com &>/dev/null
do
    echo "Internet down. Google could not be pinged, retrying in 5 seconds."
    sleep 5
done
echo "Internet up. Starting the LUKSO Mainnet Node."
# If internet is up, continue with next command
exec /usr/local/bin/lukso start \
        --checkpoint-sync
```

</TabItem> <TabItem value="testnet-node" label="Testnet Node">

```sh
#!/bin/bash
# Try to ping Google Server
while ! ping -c1 google.com &>/dev/null
do
    echo "Internet down. Google could not be pinged, retrying in 5 seconds."
    sleep 5
done
echo "Internet up. Starting the LUKSO Testnet Node."
# If internet is up, continue with next command
exec /usr/local/bin/lukso start \
        --testnet \
        --checkpoint-sync
```

</TabItem>
  <TabItem value="mainnet-validator" label="Mainnet Validator" default>

```sh
#!/bin/bash
# Try to ping Google Server
while ! ping -c1 google.com &>/dev/null
do
    echo "Internet down. Google could not be pinged, retrying in 5 seconds."
    sleep 5
done
echo "Internet up. Starting the LUKSO Mainnet Validator."
# If internet is up, continue with next command
exec /usr/local/bin/lukso start \
        --validator \
        --validator-wallet-password ./static/<your-generic-password-file> \
        --transaction-fee-recipient "<your-fee-recipient-address>" \
        --checkpoint-sync
```

:::info

Exchange the following properties:

- `<your-generic-password-file>` with the name of your password file
- `<your-fee-recipient-address>` with your wallet address to receive validator income.

:::

</TabItem> <TabItem value="testnet-validator" label="Testnet Validator">

```sh
#!/bin/bash
# Try to ping Google Server
while ! ping -c1 google.com &>/dev/null
do
    echo "Internet down. Google could not be pinged, retrying in 5 seconds."
    sleep 5
done
echo "Internet up. Starting the LUKSO Testnet Validator."
# If internet is up, continue with next command
exec /usr/local/bin/lukso start \
        --testnet \
        --validator \
        --validator-wallet-password ./static/<your-generic-password-file> \
        --transaction-fee-recipient "<your-fee-recipient-address>" \
        --checkpoint-sync
```

:::info

Exchange the following properties:

- `<your-generic-password-file>` with the name of your password file
- `<your-fee-recipient-address>` with your wallet address to receive validator income.

:::

</TabItem>
</Tabs>

<details>
    <summary>Full Command Explanation</summary>

| Parameter                                  | Description                                                       |
| ------------------------------------------ | ----------------------------------------------------------------- |
| <nobr> `c1` </nobr>                        | Specifies to send a single package before stopping.               |
| <nobr> `&>/dev/null` </nobr>               | Discard the output of the ping, as its not needed.                |
| <nobr> `testnet` </nobr>                   | Runs the node on the testnet instead of the mainnet.              |
| <nobr> `validator` </nobr>                 | Runs the node with validator keys to participate in staking.      |
| <nobr> `validator-wallet-password` </nobr> | Dymanic path to the password file based on the script's location. |
| <nobr> `transaction-fee-recipient` </nobr> | Attaches the wallet address that will receive staking rewards.    |
| <nobr> `checkpoint-sync` </nobr>           | Speeds up synchronization by lazy-loading full blockchain data.   |

</details>

:::tip

Additional flags can be attached to further customize your node, like [configuring the slasher service](./slasher-configuration.md), [specifying a node name](./custom-node-name.md), or [setting a validator graffiti](validator-graffiti.md). The startup script will automatically read all the client configuration files within the node folder. However, keep in mind that you will always have to add another backslash `\` if you attach several flags across multiple lines.

:::

:::warning

In case you are modifying the startup script, make sure to [restrict permissions](#5-restrict-access-rights) as regular user wont have access to it.

:::

## 5. Restrict Access Rights

To protect sensitive credentials and ensure system security, we need to restrict file access. Additional permission management prevents unauthorized access to the password file and startup script to ensure only the dedicated user can start the node.

:::info

Within the commands, exchange the following properties:

- `<user-name>` with the name of the user you're logging into the node.
- `<lukso-working-directory>` with the name of your node folder
- `<your-generic-password-file>` with the name of your password file

:::

**5.1 Change Node Folder Owner**: Set the new _lukso-validator-worker_ as owner of all node directory files and configs.

```sh
sudo chown -R lukso-validator-worker:lukso-validator-worker /home/<user-name>/<lukso-working-directory>
```

**5.2 Change LUKSO CLI Owner**: Set the new _lukso-validator-worker_ as owner of the LUKSO CLI and binaries.

```sh
sudo chown lukso-validator-worker:lukso-validator-worker /usr/local/bin/lukso
```

**5.3 Grant Node Folder Access**: Ensure the regular user still has permission to access logs and the working directory.

```sh
sudo chmod -R 750 /home/<user-name>/<lukso-working-directory>
sudo chmod 755 /home/<user-name>/<lukso-working-directory>
```

**5.4 Restrict Password File**: Ensure that only the _lukso-validator-worker_ can read the password to start the node.

```sh
sudo chmod 400 /home/<user-name>/<lukso-working-directory>/static/<your-generic-password-file>
```

**5.5 Restrict Startup Script**: Ensure that only the _lukso-validator-worker_ can start up the node.

```sh
sudo chmod 500 /home/<user-name>/<lukso-working-directory>/static/lukso_startup.sh
```

**5.6 Check User Access**: Ensure that the _lukso-validator-worker_ can access the full path to the node directory.

```sh
namei -l /home/<user-name>/<lukso-working-directory>
```

The output should look like the following:

```text
f: /home/<user-name>/<lukso-working-directory>
drwxr-xr-x root                    root                    /
drwxr-xr-x root                    root                    home
drwxr-x--- <user-name>             <user-name>             <user-name>
drwxr-xr-x lukso-validator-worker  lukso-validator-worker  <lukso-working-directory>
```

:::warning

By looking at the first column, you need to verify that users can read and access `r-x` all parent folders of the node folder. Without access `---` to intermediate directories, they cant access any of the underlying folders they became the owner of.

:::

**5.7 Check User Access**: Grant access to the _user_ directory and verify _lukso-validator-worker_ can access the node folder.

```sh
sudo chmod 755 /home/<user-name>
namei -l /home/<user-name>/<lukso-working-directory>
```

The output should look like the following:

```text
f: /home/<user-name>/<lukso-working-directory>
drwxr-xr-x root                    root                    /
drwxr-xr-x root                    root                    home
drwxr-xr-x <user-name>             <user-name>             <user-name>
drwxr-xr-x lukso-validator-worker  lukso-validator-worker  <lukso-working-directory>
```

## 6. Configure Service File

After the user, files, and permissions are in place, you can configure the actual system service that is going to execute our startup script once the system boots. Create a new service file in the system's directory using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
sudo vim /etc/systemd/system/lukso-validator.service
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
sudo nano /etc/systemd/system/lukso-validator.service
```

</TabItem>
</Tabs>

Then continue to write down or paste the service properties and descriptions for your preferred logging tool.

:::tip

Further details on Journal and System Logging can be found on the [**Utility Tools**](/docs/theory/node-operation/utility-tools.md) page in the the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

<Tabs groupId="logging-tool">
  <TabItem value="journal" label="Journal Logging" default>

```text
[Unit]
Description=LUKSO Validator Service
Documentation=https://github.com/lukso-network/tools-lukso-cli
Wants=network-online.target
After=network-online.target

[Service]
User=lukso-validator-worker
Group=lukso-validator-worker
Type=oneshot
RemainAfterExit=yes
WorkingDirectory=/home/<user-name>/<lukso-working-directory>
ExecStart=/home/<user-name>/<lukso-working-directory>/static/lukso_startup.sh
ExecStop=/usr/local/bin/lukso stop
SyslogIdentifier=lukso-validator
StandardOutput=journal
StandardError=journal

[Install]
WantedBy=multi-user.target
```

</TabItem> <TabItem value="system" label="System Logging">

```text
[Unit]
Description=LUKSO Validator Service
Documentation=https://github.com/lukso-network/tools-lukso-cli
Wants=network-online.target
After=network-online.target

[Service]
User=lukso-validator-worker
Group=lukso-validator-worker
Type=oneshot
RemainAfterExit=yes
WorkingDirectory=/home/<user-name>/<lukso-working-directory>
ExecStart=/home/<user-name>/<lukso-working-directory>/static/lukso_startup.sh
ExecStop=/usr/local/bin/lukso stop
SyslogIdentifier=lukso-validator
StandardOutput=syslog
StandardError=syslog

[Install]
WantedBy=multi-user.target
```

</TabItem>
</Tabs>

<details>
    <summary>Full Property Explanation</summary>

| Property           | Description                                                                                      |
| ------------------ | ------------------------------------------------------------------------------------------------ |
| `Description`      | A human-readable label for the service, shown in `systemctl status`.                             |
| `Documentation`    | URL to relevant documentation for setup or troubleshooting.                                      |
| `Wants`            | The service should try to start `network-online.target` before starting the validator service.   |
| `After`            | Ensures the service starts only after the network is online via `network-online.target`.         |
| `User`             | Executes the service as the `lukso-validator-worker` user.                                       |
| `Group`            | Executes the service under the `lukso-validator-worker` group.                                   |
| `Type`             | Set to `oneshot`, meaning the command runs once and considers the service to be started.         |
| `RemainAfterExit`  | Keeps the service in an active state, even when exited, to save logs for long-running processes. |
| `WorkingDirectory` | Defines that the service command will be executed in the `<lukso-working-directory>`.            |
| `ExecStart`        | The `lukso_startup.sh` script that will be started from the service.                             |
| `ExecStop`         | Command to stop the validator service using `lukso stop` once clients are up and running.        |
| `SyslogIdentifier` | Tags logs from the service with `lukso-validator` to help distinguish them.                      |
| `StandardOutput`   | Sends regular service logs to the journal or syslog system.                                      |
| `StandardError`    | Sends error service logs to the journal or syslog system.                                        |
| `WantedBy`         | Binds the service to the `multi-user.target`, so it starts during all boot processes.            |

</details>

:::info

Exchange the following properties:

- `<user-name>` with the name of the user you're logging into the node.
- `<lukso-working-directory>` with the name of your node folder

:::

:::warning

Ensure there are no missing or unintended spaces, characters or linebreaks before saving the service configuration.

:::

:::danger

In case you set different `User` and `Group` names, ensure that they are spelled correctly within the service file. If the exact user name cant be found, system services will fall back to use the `root` permissions, creating security risks.

:::

After you saved and exited the service file, you will need to update the system manager configuration, ensuring that all file changes are included within the current system setup. Use the system control command to reload them.

```sh
sudo systemctl daemon-reload
```

## 7. Restart the Node

After setting up the service and configuring file access, you can enable and start the system service.

**7.1 Enable Start Boot**: Enable autostarts of the node process during system boot.

```sh
sudo systemctl enable lukso-validator
```

The output should look similar to this:

```text
Created symlink /etc/systemd/system/multi-user.target.wants/validator-validator.service ‚Üí /etc/systemd/system/lukso-validator.service.
```

**7.2 Startup Service**: Once enabled, you can start the automated node startup using the system control command:

```sh
sudo systemctl start lukso-validator
```

## 8. Check Service Status

You can fetch the current status from the system control to check if the node service is running and configured correctly. The command will display whether it is active, enabled, or disabled and show recent log entries.

```sh
sudo systemctl status lukso-validator
```

The output should look similar to this:

```text
‚óè validator.service - LUKSO Validator Node
     Loaded: loaded (/etc/systemd/system/validator.service; enabled; vendor preset: enabled)
     Active: active (exited) since [DATE] UTC; [TIME] ago
       Docs: https://github.com/lukso-network/tools-lukso-cli
   Main PID: 9096 (code=exited, status=0/SUCCESS)
      Tasks: 26 (limit: 4694)
     Memory: 1.1G
     CGroup: /system.slice/validator.service
             [PID] geth --config=./configs/testnet/geth/geth.toml
             ‚îú‚îÄ[PID] prysm --log-file=./testnet-logs/prysm_2025-06-06_14-43-01.log --accept-terms-of-use --config-file=./configs/testn>
             ‚îî‚îÄ[PID] validator --accept-terms-of-use --config-file=./configs/testnet/prysm/validator.yaml --log-file=./testnet-logs/va>

[DATE] [TIME] [USER] validator[9096]: time="2025-06-06T14:43:13Z" level=info msg="‚úÖ  Validator started! Use 'luk>
[DATE] [TIME] [USER] validator[9096]: time="2025-06-06T14:43:13Z" level=info msg="üéâ  Clients have been started. >
...
[DATE] [TIME] [USER] systemd[1]: Finished LUKSO Validator Node.
```

:::tip

You can still check the status of the node using the [LUKSO CLI](https://github.com/lukso-network/tools-lukso-cli), however, you always have to use the superuser permission.
As you have a separate user to run the service, only _root_ or _lukso-validator-worker_ are permitted to fetch the service information like `lukso status` or `lukso logs`. By default, the CLI will always show the processes as stopped, even if they are running.

:::

```sh
# Move to Home Directory
cd

# Enter Node Folder
cd <lukso-working-directory>

# Check Processes
sudo lukso status
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

Depending on the clients you use, output should look similar to this:

```sh
INFO[0000] PID 9409 - Execution ([EXECUTION_CLIENT_NAME]): Running üü¢
INFO[0000] PID 9419 - Consensus ([CONSENSUS_CLIENT_NAME]): Running üü¢
INFO[0000] PID 9426 - Validator ([VALIDATOR_CLIENT_NAME]): Running üü¢
```

## Maintenance

Proper maintenance ensures that all the components are working as intended and can be updated on the fly.

:::warning

The service starts the [LUKSO CLI](https://github.com/lukso-network/tools-lukso-cli) as if its directly run within your node folder, just by a specific user with limited permissions and the exclusive right to view the validator password. All CLI commands can be executed as before using root permissions, however, never execute `sudo lukso start`, as it will restart the clients with full root privilages, entailing security risks.

:::

**Logging**: Check the latest status of the system service.

<Tabs groupId="logging-tool">
  <TabItem value="journal" label="Journal Logging" default>

```sh
sudo journalctl -f -u lukso-validator
```

</TabItem> <TabItem value="system" label="System Logging">

```sh
sudo tail -f /var/log/syslog | grep lukso-validator
```

</TabItem>
</Tabs>

:::tip

Further details about checking client logs files can be found on the [**Problem Scanning**](/docs/guides/maintenance/problem-scanning.md) page.

:::

**Starting**: If you made any changes or updates to configuration, reload the system daemon and start the node.

```sh
sudo systemctl daemon-reload
sudo systemctl restart lukso-validator
```

**Stopping**: You can stop all the node clients and parent processes using the system control.

```sh
sudo systemctl stop lukso-validator
```

:::tip

Further information about system control or logging can be found on the [**Utility Tools**](/docs/theory/node-operation/utility-tools.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

## Revert Setup

If something went wrong, you can remove the user or delete the service and related files all together.

:::info

Within the commands, exchange the following properties:

- `<user-name>` with the name of the user you're logging into the node.
- `<lukso-working-directory>` with the name of your node folder

:::

**1. Stop and Disable Service**: Stop the clients and remove it's service link from the system's boot.

```sh
sudo systemctl stop lukso-validator
sudo systemctl disable lukso-validator
```

**2. Change Folder Ownership**: Change the owner of the node folder back to your regular node user.

```sh
sudo chown -R <user-name>:<user-name> /home/<user-name>/<your-working-directory>
```

**3. Change LUKSO CLI Ownership**: Revert the ownership of the LUKSO CLI back to as it was before.

```sh
sudo chown root:root /usr/local/bin/lukso
```

**4. Restrict User Directory**: Set exclusively access to your user's home directory again.

```sh
sudo chmod 750 /home/<user-name>
```

**5. Remove System User**: Remove the _lukso-validator-worker_ user, group, and files, so there is no orphaned data.

```sh
sudo deluser --remove-all-files lukso-validator-worker
sudo delgroup lukso-validator-worker
```

**6. Remove Service File**: Delete the configurations and reload the system daemon.

```sh
sudo rm /etc/systemd/system/lukso-validator.service
sudo systemctl daemon-reload
```

**7. Remove Startup Files**: Delete the password file and startup script within the node folder.

```sh
rm -rf <lukso-working-directory>/static
```

---

// File: guides/modifications/execution-dashboard

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 7.8 Execution Dashboard

To list your node on an [Execution Status Page](/docs/guides/monitoring/external-monitoring.md#execution-status-page), you can add a ETHStats secret to your execution client to monitor versions, latencies, peers, synced blocks, and pending transactions based on their current [gas price configuration](/docs/guides/maintenance/gas-price-configuration.md). You node will then begin to synchronize data with the dashboard service, so the service can be monitored from any device.

| Dashboard                                                                         | Maintainer | Access  | Credentials                                                                                                                               |
| --------------------------------------------------------------------------------- | ---------- | ------- | ----------------------------------------------------------------------------------------------------------------------------------------- |
| [Mainnet Execution Status Page ‚Üó](https://stats.execution.mainnet.lukso.network/) | LUKSO Team | Private | **Server:** `stats.execution.mainnet.lukso.network` <br/> **Secret**: _Apply as core contributor via [Discord](https://discord.gg/lukso)_ |
| [Testnet Execution Status Page ‚Üó](https://stats.execution.testnet.lukso.network/) | LUKSO Team | Private | **Server:** `stats.execution.testnet.lukso.network` <br/> **Secret**: _Apply as Testnet operator via [Discord](https://discord.gg/lukso)_ |
| [Stakingverse Status Page ‚Üó](https://community.stats.execution.stakingverse.io/)  | Community  | Public  | **Server:** `community.stats.execution.stakingverse.io` <br/> **Secret**: `Stakingverse-JordyDutch-69420`                                 |

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Stop Node Operation

Depending on your setup method, there are different ways to stop your node before listing your node on a dashboard.

<Tabs groupId="setup">
  <TabItem value="cli" label="LUKSO CLI" default>

```sh
cd <lukso-working-directory>
lukso stop
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl stop lukso-validator
```

</TabItem>
</Tabs>

<details>
<summary>Force Client Shutdown</summary>

<Tabs>
<TabItem value="geth" label="Geth">

```sh
sudo pkill geth
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
sudo pkill erigon
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
sudo pkill nethermind
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
sudo pkill besu
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
sudo pkill teku
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
sudo pkill nimbus_beacon_node
sudo pkill nimbus_validator_client
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```sh
sudo pkill lighthouse
```

:::tip

The Lighthouse client uses a single binary for both the consensus and validator processes.

:::

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
sudo pkill prysm
sudo pkill validator
```

</TabItem>
</Tabs>

</details>

## 2. Add ETHStats Secret

You can either set your dashboard credentials via startup flags or persistently within the configuration files of your execution client. If you only want to check your node temporarily, using the flag is recommended, as it will only persist until the next restart of the node.

<Tabs groupId="configuration">
  <TabItem value="flag" label="Setting a Startup Flag" default>

Depending on your setup method, there are different ways to pass down the ETHStats flag using the [LUKSO CLI](https://github.com/lukso-network/tools-lukso-cli).

<Tabs groupId="setup">
<TabItem value="clinode" label="LUKSO CLI Node" default>

Every execution client has a individual flag to set the ETHStats Secret during startup.

<Tabs>
<TabItem value="geth" label="Geth">

```sh
cd <lukso-working-directory>

# Start the Mainnet Node with a ETHStats Secret
lukso start --checkpoint-sync --geth-ethstats "<your-dashboard-name>:<ethstats-secret>@<ethstats-server>"

# Start the Testnet Node with a ETHStats Secret
lukso start --testnet --checkpoint-sync --geth-ethstats "<your-dashboard-name>:<ethstats-secret>@<ethstats-server>"
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
cd <lukso-working-directory>

# Start the Mainnet Node with a ETHStats Secret
lukso start --checkpoint-sync --erigon-ethstats "<your-dashboard-name>:<ethstats-secret>@<ethstats-server>"

# Start the Testnet Node with a ETHStats Secret
lukso start --testnet --checkpoint-sync --erigon-ethstats "<your-dashboard-name>:<ethstats-secret>@<ethstats-server>"
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
cd <lukso-working-directory>

# Start the Mainnet Node with Custom Name
lukso start --checkpoint-sync --nethermind-ethstats-enabled=true --nethermind-ethstats-name "<your-dashboard-name>" --nethermind-ethstats-secret "<ethstats-secret>" --ethstats-server "wss://<ethstats-server>"

# Start the Testnet Node with Custom Name
lukso start --testnet --checkpoint-sync --nethermind-ethstats-enabled=true --nethermind-ethstats-name "<your-dashboard-name>" --nethermind-ethstats-secret "<ethstats-secret>" --nethermind-ethstats-server "wss://<ethstats-server>"
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
cd <lukso-working-directory>

# Start the Mainnet Node with a ETHStats Secret
lukso start --checkpoint-sync --besu-ethstats "<your-dashboard-name>:<ethstats-secret>@<ethstats-server>"

# Start the Testnet Node with a ETHStats Secret
lukso start --testnet --checkpoint-sync --besu-ethstats "<your-dashboard-name>:<ethstats-secret>@<ethstats-server>"
```

</TabItem>
</Tabs>

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path of the node folder
- `<your-dashboard-name>` with the node name to show up on the dashboard
- `ethstats-secret` with the actual secret of your dashboard server
- `ethstats-server` with the address of your dashboard server

:::

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

</TabItem> <TabItem value="clivalidator" label="LUKSO CLI Validator" default>

Every execution client has a individual flag to set the EthStats Secret during startup.

<Tabs>
<TabItem value="geth" label="Geth">

```sh
cd <lukso-working-directory>

# Start the Mainnet Validator Node with Custom Name
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --geth-ethstats "<your-dashboard-name>:<ethstats-secret>@<ethstats-server>"

# Start the Testnet Validator Node with Custom Name
lukso start --testnet --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync  --geth-ethstats "<your-dashboard-name>:<ethstats-secret>@<ethstats-server>"
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
cd <lukso-working-directory>

# Start the Mainnet Validator Node with Custom Name
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --erigon-ethstats "<your-dashboard-name>:<ethstats-secret>@<ethstats-server>"

# Start the Testnet Validator Node with Custom Name
lukso start --testnet --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --erigon-ethstats "<your-dashboard-name>:<ethstats-secret>@<ethstats-server>"
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
cd <lukso-working-directory>

# Start the Mainnet Validator Node with Custom Name
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --nethermind-ethstats-enabled=true --nethermind-ethstats-name "<your-dashboard-name>" --nethermind-ethstats-secret "<ethstats-secret>" --nethermind-ethstats-server "wss://<ethstats-server>"

# Start the Testnet Validator Node with Custom Name
lukso start --testnet --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --nethermind-ethstats-enabled=true --nethermind-ethstats-name "<your-dashboard-name>" --nethermind-ethstats-secret "<ethstats-secret>" --nethermind-ethstats-server "wss://<ethstats-server>"
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
cd <lukso-working-directory>

# Start the Mainnet Validator Node with Custom Name
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --besu-ethstats "<your-dashboard-name>:<ethstats-secret>@<ethstats-server>"

# Start the Testnet Validator Node with Custom Name
lukso start --testnet --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync --besu-ethstats "<your-dashboard-name>:<ethstats-secret>@<ethstats-server>"
```

</TabItem>
</Tabs>

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path of the node folder
- `<your-fee-recipient-address>` with the wallet address receiving staking profits
- `<your-dashboard-name>` with the node name to show up on the dashboard
- `ethstats-secret` with the actual secret of your dashboard server
- `ethstats-server` with the address of your dashboard server

:::

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

</TabItem> <TabItem value="automation" label="Service Automation">

Open the startup script within your node directory with your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
sudo vim <lukso-working-directory>/static/lukso_startup.sh
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
sudo nano <lukso-working-directory>/static/lukso_startup.sh
```

</TabItem>
</Tabs>

:::info

Exchange `<lukso-working-directory>` with the path to the node folder.

:::

Add the ETHStats flag new line to the start command, then save and exit the file.

<Tabs>
<TabItem value="geth" label="Geth">

```text
exec /usr/local/bin/lukso start \
        --validator \
        --validator-wallet-password ./static/<your-generic-password-file> \
        --transaction-fee-recipient "<your-fee-recipient-address>" \
        --checkpoint-sync \
        --geth-ethstats "<your-dashboard-name>:<ethstats-secret>@<ethstats-server>"
```

</TabItem> <TabItem value="erigon" label="Erigon">

```text
exec /usr/local/bin/lukso start \
        --validator \
        --validator-wallet-password ./static/<your-generic-password-file> \
        --transaction-fee-recipient "<your-fee-recipient-address>" \
        --checkpoint-sync \
        --erigon-ethstats "<your-dashboard-name>:<ethstats-secret>@<ethstats-server>"
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```text
exec /usr/local/bin/lukso start \
        --validator \
        --validator-wallet-password ./static/<your-generic-password-file> \
        --transaction-fee-recipient "<your-fee-recipient-address>" \
        --checkpoint-sync \
        --nethermind-ethstats-enabled=true \
        --nethermind-ethstats-name   "<your-dashboard-name>" \
        --nethermind-ethstats-secret "<ethstats-secret>" \
        --nethermind-ethstats-server "wss://<ethstats-server>" \
```

</TabItem> <TabItem value="besu" label="Besu">

```text
exec /usr/local/bin/lukso start \
        --validator \
        --validator-wallet-password ./static/<your-generic-password-file> \
        --transaction-fee-recipient "<your-fee-recipient-address>" \
        --checkpoint-sync \
        --besu-ethstats "<your-dashboard-name>:<ethstats-secret>@<ethstats-server>"
```

</TabItem>
</Tabs>

:::info

The following properties need to be exchanged:

- `<your-generic-password-file>` with the name of your validator password file
- `<your-fee-recipient-address>` with the wallet address receiving staking profits
- `<your-dashboard-name>` with the node name to show up on the dashboard
- `ethstats-secret` with the actual secret of your dashboard server
- `ethstats-server` with the address of your dashboard server

:::

After the startup script was updated, you can restart the node by executing the related service.

```sh
sudo systemctl start lukso-validator
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="file" label="Modifying the Client Configuration">

Depending on your execution client, the ETHStats Secret can be set with different properties.

<Tabs groupId="client">
<TabItem value="geth" label="Geth">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/geth/
vim geth.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/geth/
nano geth.toml
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="erigon" label="Erigon">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/erigon/
vim erigon.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/erigon/
nano erigon.toml
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="nethermind" label="Nethermind">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/nethermind/
vim nethermind.cfg
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/nethermind/
nano nethermind.cfg
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="besu" label="Besu">

Open the configuration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>/besu/
vim besu.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>/besu/
nano besu.toml
```

</TabItem>
</Tabs>

</TabItem>
</Tabs>

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path to the node folder.
- `<network>` with the name of your node's network.

:::

Add the ETHStats Secret as a new line within the settings, then save and exit the file.

<Tabs groupId="client">
<TabItem value="geth" label="Geth">

Search for the _Ethstats_ section, then add and uncomment the _URL_ property under it.

```text
[Ethstats]
URL = "<your-dashboard-name>:<ethstats-secret>@<ethstats-server>"
```

</TabItem> <TabItem value="erigon" label="Erigon">

Set and uncomment the _ethstats_ property at the end of the file.

```text
"ethstats" = "<your-dashboard-name>:<ethstats-secret>@<ethstats-server>"
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

Set the _EthStats_ object and _Name_ property at the ending bracket of the _Network_ object.

```text
"EthStats": {
  "Enabled": true,
  "Name": "<your-dashboard-name>",
  "Secret": "<ethstats-secret>",
  "Server": "wss://<ethstats-server>"
}
```

</TabItem> <TabItem value="besu" label="Besu">

Set the _ethstats_ property at the end of the file.

```text
'ethstats'='<your-dashboard-name>:<ethstats-secret>@<ethstats-server>'
```

</TabItem>
</Tabs>

:::info

The following properties need to be exchanged:

- `<your-dashboard-name>` with the node name to show up on the dashboard
- `ethstats-secret` with the actual secret of your dashboard server
- `ethstats-server` with the address of your dashboard server

:::

:::warning

Ensure there are no missing spaces, characters or unintended linebreaks before saving the configuration file.

:::

Depending on your setup method, there are different ways to start your node after setting the ETHStats Secret.

<Tabs groupId="setup">
  <TabItem value="clinode" label="LUKSO CLI Node" default>

```sh
cd <lukso-working-directory>
lukso start --checkpoint-sync
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="clivalidator" label="LUKSO CLI Validator" default>

```sh
cd <lukso-working-directory>
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync
```

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path of the node folder
- `<your-fee-recipient-address>` with the wallet address receiving staking profits

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl start lukso-validator
```

</TabItem>
</Tabs>

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

</TabItem>
</Tabs>

## üé® DAppNode

On a DAppNode setup, the Geth client can be adjusted from the user interface.

**1. Stop Node Operation**: Stop the execution and consensus client within the _Node Operation View_.

**2. Navigate to Staker Menu**: Open the _LUKSO Stakers_ menu and move into the _Lukso Geth Package_.

**3. Adjust Slasher Value**: Navigate to the _Configs_ window and add the ETHStats flag in the _EXTRA_OPTS_ field.

```sh
--ethstats "<your-dashboard-name>:<ethstats-secret>@<ethstats-server>"
```

:::info

The following properties need to be exchanged:

- `<your-dashboard-name>` with the node name to show up on the dashboard
- `ethstats-secret` with the actual secret of your dashboard server
- `ethstats-server` with the address of your dashboard server

:::

**4. Restart the Node**: Restart the execution and consensus client within the _Node Operation View_.

---

// File: guides/monitoring/software-preparation

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 8.1 Software Preparation

Node monitoring ensures that operators can solve issues ahead of time, maintain uptime, and optimize performance by providing real-time insight into system health, client status, and network usage. This page will walk you through the software installs and configurations needed to get your monitoring environment up and running. All the monitoring tooling, regardless of the client configurations, generally follows a modular approach of software modules.

| Step | Name                                    | Description                                                |
| ---- | --------------------------------------- | ---------------------------------------------------------- |
| 1    | Install Core Tools & Port Configuration | Install required packages and expose monitoring ports.     |
| 2    | Create Exporter Services                | Export metrics like system, consensus, and execution data. |
| 3    | Setup Prometheus                        | Scrape and process metrics from exporter services.         |
| 4    | Configure Grafana                       | Visualizing metrics and creating dashboards.               |
| 5    | Configure Dashboard                     | Load dashboards and configure alerts.                      |

:::tip

Further details about node analytics can be found on the [**Monitoring Tools**](/docs/theory/node-operation/monitoring-tools.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

:::info

As the table suggests, exporter services and clients should be set up before configuring Prometheus or Grafana, so all data sources are set in place. Setting up the underlaying software first has the following benefits:

- **Problem Encapsulation**: By installing exporters beforehand, you can verify that the metrics are accessible and correctly exposed. Separated installation helps troubleshoot potential issues with the exporters or the services themselves.
- **No Idle Rotation Problems**: With the exporters already installed and configured, Prometheus can immediately start scraping the endpoints and collecting metrics. Having data endpoints running ensures that you have data available for monitoring as soon as Prometheus is up, excluding errors where configurations need to be reloaded and updated.

:::

<Tabs groupId="editor">
  <TabItem value="lukso-cli" label="üëæ LUKSO CLI" default>

The LUKSO CLI does not restrict the use of additional tools and monitoring solutions, but it also doesn‚Äôt include any monitoring tools out of the box. That means the setup must be done manually and will dock onto the already running clients. The following six tools are essential to install before setting up Prometheus, Grafana, and the required Exporters:

| Tool                                          | Description                                                                            |
| --------------------------------------------- | -------------------------------------------------------------------------------------- |
| <nobr> **wget** </nobr>                       | Utility for downloading files to fetch resources directly from the terminal.           |
| <nobr> **make** </nobr>                       | Automation tool used to compile software, required for compiling some exporter tools.  |
| <nobr> **git** </nobr>                        | Version control system used to clone repositories for exporter services.               |
| <nobr> **apt-transport-https** </nobr>        | Allows to securely download packages over HTTPS, required for third-party software.    |
| <nobr> **software-properties-common** </nobr> | Provides useful tools like `add-apt-repository` to manage software sources.            |
| <nobr> **gnupg2** </nobr>                     | Standard for secure encryption and signing, required for verifying package signatures. |

:::info

The following step is performed on your üìü **node server**.

:::

```sh
sudo apt install wget make git apt-transport-https software-properties-common gnupg2
```

</TabItem> <TabItem value="dappnode" label="üé® DAppNode">

DAppNode provides an integrated monitoring solution called [**DAppNode Monitoring Service**](https://docs.dappnode.io/docs/user/packages/dms/). The software solution includes all necessary tools such as node exporters, Prometheus, and Grafana out of the box. The dashboards come pre-configured, and services are automatically hooked into the DAppNode-managed blockchain clients without custom installation.

- [DAappNode DMS Setup](https://docs.dappnode.io/docs/user/packages/dms/)
- [DAppNode Metrics](https://docs.dappnode.io/docs/user/ethical-metrics/overview/)

</TabItem> <TabItem value="docker" label="üê≥ Docker">

The LUKSO team provides a separate [**Docker Monitoring Setup**](https://github.com/lukso-network/network-docker-monitoring), designed to work alongside their default Docker repositories for node operators. The configuration includes all necessary exporter services, Prometheus, and Grafana within one single container.

- [LUKSO Docker Monitoring Setup](https://github.com/lukso-network/network-docker-monitoring)
- [LUKSO Docker Containers](https://github.com/lukso-network/network-docker-containers)

</TabItem>
</Tabs>

---

// File: guides/monitoring/port-configuration

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 8.2 Port Configuration

Dashboard and monitoring tools like Grafana and Prometheus require open access to be viewed from your personal computer or trough a VPN connecting to your node. This section outlines which ports are used, which need to be open, and what additional ports are used internally during further service configurations.

:::info

Similar to [checking peers](/docs/guides/modifications/peer-count-limits.md#1-check-peer-connections) or [attaching clients](/docs/guides/maintenance/problem-scanning.md#attach-execution-clients), Prometheus can listen to consensus client ports to collect status messages.

:::

## Monitoring Ports

Consensus blockchain clients have different monitoring ports that allow Prometheus to gather metrics.

| LUKSO CLI PORT | CLIENT          | DESCRIPTION                      | TCP | External |
| -------------- | --------------- | -------------------------------- | --- | -------- |
| 4000           | [Lighthouse] ‚Üó  | Consensus REST API               | ‚úîÔ∏è  | ‚ùå       |
| 5062           | [Lighthouse] ‚Üó  | Validator REST API               | ‚úîÔ∏è  | ‚ùå       |
| 3500           | [Prysm] ‚Üó       | Consensus and Validator REST API | ‚úîÔ∏è  | ‚ùå       |
| 5051           | [Teku] ‚Üó        | Consensus and Validator REST API | ‚úîÔ∏è  | ‚ùå       |
| 5052           | [Nimbus-Eth2] ‚Üó | Consensus and Validator REST API | ‚úîÔ∏è  | ‚ùå       |
| 5054           | [Lighthouse] ‚Üó  | Consensus Metrics                | ‚úîÔ∏è  | ‚ùå       |
| 5057           | [Lighthouse] ‚Üó  | Validator Metrics                | ‚úîÔ∏è  | ‚ùå       |
| 8008           | [Nimbus-Eth2] ‚Üó | Consensus and Validator Metrics  | ‚úîÔ∏è  | ‚ùå       |
| 8008           | [Teku] ‚Üó        | Consensus Metrics                | ‚úîÔ∏è  | ‚ùå       |
| 8009           | [Teku] ‚Üó        | Validator Metrics                | ‚úîÔ∏è  | ‚ùå       |
| 8080           | [Prysm] ‚Üó       | Consensus Metrics                | ‚úîÔ∏è  | ‚ùå       |
| 8081           | [Prysm] ‚Üó       | Validator Metrics                | ‚úîÔ∏è  | ‚ùå       |

Service ports also come with default ports to bundle and present data.

| PORT | SERVICE               | DESCRIPTION          | TCP | External |
| ---- | --------------------- | -------------------- | --- | -------- |
| 3000 | [Grafana] ‚Üó           | Monitoring Dashboard | ‚úîÔ∏è  | ‚úÖ       |
| 7979 | [JSON-Exporter] ‚Üó     | Income Metrics       | ‚úîÔ∏è  | ‚ùå       |
| 9090 | [Prometheus] ‚Üó        | Data Analytics       | ‚úîÔ∏è  | ‚úÖ       |
| 9100 | [Node-Exporter] ‚Üó     | Hardware Metrics     | ‚úîÔ∏è  | ‚ùå       |
| 9115 | [Blackbox-Exporter] ‚Üó | Connectivity Metrics | ‚úîÔ∏è  | ‚ùå       |

:::warning

The [**LUKSO Network Configuration**](https://github.com/lukso-network/network-configs/tree/main) changed the following client ports:

- **Lighthouse**: Validator Metrics from Port `5064` to `5057`
- **Teku**: Validator Metrics from Port `8008` to `8009`

:::

:::tip

Node clients and exporter services are for internal use. All their data is collected by Prometheus, that further sends it to Grafana to create visual graphs to the metrics.

:::

:::info

Client port numbers must be defined when creating the [**Prometheus**](/docs/guides/monitoring/prometheus.md) configuration file.

:::

## Firewall Configuration

You can add the Grafana and Prometheus port rules to your firewall as previously done in the [Client Setup](/docs/guides/client-setup/firewall-settings.md).

:::info

The following step is performed on your üíª **personal computer**.

:::

**1. Node Connection**: _Log in to your node if you are not already connected._

```sh
ssh <ssh-device-alias>
```

:::info

The following steps are performed on your üìü **node server**.

:::

**2. Add Port Rules**: _Allow the TCP ports from both Grafana and Prometheus to allow data access._

```sh
sudo ufw allow 3000/tcp
sudo ufw allow 9090/tcp
```

The output of each command should always show:

```sh
Rule added
Rule added (v6)
```

**3. Check Configuration**: _Verify the new firewall rules._

```sh
sudo ufw status
```

The output should look similar to this:

<Tabs>
<TabItem value="lh-teku-nimbus" label="Execution Client + Lighthouse, Teku, or Nimbus-Eth2">

```text
Status: active

To Action From

---

<preferred-ssh-port>/tcp         ALLOW       Anywhere
30303/tcp                        ALLOW       Anywhere
30303/udp                        ALLOW       Anywhere
9000/tcp                         ALLOW       Anywhere
3000/tcp                         ALLOW       Anywhere
9090/tcp                         ALLOW       Anywhere
<preferred-ssh-port>/tcp (v6)    ALLOW       Anywhere (v6)
30303/tcp (v6)                   ALLOW       Anywhere (v6)
30303/udp (v6)                   ALLOW       Anywhere (v6)
9000/tcp (v6)                    ALLOW       Anywhere (v6)
3000/tcp (v6)                    ALLOW       Anywhere (v6)
9090/tcp (v6)                    ALLOW       Anywhere (v6)
```

</TabItem> 
<TabItem value="prysm" label="Execution Client + Prysm">

```text
Status: active

To Action From

---

<preferred-ssh-port>/tcp         ALLOW       Anywhere
30303/tcp                        ALLOW       Anywhere
30303/udp                        ALLOW       Anywhere
13000/tcp                        ALLOW       Anywhere
12000/udp                        ALLOW       Anywhere
3000/tcp                         ALLOW       Anywhere
9090/tcp                         ALLOW       Anywhere
<preferred-ssh-port>/tcp (v6)    ALLOW       Anywhere (v6)
30303/tcp (v6)                   ALLOW       Anywhere (v6)
30303/udp (v6)                   ALLOW       Anywhere (v6)
13000/tcp (v6)                   ALLOW       Anywhere (v6)
12000/udp (v6)                   ALLOW       Anywhere (v6)
3000/tcp (v6)                    ALLOW       Anywhere (v6)
9090/tcp (v6)                    ALLOW       Anywhere (v6)
```

</TabItem> 
</Tabs>

:::info

The `<preferred-ssh-port>` property will be exchanged with your actual SSH port.

:::

:::warning

If something is missing, retry to apply the above rules or have a look into the [firewall configuration](/docs/guides/system-setup/firewall-configuration.md) for further details.

:::

If you need to modify the firewall rules, such as removing an unwanted port rule, you can list them all.

```sh
sudo ufw status
```

:::info

To `delete` a specific port rule using `UFW`, type the `<rule-number>` that is no longer required.

:::

```sh
sudo ufw delete <rule-number>
```

[Lighthouse]: https://lighthouse-book.sigmaprime.io/api_metrics.html
[Prysm]: https://prysm.offchainlabs.com/docs/monitoring-alerts-metrics/grafana-dashboard/
[Teku]: https://docs.teku.consensys.io/how-to/monitor/use-metrics
[Nimbus-Eth2]: https://nimbus.guide/options.html
[Grafana]: https://grafana.com/docs/grafana/latest/setup-grafana/configure-grafana/#http_port
[Prometheus]: https://prometheus.io/docs/introduction/first_steps/
[JSON-Exporter]: https://github.com/prometheus-community/json_exporter
[Node-Exporter]: https://github.com/prometheus/node_exporter
[Blackbox-Exporter]: https://github.com/prometheus/blackbox_exporter

---

// File: guides/monitoring/node-exporter

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 8.3 Node Exporter

The Node Exporter collects machine metrics like memory, disk space, processor usage, and network statistics, providing visibility for system health and performance. It's an essential tool for monitoring resource consumption on blockchain nodes.

:::tip

Further details about node analytics can be found on the [**Monitoring Tools**](/docs/theory/node-operation/monitoring-tools.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Create System User

Running services as a system user with minimal privileges is a best practice, limiting damage if compromised. The JSON Exporter user will only be able to read and execute service-specific files. Use the system's user creation tool to add a new one.

```sh
sudo adduser --system node-exporter-worker --group --no-create-home
```

<details>
<summary>Full Command Explanation</summary>

| Flag                              | Description                                                                                    |
| --------------------------------- | ---------------------------------------------------------------------------------------------- |
| <nobr> `--system` </nobr>         | Creates a system user, used to run services and daemons rather than for people to log in with. |
| <nobr> `--group` </nobr>          | Creates a new group with the same name as the user.                                            |
| <nobr> `--no-create-home` </nobr> | Prevents creation of a home directory since the service does not need one.                     |

</details>

If you want to confirm that the user has been created, you can search for it within the password file, housing all essential information for each user account. Using the search tool _grep_, we can check if the user exists within the file.

```sh
grep "node-exporter-worker" /etc/passwd
```

The output should look similar to this:

```text
node-exporter-worker:x:114:120::/home/node-exporter-worker:/usr/sbin/nologin
```

## 2. Install Node Exporter

To add the Node Exporter tool to your node, you have to install it's package.

:::tip

Depending on the [Current Node Exporter Release](https://github.com/prometheus/node_exporter/releases/) the version and filenames might differ. Please ensure to use the latest release for best security and stability. As of **July 2025** it is version **1.9.1**.

:::

**2.1 Download Archive**: Move to the home directory and download the latest version.

```sh
cd
wget https://github.com/prometheus/node_exporter/releases/download/v1.9.1/node_exporter-1.9.1.linux-amd64.tar.gz
```

**2.2 Extract Files**: Unpack the archive using Ubuntu‚Äôs archiving tool.

```sh
tar xzfv node_exporter-1.9.1.linux-amd64.tar.gz
```

:::info

The `tar` command extracts `x` the uncompressed `z` archive from the file path `f` using verbose `v` status messages.

:::

**2.3 Move Binary to System Path**: Move the Node Exporter binary to your system path.

```sh
sudo cp node_exporter-1.9.1.linux-amd64/node_exporter /usr/local/bin/
```

**2.4 Assign Permissions**: Set the correct owner and access rights.

```sh
sudo chown node-exporter-worker:node-exporter-worker /usr/local/bin/node_exporter
sudo chmod 755 /usr/local/bin/node_exporter
```

<details>
  <summary>Full Command Descriptions</summary>

| **Setting**                                           | **Description**                                                     |
| ----------------------------------------------------- | ------------------------------------------------------------------- |
| <nobr> `sudo chown <user>:<user> <directory>` </nobr> | Assign ownership to a single folder or file.                        |
| <nobr> `sudo chmod 755 <directory>` </nobr>           | Set readable permissions for everyone, typically for general files. |

</details>

**2.5 Cleanup Installation Files**: Delete leftover archive and extracted folder.

```sh
rm -rf node_exporter-1.9.1.linux-amd64
rm node_exporter-1.9.1.linux-amd64.tar.gz
```

## 3. Service Configuration

Once the binary file is in place, we can create a service configuration for the exporter, so it automatically starts during boot and restarts during crashes. The configuration will also check for logging before it starts up and uses the previously created user.

**3.1 Create Service File**: Create a system service file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
sudo vim /etc/systemd/system/node_exporter.service
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
sudo nano /etc/systemd/system/node_exporter.service
```

</TabItem>
</Tabs>

**3.2 Add Configuration**: Paste the following content using your preferred logging tool, then save and exit the file.

:::tip

Further details on Journal and System Logging can be found on the [**Utility Tools**](/docs/theory/node-operation/utility-tools.md) page in the the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

<Tabs groupId="logging-tool">
  <TabItem value="journal" label="Journal Logging" default>

```text
[Unit]
Description=Node Exporter
Documentation=https://github.com/prometheus/node_exporter

[Service]
User=node-exporter-worker
Group=node-exporter-worker
Type=simple
ExecStart=/usr/local/bin/node_exporter
Restart=always
RestartSec=5
SyslogIdentifier=node_exporter
StandardOutput=journal
StandardError=journal
ProtectSystem=full
NoNewPrivileges=true
PrivateTmp=true

[Install]
WantedBy=multi-user.target
```

</TabItem> <TabItem value="system" label="System Logging">

```text
[Unit]
Description=Node Exporter
Documentation=https://github.com/prometheus/node_exporter

[Service]
User=node-exporter-worker
Group=node-exporter-worker
Type=simple
ExecStart=/usr/local/bin/node_exporter
Restart=always
RestartSec=5
SyslogIdentifier=node_exporter
StandardOutput=syslog
StandardError=syslog
ProtectSystem=full
NoNewPrivileges=true
PrivateTmp=true

[Install]
WantedBy=multi-user.target
```

</TabItem>
</Tabs>

<details>
    <summary>Full Property Explanation</summary>

| Property           | Description                                                                           |
| ------------------ | ------------------------------------------------------------------------------------- |
| `Description`      | A human-readable description of the service shown in `systemctl status`.              |
| `Documentation`    | Link to documentation of the software that is being used for this service file.       |
| `User`             | Executes the service as the `node-exporter-worker` user.                              |
| `Group`            | Executes the service under the `node-exporter-worker` group.                          |
| `Type`             | Indicates running at a `simple` service in the foreground without forking.            |
| `ExecStart`        | Link to binary at `/usr/local/bin/node_exporter`, started with the terminal command.  |
| `Restart`          | Restarts the service `always` for a variety of reasons, errors, or timeouts.          |
| `RestartSec`       | Delay in seconds before restarting the service.                                       |
| `SyslogIdentifier` | Tags logs from the service with `node_exporter` to help distinguish them.             |
| `StandardOutput`   | Sends regular service logs to the journal or syslog system.                           |
| `StandardError`    | Sends error service logs to the journal or syslog system.                             |
| `ProtectSystem`    | Restricts filesystem write access outside of the service runtime.                     |
| `NoNewPrivileges`  | Prevents privilege escalation which processes can be apply for.                       |
| `PrivateTmp`       | Creates an isolated `/tmp` directory for the service.                                 |
| `WantedBy`         | Binds the service to the `multi-user.target`, so it starts during all boot processes. |

</details>

:::warning

If you renamed the user, make sure to update both `User` and `Group` values to prevent running the service as `root`.

:::

## 4. Start the Exporter Service

After setting up the service, you can enable and start the system service.

**4.1 Reload Daemon**: Reload the system daemon to include the new service.

```sh
sudo systemctl daemon-reload
```

**4.2 Start Service**: Start the Node Exporter service using the system control.

```sh
sudo systemctl start node_exporter
```

**4.3 Enable Autostart on Boot**: Enable the service to start automatically during boot.

```sh
sudo systemctl enable node_exporter
```

The output should look similar to this:

```text
Created symlink /etc/systemd/system/multi-user.target.wants/node_exporter.service ‚Üí /etc/systemd/system/node_exporter.service.
```

## 5. Check Service Status

You can fetch the current status from the system control to check if the Node Exporter service is running and configured correctly. The command will display whether it is active, enabled, or disabled and show recent log entries.

```sh
sudo systemctl status node_exporter
```

The output should look similar to this:

```text
‚óè node_exporter.service - Node Exporter
     Loaded: loaded (/etc/systemd/system/node_exporter.service; enabled; >
     Active: active (running) since [DATE]; [TIME] ago
       Docs: https://github.com/prometheus/node_exporter
   Main PID: 22812 (node_exporter)
      Tasks: 5 (limit: 38043)
     Memory: 2.8M
        CPU: 10ms
     CGroup: /system.slice/node_exporter.service
             ‚îî‚îÄ22812 /usr/local/bin/node_exporter
```

## Maintenance

Proper maintenance ensures that all the components are working as intended and can be updated on the fly.

**Logging**: Check the latest status of the system service.

<Tabs groupId="logging-tool">
  <TabItem value="journal" label="Journal Logging" default>

```sh
sudo journalctl -f -u node_exporter
```

</TabItem> <TabItem value="system" label="System Logging">

```sh
sudo tail -f /var/log/syslog | grep node_exporter
```

</TabItem>
</Tabs>

**Starting**: If you made any changes or updates to configuration, reload the system daemon and start the exporter.

```sh
sudo systemctl daemon-reload
sudo systemctl restart node_exporter
```

**Stopping**: You can stop the exporter using the system control.

```sh
sudo systemctl stop node_exporter
```

:::tip

Further information about system control or logging can be found on the [**Utility Tools**](/docs/theory/node-operation/utility-tools.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

## Revert Setup

If something went wrong, you can remove the user or delete the service and related files all together.

**1. Stop and Disable the Service**: Stop the tool and remove it's service link from the system's boot.

```sh
sudo systemctl stop node_exporter
sudo systemctl disable node_exporter
```

**2. Remove the Service File**: Delete the configuration and reload the system daemon.

```sh
sudo rm /etc/systemd/system/node_exporter.service
sudo systemctl daemon-reload
```

**3. Delete Binary**: Remove the executable Node Exporter from your system.

```sh
sudo rm -rf /usr/local/bin/node_exporter
```

**4. Remove User and Group**: Prune the user and all it's cached configurations.

```sh
sudo deluser --remove-all-files node-exporter-worker
sudo delgroup node-exporter-worker
```

---

// File: guides/monitoring/json-exporter

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 8.4 JSON Exporter

The JSON Exporter fetches data from JSON endpoints, like the LYX price from CoinGecko. Having access to live price metrics allows you to monitor market performance and monitor financial metrics against validator number or participation rate.

:::tip

Further details about node analytics can be found on the [**Monitoring Tools**](/docs/theory/node-operation/monitoring-tools.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Create System User

Running services as a system user with minimal privileges is a best practice, limiting damage if compromised. The JSON Exporter user will only be able to read and execute service-specific files. Use the system's user creation tool to add a new one.

```sh
sudo adduser --system json-exporter-worker --group --no-create-home
```

<details>
<summary>Full Command Explanation</summary>

| Flag                              | Description                                                                                    |
| --------------------------------- | ---------------------------------------------------------------------------------------------- |
| <nobr> `--system` </nobr>         | Creates a system user, used to run services and daemons rather than for people to log in with. |
| <nobr> `--group` </nobr>          | Creates a new group with the same name as the user.                                            |
| <nobr> `--no-create-home` </nobr> | Prevents creation of a home directory since the service does not need one.                     |

</details>

If you want to confirm that the user has been created, you can search for it within the password file, housing all essential information for each user account. Using the search tool grep, we can check if the user exists within the file.

```sh
grep "json-exporter-worker" /etc/passwd
```

The output should look similar to this:

```text
json-exporter-worker:x:115:121::/home/json-exporter-worker:/usr/sbin/nologin
```

## 2. Install JSON Exporter

To add the JSON Exporter tool to your node, you have to install it's package.

:::tip

Depending on the [Current JSON Exporter Release](https://github.com/prometheus-community/json_exporter/releases/) the version and filenames might differ. Please ensure to use the latest release for best security and stability. As of **July 2025** it is version **0.7.0**.

:::

**2.1 Download Archive**: Move to the home directory and download the latest version.

```sh
cd
wget https://github.com/prometheus-community/json_exporter/releases/download/v0.7.0/json_exporter-0.7.0.linux-amd64.tar.gz
```

**2.2 Extract Files**: Unpack the archive using Ubuntu‚Äôs archiving tool.

```sh
tar xzfv json_exporter-0.7.0.linux-amd64.tar.gz
```

:::info

The `tar` command extracts `x` the uncompressed `z` archive from the file path `f` using verbose `v` status messages.

:::

**2.3 Move Binary to System Path**: Move the JSON Exporter binary to your system path.

```sh
sudo cp json_exporter-0.7.0.linux-amd64/json_exporter /usr/local/bin/
```

**2.4 Assign Permissions**: Set the correct owner and access rights.

```sh
sudo chown json-exporter-worker:json-exporter-worker /usr/local/bin/json_exporter
sudo chmod 755 /usr/local/bin/json_exporter
```

<details>
  <summary>Full Command Descriptions</summary>

| **Setting**                                           | **Description**                                                     |
| ----------------------------------------------------- | ------------------------------------------------------------------- |
| <nobr> `sudo chown <user>:<user> <directory>` </nobr> | Assign ownership to a single folder or file.                        |
| <nobr> `sudo chmod 755 <directory>` </nobr>           | Set readable permissions for everyone, typically for general files. |

</details>

**2.5 Cleanup Installation Files**: Delete leftover archive and extracted folder.

```sh
rm -rf json_exporter-0.7.0.linux-amd64
rm json_exporter-0.7.0.linux-amd64.tar.gz
```

## 3. Price Configuration

Create a configuration file that will be used for the API call to fetch the current LYX price.

**3.1 Create Config Directory and File**: Choose a separate folder and create a config file using your preferred text editor.

```sh
sudo mkdir /etc/json_exporter/
```

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
sudo vim /etc/json_exporter/json_exporter.yaml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
sudo nano /etc/json_exporter/json_exporter.yaml
```

</TabItem>
</Tabs>

**3.2 Paste Configuration**: Add the CoinGecko API configuration structure.

<Tabs groupId="currency">
  <TabItem value="euro" label="EUR" default>

```text
modules:
  default:
    metrics:
    - name: lyxeur
      path: "{.lukso-token.eur}"
      help: LUKSO (LYX) Price in EUR
```

</TabItem> <TabItem value="usd" label="USD">

```text
modules:
  default:
    metrics:
    - name: lyxusd
      path: "{.lukso-token.usd}"
      help: LUKSO (LYX) Price in USD
```

</TabItem>
</Tabs>

:::warning

Ensure the correct formatting of double-spaces for the correct use of the API calls.

:::

**3.3 Restrict Permissions**: Change the ownership of the configuration file to the service user.

```sh
sudo chown -R json-exporter-worker:json-exporter-worker /etc/json_exporter/
```

## 4. Service Configuration

Once the binary and API files are in place, we can create a service configuration for the exporter, so it automatically starts during boot and restarts during crashes. The configuration will also check for logging before it starts up and uses the previously created user.

**4.1 Create Service File**: Create a system service file using your preferred text editor.

<Tabs groupId="editor">
<TabItem value="vim" label="Vim" default>

```sh
sudo vim /etc/systemd/system/json_exporter.service
```

</TabItem>
<TabItem value="nano" label="Nano">

```sh
sudo nano /etc/systemd/system/json_exporter.service
```

</TabItem>
</Tabs>

**4.2 Add Configuration**: Paste the following content using your preferred logging tool, then save and exit the file.

:::tip

Further details on Journal and System Logging can be found on the [**Utility Tools**](/docs/theory/node-operation/utility-tools.md) page in the the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

<Tabs groupId="logging-tool">
<TabItem value="journal" label="Journal Logging" default>

```text
[Unit]
Description=JSON Exporter
Documentation=https://github.com/prometheus-community/json_exporter
After=network.target network-online.target

[Service]
User=json-exporter-worker
Group=json-exporter-worker
Type=simple
ExecStart=/usr/local/bin/json_exporter --config.file /etc/json_exporter/json_exporter.yaml
Restart=always
RestartSec=5
SyslogIdentifier=json_exporter
StandardOutput=journal
StandardError=journal
ProtectSystem=full
NoNewPrivileges=true
PrivateTmp=true

[Install]
WantedBy=multi-user.target
```

</TabItem>
<TabItem value="system" label="System Logging">

```text
[Unit]
Description=JSON Exporter
Documentation=https://github.com/prometheus-community/json_exporter
After=network.target network-online.target

[Service]
User=json-exporter-worker
Group=json-exporter-worker
Type=simple
ExecStart=/usr/local/bin/json_exporter --config.file /etc/json_exporter/json_exporter.yaml
Restart=always
RestartSec=5
SyslogIdentifier=json_exporter
StandardOutput=syslog
StandardError=syslog
ProtectSystem=full
NoNewPrivileges=true
PrivateTmp=true

[Install]
WantedBy=multi-user.target
```

</TabItem>
</Tabs>

<details>
<summary>Full Property Explanation</summary>

| Property           | Description                                                                                                                                                                       |
| ------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `Description`      | A human-readable description of the service shown in `systemctl status`.                                                                                                          |
| `Documentation`    | Link to documentation of the software that is being used for this service file.                                                                                                   |
| `After`            | - `network.target`: Ensures networking setup enabled before service is started. <br /> - `network-online.target`: Waits for network to be fully online before service is started. |
| `User`             | Executes the service as the `json-exporter-worker` user.                                                                                                                          |
| `Group`            | Executes the service under the `json-exporter-worker` group.                                                                                                                      |
| `Type`             | Indicates running at a `simple` service in the foreground without forking.                                                                                                        |
| `ExecStart`        | Link to binary at `/usr/local/bin/json_exporter`, started with the terminal command.                                                                                              |
| `Restart`          | Restarts the service `always` for a variety of reasons, errors, or timeouts.                                                                                                      |
| `RestartSec`       | Delay in seconds before restarting the service.                                                                                                                                   |
| `SyslogIdentifier` | Tags logs from the service with `json_exporter` to help distinguish them.                                                                                                         |
| `StandardOutput`   | Sends regular service logs to the journal or syslog system.                                                                                                                       |
| `StandardError`    | Sends error service logs to the journal or syslog system.                                                                                                                         |
| `ProtectSystem`    | Restricts filesystem write access outside of the service runtime.                                                                                                                 |
| `NoNewPrivileges`  | Prevents privilege escalation which processes can be apply for.                                                                                                                   |
| `PrivateTmp`       | Creates an isolated `/tmp` directory for the service.                                                                                                                             |
| `WantedBy`         | Binds the service to the `multi-user.target`, so it starts during all boot processes.                                                                                             |

</details>

:::warning

If you renamed the user, make sure to update both `User` and `Group` values to prevent running the service as `root`.

:::

## 5. Start the Exporter Service

After setting up the service, you can enable and start the system service.

**5.1 Reload Daemon**: Reload the system daemon to include the new service.

```sh
sudo systemctl daemon-reload
```

**5.2 Start Service**: Start the Node Exporter service using the system control.

```sh
sudo systemctl start json_exporter
```

**5.3 Enable Autostart on Boot**: Enable the service to start automatically during boot.

```sh
sudo systemctl enable json_exporter
```

The output should look similar to this:

```text
Created symlink /etc/systemd/system/multi-user.target.wants/json_exporter.service ‚Üí /etc/systemd/system/json_exporter.service.
```

## 6. Check Service Status

You can fetch the current status from the system control to check if the JSON Exporter service is running and configured correctly. The command will display whether it is active, enabled, or disabled and show recent log entries.

```sh
sudo systemctl status json_exporter
```

The output should look similar to this:

```text
‚óè json_exporter.service - JSON Exporter
     Loaded: loaded (/etc/systemd/system/json_exporter.service; enabled; vendor preset: enab>
     Active: active (running) since [DATE]; [TIME] ago
       Docs: https://github.com/prometheus-community/json_exporter
   Main PID: 88174 (json_exporter)
      Tasks: 14 (limit: 38043)
     Memory: 7.6M
        CPU: 139ms
     CGroup: /system.slice/json_exporter.service
             ‚îî‚îÄ88174 /usr/local/bin/json_exporter --config.file /etc/json_exporter/json_expo>

[DATE] [TIME] [USER] json_exporter[88174]: net/http.HandlerFunc.ServeHTTP(0xc00002408>...
```

## Maintenance

Proper maintenance ensures that all the components are working as intended and can be updated on the fly.

**Logging**: Check the latest status of the system service.

<Tabs groupId="logging-tool">
<TabItem value="journal" label="Journal Logging" default>

```sh
sudo journalctl -f -u json_exporter
```

</TabItem>
<TabItem value="system" label="System Logging">

```sh
sudo tail -f /var/log/syslog | grep json_exporter
```

</TabItem>
</Tabs>

**Restarting**: If you made any changes or updates to configuration, reload the system daemon and start the exporter.

```sh
sudo systemctl daemon-reload
sudo systemctl restart json_exporter
```

**Stopping**: You can stop the exporter using the system control.

```sh
sudo systemctl stop json_exporter
```

:::tip

Further information about system control or logging can be found on the [**Utility Tools**](/docs/theory/node-operation/utility-tools.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

## Revert Setup

If something went wrong, you can remove the user or delete the service and related files all together.

**1. Stop and Disable the Service**: Stop the tool and remove it's service link from the system's boot.

```sh
sudo systemctl stop json_exporter
sudo systemctl disable json_exporter
```

**2. Remove the Service and Config Files**: Delete the configurations and reload the system daemon.

```sh
sudo rm /etc/systemd/system/json_exporter.service
sudo rm -rf /etc/json_exporter
sudo systemctl daemon-reload
```

**3. Delete Binary**: Remove the executable JSON Exporter from your system.

```sh
sudo rm -rf /usr/local/bin/json_exporter
```

**4. Remove User and Group**: Prune the user and all it's cached configurations.

```sh
sudo deluser --remove-all-files json-exporter-worker
sudo delgroup json-exporter-worker
```

---

// File: guides/monitoring/blackbox-exporter

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 8.5 Blackbox Exporter

The Blackbox Exporter probes server endpoints and monitors the ping time between the node machine and two DNS servers. This information can be crucial in diagnosing network-related issues or delays.

:::tip

Further details about node analytics can be found on the [**Monitoring Tools**](/docs/theory/node-operation/monitoring-tools.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Create System User

Running services as a system user with minimal privileges is a best practice, limiting damage if compromised. The Blackbox Exporter user will only be able to read and execute service-specific files. Use the system's user creation tool to add a new one.

```sh
sudo adduser --system blackbox-exporter-worker --group --no-create-home
```

<details>
<summary>Full Command Explanation</summary>

| Flag                              | Description                                                                                    |
| --------------------------------- | ---------------------------------------------------------------------------------------------- |
| <nobr> `--system` </nobr>         | Creates a system user, used to run services and daemons rather than for people to log in with. |
| <nobr> `--group` </nobr>          | Creates a new group with the same name as the user.                                            |
| <nobr> `--no-create-home` </nobr> | Prevents creation of a home directory since the service does not need one.                     |

</details>

If you want to confirm that the user has been created, you can search for it within the password file, housing all essential information for each user account. Using the search tool grep, we can check if the user exists within the file.

```sh
grep "blackbox-exporter-worker" /etc/passwd
```

The output should look similar to this:

```text
blackbox-exporter-worker:x:116:122::/home/blackbox-exporter-worker:/usr/sbin/nologin
```

## 2. Install Blackbox Exporter

To add the Blackbox Exporter tool to your node, you have to install it's package.

:::tip

Depending on the [Current Blackbox Exporter Release](https://github.com/prometheus/blackbox_exporter/releases/) the version and filenames might differ. Please ensure to use the latest release for best security and stability. As of **July 2025** it is version **0.27.0**.

:::

**2.1 Download Archive**: Move to the home directory and download the latest version.

```sh
cd
wget https://github.com/prometheus/blackbox_exporter/releases/download/v0.27.0/blackbox_exporter-0.27.0.linux-amd64.tar.gz
```

**2.2 Extract Files**: Unpack the archive using Ubuntu‚Äôs archiving tool.

```sh
tar xzfv blackbox_exporter-0.27.0.linux-amd64.tar.gz
```

:::info

The `tar` command extracts `x` the uncompressed `z` archive from the file path `f` using verbose `v` status messages.

:::

**2.3 Move Binary to System Path**: Move the Blackbox Exporter binary to your system path.

```sh
sudo cp blackbox_exporter-0.27.0.linux-amd64/blackbox_exporter /usr/local/bin/
```

**2.4 Set Ownership and Permissions**: Set the correct owner and access rights.

```sh
sudo chown blackbox-exporter-worker:blackbox-exporter-worker /usr/local/bin/blackbox_exporter
sudo chmod 755 /usr/local/bin/blackbox_exporter
```

**2.5 Cleanup Files**: Delete leftover archive and extracted folder.

```sh
rm -rf blackbox_exporter-0.27.0.linux-amd64
rm blackbox_exporter-0.27.0.linux-amd64.tar.gz
```

## 3. Extend Network Capabilities

The Blackbox Exporter needs raw socket access to perform ping-based probes. Grant this capability:

```sh
sudo setcap cap_net_raw+ep /usr/local/bin/blackbox_exporter
```

<details>
<summary>Full Command Explanation</summary>

| Flag                            | Description                                                                        |
| ------------------------------- | ---------------------------------------------------------------------------------- |
| <nobr> `setcap` </nobr>         | Sets Linux capabilities on an executable like `/usr/local/bin/blackbox_exporter`.  |
| <nobr> `cap_net_raw+ep` </nobr> | Effectively `e` permitts `p` the capability to use raw and packet network sockets. |

</details>

## 4. Probing Configuration

Create a configuration file that will be used for the pings from the node to the servers.

**4.1 Create Config Directory and File**: Choose a separate folder and create a config file using your preferred text editor.

```sh
sudo mkdir /etc/blackbox_exporter/
```

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
sudo vim /etc/blackbox_exporter/blackbox.yaml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
sudo nano /etc/blackbox_exporter/blackbox.yaml
```

</TabItem>
</Tabs>

**4.2 Paste Configuration**: Add the preferred server call properties.

```text
modules:
  icmp:
    prober: icmp
    timeout: 10s
    icmp:
      preferred_ip_protocol: ipv4
```

:::warning

Ensure the correct formatting of double-spaces the configuration to take effect correctly.

:::

**4.3 Restrict Permissions**: Change the ownership of the configuration file to the service user.

```sh
sudo chown -R blackbox-exporter-worker:blackbox-exporter-worker /etc/blackbox_exporter/
```

## 5. Service Configuration

Once the binary and ping files are in place, we can create a service configuration for the exporter, so it automatically starts during boot and restarts during crashes. The configuration will also check for logging before it starts up and uses the previously created user.

**5.1 Create Service File**: Create a system service file using your preferred text editor.

<Tabs groupId="editor">
<TabItem value="vim" label="Vim" default>

```sh
sudo vim /etc/systemd/system/blackbox_exporter.service
```

</TabItem>
<TabItem value="nano" label="Nano">

```sh
sudo nano /etc/systemd/system/blackbox_exporter.service
```

</TabItem>
</Tabs>

**5.2 Add Configuration**: Paste the following content using your preferred logging tool, then save and exit the file.

:::tip

Further details on Journal and System Logging can be found on the [**Utility Tools**](/docs/theory/node-operation/utility-tools.md) page in the the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

<Tabs groupId="logging-tool">
<TabItem value="journal" label="Journal Logging" default>

```text
[Unit]
Description=Blackbox Exporter
Documentation=https://github.com/prometheus/blackbox_exporter
After=network.target network-online.target

[Service]
User=blackbox-exporter-worker
Group=blackbox-exporter-worker
Type=simple
ExecStart=/usr/local/bin/blackbox_exporter --config.file /etc/blackbox_exporter/blackbox.yaml
Restart=always
RestartSec=5
SyslogIdentifier=blackbox_exporter
StandardOutput=journal
StandardError=journal
ProtectSystem=full
NoNewPrivileges=true
PrivateTmp=true

[Install]
WantedBy=multi-user.target
```

</TabItem>
<TabItem value="system" label="System Logging">

```text
[Unit]
Description=Blackbox Exporter
Documentation=https://github.com/prometheus/blackbox_exporter
After=network.target network-online.target

[Service]
User=blackbox-exporter-worker
Group=blackbox-exporter-worker
Type=simple
ExecStart=/usr/local/bin/blackbox_exporter --config.file /etc/blackbox_exporter/blackbox.yaml
Restart=always
RestartSec=5
SyslogIdentifier=blackbox_exporter
StandardOutput=syslog
StandardError=syslog
ProtectSystem=full
NoNewPrivileges=true
PrivateTmp=true

[Install]
WantedBy=multi-user.target
```

</TabItem>
</Tabs>

<details>
<summary>Full Property Explanation</summary>

| Property           | Description                                                                                                                                                                       |
| ------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `Description`      | A human-readable description of the service shown in `systemctl status`.                                                                                                          |
| `Documentation`    | Link to documentation of the software that is being used for this service file.                                                                                                   |
| `After`            | - `network.target`: Ensures networking setup enabled before service is started. <br /> - `network-online.target`: Waits for network to be fully online before service is started. |
| `User`             | Executes the service as the `blackbox-exporter-worker` user.                                                                                                                      |
| `Group`            | Executes the service under the `blackbox-exporter-worker` group.                                                                                                                  |
| `Type`             | Indicates running at a `simple` service in the foreground without forking.                                                                                                        |
| `ExecStart`        | Link to binary at `/usr/local/bin/blackbox_exporter`, started with the terminal command.                                                                                          |
| `Restart`          | Restarts the service `always` for a variety of reasons, errors, or timeouts.                                                                                                      |
| `RestartSec`       | Delay in seconds before restarting the service.                                                                                                                                   |
| `SyslogIdentifier` | Tags logs from the service with `json_exporter` to help distinguish them.                                                                                                         |
| `StandardOutput`   | Sends regular service logs to the journal or syslog system.                                                                                                                       |
| `StandardError`    | Sends error service logs to the journal or syslog system.                                                                                                                         |
| `ProtectSystem`    | Restricts filesystem write access outside of the service runtime.                                                                                                                 |
| `NoNewPrivileges`  | Prevents privilege escalation which processes can be apply for.                                                                                                                   |
| `PrivateTmp`       | Creates an isolated `/tmp` directory for the service.                                                                                                                             |
| `WantedBy`         | Binds the service to the `multi-user.target`, so it starts during all boot processes.                                                                                             |

</details>

:::warning

If you renamed the user, make sure to update both `User` and `Group` values to prevent running the service as `root`.

:::

## 6. Start the Exporter Service

After setting up the service, you can enable and start the system service.

**6.1 Reload Daemon**: Reload the system daemon to include the new service.

```sh
sudo systemctl daemon-reload
```

**6.2 Start Exporter**: Start the Node Exporter service using the system control.

```sh
sudo systemctl start blackbox_exporter
```

**6.3 Enable Autostart**: Enable the service to start automatically during boot.

```sh
sudo systemctl enable blackbox_exporter
```

The output should look similar to this:

```text
Created symlink /etc/systemd/system/multi-user.target.wants/blackbox_exporter.service ‚Üí /etc/systemd/system/blackbox_exporter.service.
```

## 7. Check Service Status

You can fetch the current status from the system control to check if the Blackbox Exporter service is running and configured correctly. The command will display whether it is active, enabled, or disabled and show recent log entries.

```sh
sudo systemctl status blackbox_exporter
```

The output should look similar to this:

```text
‚óè blackbox_exporter.service - Blackbox Exporter
     Loaded: loaded (/etc/systemd/system/blackbox_exporter.service; enabled; vendor preset: enabled)
     Active: active (running) since [DATE]; [TIME] ago
       Docs: https://github.com/prometheus/blackbox_exporter
   Main PID: 27272 (blackbox_exporter)
      Tasks: 7 (limit: 38043)
     Memory: 2.4M
        CPU: 8ms
     CGroup: /system.slice/blackbox_exporter.service
             ‚îî‚îÄ27272 /usr/local/bin/blackbox_exporter --config.file /etc/blackbox_exporter/blackbox.>

[DATE] [USER] systemd[1]: Started Blackbox Exporter.
[DATE] [USER] blackbox_exporter[27272]: ts=2023-05-18T09:11:09.531Z caller=main.go:78 >...
...
```

## Maintenance

Proper maintenance ensures that all the components are working as intended and can be updated on the fly.

**Logging**: Check the latest status of the system service.

<Tabs groupId="logging-tool">
<TabItem value="journal" label="Journal Logging" default>

```sh
sudo journalctl -f -u blackbox_exporter
```

</TabItem>
<TabItem value="system" label="System Logging">

```sh
sudo tail -f /var/log/syslog | grep blackbox_exporter
```

</TabItem>
</Tabs>

**Restarting**: If you made any changes or updates to configuration, reload the system daemon and start the exporter.

```sh
sudo systemctl daemon-reload
sudo systemctl restart blackbox_exporter
```

**Stopping**: You can stop the exporter using the system control.

```sh
sudo systemctl stop blackbox_exporter
```

:::tip

Further information about system control or logging can be found on the [**Utility Tools**](/docs/theory/node-operation/utility-tools.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

## Revert Setup

If something went wrong, you can remove the user or delete the service and related files all together.

**1. Stop and Disable Service**: Stop the tool and remove it's service link from the system's boot.

```sh
sudo systemctl stop blackbox_exporter
sudo systemctl disable blackbox_exporter
```

**2. Remove the Service and Config Files**: Delete the configurations and reload the system daemon.

```sh
sudo rm /etc/systemd/system/blackbox_exporter.service
sudo rm -rf /etc/blackbox_exporter
sudo systemctl daemon-reload
```

**3. Delete Binary**: Remove the executable Blackbox Exporter from your system.

```sh
sudo rm -rf /usr/local/bin/blackbox_exporter
```

**4. Remove User and Group**: Prune the user and all it's cached configurations.

```sh
sudo deluser --remove-all-files blackbox-exporter-worker
sudo delgroup blackbox-exporter-worker
```

---

// File: guides/monitoring/prometheus

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 8.6 Prometheus

Prometheus is a time-series database and monitoring system that collects, stores, and queries metrics from various sources like our previously set up [Node Exporter](/docs/guides/monitoring/node-exporter.md), [JSON Exporter](/docs/guides/monitoring/json-exporter.md), and [Blackbox Exporter](/docs/guides/monitoring/blackbox-exporter.md). The guide explains how to set up the local Prometheus server and it's configuration to gather and unify all those metrics.

:::tip

Further details about node analytics can be found on the [**Monitoring Tools**](/docs/theory/node-operation/monitoring-tools.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Create System User

Running services as a system user with minimal privileges is a best practice, limiting damage if compromised. The Blackbox Exporter user will only be able to read and execute service-specific files. Use the system's user creation tool to add a new one.

```sh
sudo adduser --system prometheus-worker --group --no-create-home
```

<details>
<summary>Full Command Explanation</summary>

| Flag                              | Description                                                                                    |
| --------------------------------- | ---------------------------------------------------------------------------------------------- |
| <nobr> `--system` </nobr>         | Creates a system user, used to run services and daemons rather than for people to log in with. |
| <nobr> `--group` </nobr>          | Creates a new group with the same name as the user.                                            |
| <nobr> `--no-create-home` </nobr> | Prevents creation of a home directory since the service does not need one.                     |

</details>

If you want to confirm that the user has been created, you can search for it within the password file, housing all essential information for each user account. Using the search tool grep, we can check if the user exists within the file.

```sh
grep "prometheus-worker" /etc/passwd
```

The output should look similar to this:

```text
prometheus-worker:x:117:123::/home/prometheus-worker:/usr/sbin/nologin
```

## 2. Install Prometeus

To add the Prometheus tool to your node, you have to install it's package.

:::tip

Depending on the [Current Prometheus Release](https://github.com/prometheus/prometheus/releases/) the version and filenames might differ. Please ensure to use the latest **LTS Release** for best security and stability. As of **July 2025** it is version **2.53.5**. A full list of versions and categorized releases can be viewed on the official [Prometheus Download Page](https://prometheus.io/download/).

:::

**2.1 Download Archive**: Move to the home directory and download the latest version.

```sh
cd
wget https://github.com/prometheus/prometheus/releases/download/v2.53.5/prometheus-2.53.5.linux-amd64.tar.gz
```

**2.2 Extract Files**: Unpack the archive using Ubuntu‚Äôs archiving tool.

```sh
tar xzfv prometheus-2.53.5.linux-amd64.tar.gz
```

:::info

The `tar` command extracts `x` the uncompressed `z` archive from the file path `f` using verbose `v` status messages.

:::

**2.3 Navigate into the Folder**: Move into the extracted archive to view the executables.

```sh
cd prometheus-2.53.5.linux-amd64
ls -al
cd
```

:::info

You will see **Promtool** and **Prometheus** showing up as executable programs that will both have to be installed.

| Tool         | Description                                                                                            |
| ------------ | ------------------------------------------------------------------------------------------------------ |
| `prometheus` | The main Prometheus server that scrapes and stores metrics, and exposes it's database for querying.    |
| `promtool`   | The utility tool used for validating, and debugging Prometheus configuration files and alerting rules. |

:::

**2.4 Move Binary to System Path**: Move the Promtool and Prometheus binaries to your system path.

```sh
sudo cp prometheus /usr/local/bin/
sudo cp promtool /usr/local/bin/
```

**2.5 Set Ownership and Permissions**: Set the correct owner and access rights.

```sh
sudo chown -R prometheus-worker:prometheus-worker /usr/local/bin/prometheus
sudo chown -R prometheus-worker:prometheus-worker /usr/local/bin/promtool
sudo chmod 755 /usr/local/bin/prometheus
sudo chmod 755 /usr/local/bin/promtool
```

<details>
  <summary>Full Command Descriptions</summary>

| **Setting**                                           | **Description**                                                     |
| ----------------------------------------------------- | ------------------------------------------------------------------- |
| <nobr> `sudo chown <user>:<user> <directory>` </nobr> | Assign ownership to a single folder or file.                        |
| <nobr> `sudo chmod 755 <directory>` </nobr>           | Set readable permissions for everyone, typically for general files. |

</details>

**2.6 Cleanup Installation Files**: Delete leftover archive and extracted folder.

```sh
rm -rf prometheus-2.53.5.linux-amd64
rm prometheus-2.53.5.linux-amd64.tar.gz
```

## 3. Dataset Configuration

After the executables have been set up, you must create a separate configuration file for the Prometheus server to collect all of the exporter's information, and specify where to scrape, how often to scrape, and how what to do with the data.

**3.1 Create Necessary Directories**: Create all folders to exclude permission errors during operation.

```sh
sudo mkdir -p /etc/prometheus/console_libraries /etc/prometheus/consoles /etc/prometheus/files_sd /etc/prometheus/rules /etc/prometheus/rules.d /var/lib/prometheus
```

:::tip

If folders already exist, they remain untouched. Otherwise, an empty folder will be created.

:::

<details>
  <summary>Full Folder Descriptions</summary>

| Path                                | Purpose                                                                   |
| ----------------------------------- | ------------------------------------------------------------------------- |
| `/etc/prometheus/console_libraries` | Shared library snippets used by console dashboards.                       |
| `/etc/prometheus/consoles`          | Web UI dashboard templates rendered on the Prometheus server.             |
| `/etc/prometheus/files_sd`          | File-based discovery configs for port metrics.                            |
| `/etc/prometheus/rules`             | Custom alerting and recording rule files.                                 |
| `/etc/prometheus/rules.d`           | Subdirectory for service rules like the validator, node, and ping checks. |
| `/var/lib/prometheus`               | Storage folder for all collected metrics.                                 |

</details>

**3.2 Create Config File**: Create a Prometheus configuration using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
sudo vim /etc/prometheus/prometheus.yaml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
sudo nano /etc/prometheus/prometheus.yaml
```

</TabItem>
</Tabs>

**3.3 Paste Configuration**: Add the settings and exporter jobs to the configuration structure based on your client and currency.

:::tip

All properties will later on be used within the Grafana Dashboard to fetch the token prices and build metrics based on your node. The Prometheus data endpoints include the following sources:

- **Prometheus**: Compiling All Data Sources and Database Storage
- **Consensus Client**: Validator Count, Uptime, Connection, Participation Rate
- **Node Exporter**: Storage Demand, Processor Utilization, Heat Distribution, Disk Utilization
- **Blackbox Exporter**: Google and Cloudflare Pings, Latency Checks, Network Uptime
- **JSON Exporter**: Daily and Weekly Income, Staking Position, Market Behaviour
- **Validator Client**: Attestations and Proposals

:::

<Tabs groupId="currency">
  <TabItem value="euro" label="EUR" default>

<Tabs groupId="client">
<TabItem value="teku" label="Teku">

```text
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'prometheus-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:9090']
  - job_name: 'consensus-client-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:8008']
  - job_name: 'node-exporter-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:9100']
  - job_name: 'validator-client-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:8009']
  - job_name: 'google-ping-job'
    metrics_path: /probe
    params:
      module: [icmp]
    static_configs:
      - targets:
        - 8.8.8.8
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 127.0.0.1:9115  # The blackbox exporter's real hostname:port.
  - job_name: 'cloudflare-ping-job'
    metrics_path: /probe
    params:
      module: [icmp]
    static_configs:
      - targets:
        - 1.1.1.1
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 127.0.0.1:9115  # The blackbox exporter's real hostname:port.
  - job_name: 'json-exporter-job'
    static_configs:
    - targets:
      - 127.0.0.1:7979
  - job_name: 'json'
    metrics_path: /probe
    static_configs:
    - targets:
      - https://api.coingecko.com/api/v3/simple/price?ids=lukso-token&vs_currencies=eur
    relabel_configs:
    - source_labels: [__address__]
      target_label: __param_target
    - source_labels: [__param_target]
      target_label: instance
    - target_label: __address__
      replacement: 127.0.0.1:7979
```

</TabItem> <TabItem value="nimbus" label="Nimbus-Eth2">

```text
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'prometheus-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:9090']
  - job_name: 'beacon-client-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:8008']
  - job_name: 'node-exporter-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:9100']
  - job_name: 'google-ping-job'
    metrics_path: /probe
    params:
      module: [icmp]
    static_configs:
      - targets:
        - 8.8.8.8
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 127.0.0.1:9115  # The blackbox exporter's real hostname:port.
  - job_name: 'cloudflare-ping-job'
    metrics_path: /probe
    params:
      module: [icmp]
    static_configs:
      - targets:
        - 1.1.1.1
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 127.0.0.1:9115  # The blackbox exporter's real hostname:port.
  - job_name: 'json-exporter-job'
    static_configs:
    - targets:
      - 127.0.0.1:7979
  - job_name: 'json'
    metrics_path: /probe
    static_configs:
    - targets:
      - https://api.coingecko.com/api/v3/simple/price?ids=lukso-token&vs_currencies=eur
    relabel_configs:
    - source_labels: [__address__]
      target_label: __param_target
    - source_labels: [__param_target]
      target_label: instance
    - target_label: __address__
      replacement: 127.0.0.1:7979
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```text
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'prometheus-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:9090']
  - job_name: 'consensus-client-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:5054']
  - job_name: 'node-exporter-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:9100']
  - job_name: 'validator-client-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:5057']
  - job_name: 'google-ping-job'
    metrics_path: /probe
    params:
      module: [icmp]
    static_configs:
      - targets:
        - 8.8.8.8
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 127.0.0.1:9115  # The blackbox exporter's real hostname:port.
  - job_name: 'cloudflare-ping-job'
    metrics_path: /probe
    params:
      module: [icmp]
    static_configs:
      - targets:
        - 1.1.1.1
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 127.0.0.1:9115  # The blackbox exporter's real hostname:port.
  - job_name: 'json-exporter-job'
    static_configs:
    - targets:
      - 127.0.0.1:7979
  - job_name: 'json'
    metrics_path: /probe
    static_configs:
    - targets:
      - https://api.coingecko.com/api/v3/simple/price?ids=lukso-token&vs_currencies=eur
    relabel_configs:
    - source_labels: [__address__]
      target_label: __param_target
    - source_labels: [__param_target]
      target_label: instance
    - target_label: __address__
      replacement: 127.0.0.1:7979
```

</TabItem> <TabItem value="prysm" label="Prysm">

```text
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'prometheus-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:9090']
  - job_name: 'consensus-client-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:8080']
  - job_name: 'node-exporter-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:9100']
  - job_name: 'validator-client-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:8081']
  - job_name: 'google-ping-job'
    metrics_path: /probe
    params:
      module: [icmp]
    static_configs:
      - targets:
        - 8.8.8.8
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 127.0.0.1:9115  # The blackbox exporter's real hostname:port.
  - job_name: 'cloudflare-ping-job'
    metrics_path: /probe
    params:
      module: [icmp]
    static_configs:
      - targets:
        - 1.1.1.1
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 127.0.0.1:9115  # The blackbox exporter's real hostname:port.
  - job_name: 'json-exporter-job'
    static_configs:
    - targets:
      - 127.0.0.1:7979
  - job_name: 'json'
    metrics_path: /probe
    static_configs:
    - targets:
      - https://api.coingecko.com/api/v3/simple/price?ids=lukso-token&vs_currencies=eur
    relabel_configs:
    - source_labels: [__address__]
      target_label: __param_target
    - source_labels: [__param_target]
      target_label: instance
    - target_label: __address__
      replacement: 127.0.0.1:7979
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="usd" label="USD">

<Tabs groupId="client">
<TabItem value="teku" label="Teku">

```text
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'prometheus-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:9090']
  - job_name: 'consensus-client-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:8008']
  - job_name: 'node-exporter-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:9100']
  - job_name: 'validator-client-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:8009']
  - job_name: 'google-ping-job'
    metrics_path: /probe
    params:
      module: [icmp]
    static_configs:
      - targets:
        - 8.8.8.8
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 127.0.0.1:9115  # The blackbox exporter's real hostname:port.
  - job_name: 'cloudflare-ping-job'
    metrics_path: /probe
    params:
      module: [icmp]
    static_configs:
      - targets:
        - 1.1.1.1
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 127.0.0.1:9115  # The blackbox exporter's real hostname:port.
  - job_name: 'json-exporter-job'
    static_configs:
    - targets:
      - 127.0.0.1:7979
  - job_name: 'json'
    metrics_path: /probe
    static_configs:
    - targets:
      - https://api.coingecko.com/api/v3/simple/price?ids=lukso-token&vs_currencies=usd
    relabel_configs:
    - source_labels: [__address__]
      target_label: __param_target
    - source_labels: [__param_target]
      target_label: instance
    - target_label: __address__
      replacement: 127.0.0.1:7979
```

</TabItem> <TabItem value="nimbus" label="Nimbus-Eth2">

```text
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'prometheus-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:9090']
  - job_name: 'beacon-client-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:8008']
  - job_name: 'node-exporter-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:9100']
  - job_name: 'google-ping-job'
    metrics_path: /probe
    params:
      module: [icmp]
    static_configs:
      - targets:
        - 8.8.8.8
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 127.0.0.1:9115  # The blackbox exporter's real hostname:port.
  - job_name: 'cloudflare-ping-job'
    metrics_path: /probe
    params:
      module: [icmp]
    static_configs:
      - targets:
        - 1.1.1.1
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 127.0.0.1:9115  # The blackbox exporter's real hostname:port.
  - job_name: 'json-exporter-job'
    static_configs:
    - targets:
      - 127.0.0.1:7979
  - job_name: 'json'
    metrics_path: /probe
    static_configs:
    - targets:
      - https://api.coingecko.com/api/v3/simple/price?ids=lukso-token&vs_currencies=usd
    relabel_configs:
    - source_labels: [__address__]
      target_label: __param_target
    - source_labels: [__param_target]
      target_label: instance
    - target_label: __address__
      replacement: 127.0.0.1:7979
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```text
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'prometheus-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:9090']
  - job_name: 'consensus-client-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:5054']
  - job_name: 'node-exporter-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:9100']
  - job_name: 'validator-client-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:5057']
  - job_name: 'google-ping-job'
    metrics_path: /probe
    params:
      module: [icmp]
    static_configs:
      - targets:
        - 8.8.8.8
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 127.0.0.1:9115  # The blackbox exporter's real hostname:port.
  - job_name: 'cloudflare-ping-job'
    metrics_path: /probe
    params:
      module: [icmp]
    static_configs:
      - targets:
        - 1.1.1.1
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 127.0.0.1:9115  # The blackbox exporter's real hostname:port.
  - job_name: 'json-exporter-job'
    static_configs:
    - targets:
      - 127.0.0.1:7979
  - job_name: 'json'
    metrics_path: /probe
    static_configs:
    - targets:
      - https://api.coingecko.com/api/v3/simple/price?ids=lukso-token&vs_currencies=usd
    relabel_configs:
    - source_labels: [__address__]
      target_label: __param_target
    - source_labels: [__param_target]
      target_label: instance
    - target_label: __address__
      replacement: 127.0.0.1:7979
```

</TabItem> <TabItem value="prysm" label="Prysm">

```text
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'prometheus-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:9090']
  - job_name: 'consensus-client-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:8080']
  - job_name: 'node-exporter-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:9100']
  - job_name: 'validator-client-job'
    scrape_interval: 5s
    static_configs:
      - targets: ['127.0.0.1:8081']
  - job_name: 'google-ping-job'
    metrics_path: /probe
    params:
      module: [icmp]
    static_configs:
      - targets:
        - 8.8.8.8
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 127.0.0.1:9115  # The blackbox exporter's real hostname:port.
  - job_name: 'cloudflare-ping-job'
    metrics_path: /probe
    params:
      module: [icmp]
    static_configs:
      - targets:
        - 1.1.1.1
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: 127.0.0.1:9115  # The blackbox exporter's real hostname:port.
  - job_name: 'json-exporter-job'
    static_configs:
    - targets:
      - 127.0.0.1:7979
  - job_name: 'json'
    metrics_path: /probe
    static_configs:
    - targets:
      - https://api.coingecko.com/api/v3/simple/price?ids=lukso-token&vs_currencies=usd
    relabel_configs:
    - source_labels: [__address__]
      target_label: __param_target
    - source_labels: [__param_target]
      target_label: instance
    - target_label: __address__
      replacement: 127.0.0.1:7979
```

</TabItem>
</Tabs>

</TabItem>
</Tabs>

:::tip

As shown in the [**Port Configuration**](/docs/guides/monitoring/port-configuration.md), **Nimbus-Eth2** exposes the consensus and validator data through one single port. Therefore the Prometheus configuration combines both, the `consensus-client-job` and the `validator-client-job` into a single `beacon-client-job` instance.

:::

<details>
  <summary>Global Settings and Scrape Parameter Descriptions</summary>

| Setting               | Description                                                                     |
| --------------------- | ------------------------------------------------------------------------------- |
| `scrape_interval`     | How often Prometheus collects data from all targets, usually every `15s`.       |
| `evaluation_interval` | How often recording or alerting rules are evaluated, usually every `15s`.       |
| `job_name`            | Identifier for each target group that listens to a local port.                  |
| `metrics_path`        | Path where metrics are exposed, usually `/metrics` or `/probe`.                 |
| `params`              | Used in Blackbox or JSON Exporter to pass query strings or URLs                 |
| `static_configs`      | List of targets to scrape, like the `host:port` of each service.                |
| `relabel_configs`     | Modified target labels, that map addresses to Blackbox or set an instance name. |

</details>

<details>
  <summary>Full Prometheus Job Descriptions</summary>

| Job Name               | Description                                                               |
| ---------------------- | ------------------------------------------------------------------------- |
| `prometheus-job`       | Scrapes internal metrics from the Prometheus server itself.               |
| `consensus-client-job` | Collects blockchain metrics from the consensus client.                    |
| `validator-client-job` | Pulls activity and performance data from the validator client.            |
| `beacon-client-job`    | Collects blockchain metrics from the consensus and validator client.      |
| `node-exporter-job`    | Gathers hardware and OS metrics from the node using Node Exporter.        |
| `google-ping-job`      | Uses Blackbox Exporter to probe Google DNS.                               |
| `cloudflare-ping-job`  | Uses Blackbox Exporter to probe Cloudflare DNS.                           |
| `json-exporter-job`    | Gathers staking metrics and API data from the JSON Exporter.              |
| `json`                 | Sends requests to CoinGecko API through JSON Exporter for LYX price data. |

</details>

:::warning

Ensure the correct formatting of double-spaces so that the Prometheus server functions correctly.

:::

**3.4 Restrict Permissions**: Change the ownership and restrict execution within configuration folders to the service user.

```sh
# Prometheus Configuration, Files, Logging
sudo chown -R prometheus-worker:prometheus-worker /etc/prometheus

# Prometheus Database
sudo chown -R prometheus-worker:prometheus-worker /var/lib/prometheus
sudo chmod 755 /var/lib/prometheus
```

## 4. Service Configuration

Once the software and dataset configuration are in place, we can create a service configuration, so it automatically starts during boot and restarts during crashes. The configuration will also check for logging and an internet connection before it starts up and uses the previously created user.

**4.1 Create Service File**: Create a system service file using your preferred text editor.

<Tabs groupId="editor">
<TabItem value="vim" label="Vim" default>

```sh
sudo vim /etc/systemd/system/prometheus.service
```

</TabItem>
<TabItem value="nano" label="Nano">

```sh
sudo nano /etc/systemd/system/prometheus.service
```

</TabItem>
</Tabs>

**4.2 Add Configuration**: Paste the following content using your preferred logging tool, then save and exit the file.

:::tip

Further details on Journal and System Logging can be found on the [**Utility Tools**](/docs/theory/node-operation/utility-tools.md) page in the the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

<Tabs groupId="logging-tool">
<TabItem value="journal" label="Journal Logging" default>

```text
[Unit]
Description=Prometheus
Documentation=https://github.com/prometheus/prometheus
Wants=network-online.target
After=network.target network-online.target

[Service]
User=prometheus-worker
Group=prometheus-worker
Type=simple
ExecStart=/usr/local/bin/prometheus                               \
    --config.file /etc/prometheus/prometheus.yaml                 \
    --storage.tsdb.path /var/lib/prometheus/                      \
    --storage.tsdb.retention.time=31d                             \
    --web.console.templates=/etc/prometheus/consoles              \
    --web.console.libraries=/etc/prometheus/console_libraries
ExecReload=/bin/kill -HUP $MAINPIDRestart=always
RestartSec=5
SyslogIdentifier=prometheus
StandardOutput=journal
StandardError=journal
ProtectSystem=full
NoNewPrivileges=true
PrivateTmp=true

[Install]
WantedBy=multi-user.target
```

</TabItem>
<TabItem value="system" label="System Logging">

```text
[Unit]
Description=Prometheus
Documentation=https://github.com/prometheus/prometheus
Wants=network-online.target
After=network.target network-online.target

[Service]
User=prometheus-worker
Group=prometheus-worker
Type=simple
ExecStart=/usr/local/bin/prometheus                               \
    --config.file /etc/prometheus/prometheus.yaml                 \
    --storage.tsdb.path /var/lib/prometheus/                      \
    --storage.tsdb.retention.time=31d                             \
    --web.console.templates=/etc/prometheus/consoles              \
    --web.console.libraries=/etc/prometheus/console_libraries
ExecReload=/bin/kill -HUP $MAINPIDRestart=always
RestartSec=5
SyslogIdentifier=prometheus
StandardOutput=syslog
StandardError=syslog
ProtectSystem=full
NoNewPrivileges=true
PrivateTmp=true

[Install]
WantedBy=multi-user.target
```

</TabItem>
</Tabs>

<details>
<summary>Full Property Explanation</summary>

| Property           | Description                                                                                                                                                                       |
| ------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `Description`      | A human-readable description of the service shown in `systemctl status`.                                                                                                          |
| `Documentation`    | Link to documentation of the software that is being used for this service file.                                                                                                   |
| `Wants`            | The service should try to start `network-online.target` before starting Prometheus.                                                                                               |
| `After`            | - `network.target`: Ensures networking setup enabled before service is started. <br /> - `network-online.target`: Waits for network to be fully online before service is started. |
| `User`             | Executes the service as the `json-exporter-worker` user.                                                                                                                          |
| `Group`            | Executes the service under the `json-exporter-worker` group.                                                                                                                      |
| `Type`             | Indicates running at a `simple` service in the foreground without forking.                                                                                                        |
| `ExecStart`        | - Link to binary at `/usr/local/bin/prometheus`, started with the terminal command.                                                                                               |
| `ExecReload`       | Sends a `kill` signal to the main process to restart and re-read all configuration files.                                                                                         |
| `RestartSec`       | Delay in seconds before restarting the service.                                                                                                                                   |
| `SyslogIdentifier` | Tags logs from the service with `json_exporter` to help distinguish them.                                                                                                         |
| `StandardOutput`   | Sends regular service logs to the journal or syslog system.                                                                                                                       |
| `StandardError`    | Sends error service logs to the journal or syslog system.                                                                                                                         |
| `ProtectSystem`    | Restricts filesystem write access outside of the service runtime.                                                                                                                 |
| `NoNewPrivileges`  | Prevents privilege escalation which processes can be apply for.                                                                                                                   |
| `PrivateTmp`       | Creates an isolated `/tmp` directory for the service.                                                                                                                             |
| `WantedBy`         | Binds the service to the `multi-user.target`, so it starts during all boot processes.                                                                                             |

</details>

:::warning

If you renamed the user, make sure to update both `User` and `Group` values to prevent running the service as `root`.

:::

## 5. Start the Prometheus Service

After setting up the service, you can enable and start the system service.

**5.1 Reload Daemon**: Reload the system daemon to include the new service.

```sh
sudo systemctl daemon-reload
```

**5.2 Start Service**: Start the Prometheus service using the system control.

```sh
sudo systemctl start prometheus
```

**5.3 Enable Autostart on Boot**: Enable the service to start automatically during boot.

```sh
sudo systemctl enable prometheus
```

The output should look similar to this:

```text
Created symlink /etc/systemd/system/multi-user.target.wants/prometheus.service ‚Üí /etc/systemd/system/prometheus.service.
```

## 6. Check Service Status

You can fetch the current status from the system control to check if the Prometheus service is running and configured correctly. The command will display whether it is active, enabled, or disabled and show recent log entries.

```sh
sudo systemctl status prometheus
```

The output should look similar to this:

```text
‚óè prometheus.service - Prometheus
     Loaded: loaded (/etc/systemd/system/prometheus.service; enabled; vendor preset: enabled)
     Active: active (running) since [DATE] UTC; [TIME] ago
       Docs: https://github.com/prometheus/prometheus
   Main PID: 29468 (prometheus)
      Tasks: 17 (limit: 38043)
     Memory: 27.4M
        CPU: 293ms
     CGroup: /system.slice/prometheus.service
             ‚îî‚îÄ29468 /usr/local/bin/prometheus --config.file /etc/prometheus/prometheus.yaml --storage.ts>

[DATE] [TIME] [USER] prometheus[29468]: ts=2023-05-18T09:43:54.539Z caller=head.go:536 level=info > ...
...
```

## Maintenance

Proper maintenance ensures that all the components are working as intended and can be updated on the fly.

**Logging**: Check the latest status of the system service.

<Tabs groupId="logging-tool">
<TabItem value="journal" label="Journal Logging" default>

```sh
sudo journalctl -f -u prometheus
```

</TabItem>
<TabItem value="system" label="System Logging">

```sh
sudo tail -f /var/log/syslog | grep prometheus
```

</TabItem>
</Tabs>

**Restarting**: If you made any changes or updates to configuration, reload the system daemon and start the exporter.

```sh
sudo systemctl daemon-reload
sudo systemctl restart prometheus
```

**Stopping**: You can stop the exporter using the system control.

```sh
sudo systemctl stop prometheus
```

:::tip

Further information about system control or logging can be found on the [**Utility Tools**](/docs/theory/node-operation/utility-tools.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

## Revert Setup

If something went wrong, you can remove the user or delete the service and related files all together.

**1. Stop and Disable Service**: Stop the tool and remove it's service link from the system's boot.

```sh
sudo systemctl stop prometheus
sudo systemctl disable prometheus
```

**2. Change Binary Ownership**: Change the owner of the Prometheus and Promtool executables.

```sh
sudo chown -R root:root /usr/local/bin/prometheus
sudo chown -R root:root /usr/local/bin/promtool
```

**3. Change Folder Ownership**: Change the owner of the configuration and database folers.

```sh
sudo chown -R root:root /etc/prometheus
sudo chown -R root:root /var/lib/prometheus
```

**4. Remove the Service and Config Files**: Delete all service files and reload the system daemon.

```sh
sudo rm /etc/systemd/system/prometheus.service
sudo rm -rf /etc/prometheus
sudo rm -rf /var/lib/prometheus/
sudo systemctl daemon-reload
```

**5. Delete Binary**: Remove the executable Prometheus and Promtool from your system.

```sh
sudo rm -rf /usr/local/bin/prometheus
sudo rm -rf /usr/local/bin/promtool
```

**6. Remove User and Group**: Prune the user and all it's cached configurations.

```sh
sudo deluser --remove-all-files prometheus-worker
sudo delgroup prometheus-worker
```

---

// File: guides/monitoring/grafana

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 8.7 Grafana

Grafana is an analytics and interactive visualization tool that connects to the previously configured [Prometheus](/docs/guides/monitoring/prometheus.md) tool to display real-time metrics, logs, and alerting dashboards. This guide walks you through the process of installing Grafana and configuring it to run as a dedicated background service.

:::tip

Further details about node analytics can be found on the [**Monitoring Tools**](/docs/theory/node-operation/monitoring-tools.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Create System User

Running services as a system user with minimal privileges is a best practice, limiting damage if compromised. The Blackbox Exporter user will only be able to read and execute service-specific files. Use the system's user creation tool to add a new one.

```sh
sudo adduser --system grafana-server-worker --group --no-create-home
```

<details>
<summary>Full Command Explanation</summary>

| Flag                              | Description                                                                                    |
| --------------------------------- | ---------------------------------------------------------------------------------------------- |
| <nobr> `--system` </nobr>         | Creates a system user, used to run services and daemons rather than for people to log in with. |
| <nobr> `--group` </nobr>          | Creates a new group with the same name as the user.                                            |
| <nobr> `--no-create-home` </nobr> | Prevents creation of a home directory since the service does not need one.                     |

</details>

If you want to confirm that the user has been created, you can search for it within the password file, housing all essential information for each user account. Using the search tool grep, we can check if the user exists within the file.

```sh
grep "grafana-server-worker" /etc/passwd
```

The output should look similar to this:

```text
grafana-server-worker:x:117:123::/home/grafana-server-worker:/usr/sbin/nologin
```

## 2. Install Grafana

To add the Grafana server to your node, you have to install it's package. In the case of Grafana, the setup is more extensive than downloading a single executable and adding it to the binary tree yourself. We therefore use the package manager APT, which is also used for regular Linux or Ubuntu software. To verify the package's authenticity, we must first add the Grafana GPG software key to our system's keyring folder.

:::tip

Further information about package management can be found on the [**Utility Tools**](/docs/theory/node-operation/utility-tools.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

**2.1 Add GPG Key**: Download and save Grafana's signing key to the system‚Äôs keyring.

```sh
cd
curl -fsSL https://packages.grafana.com/gpg.key|sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/grafana.gpg
```

<details>
<summary>Full Command Explanation</summary>

| Flag        | Description                                                                           |
| ----------- | ------------------------------------------------------------------------------------- |
| `-f`        | Fails silently on errors to ensure the scripts does not continue on broken responses. |
| `-s`        | Silent mode to suppress progress output.                                              |
| `-S`        | Shows errors even in silent mode.                                                     |
| `-L`        | Follows redirects to the updated download location.                                   |
| `\|`        | Sends the output of `curl` directly into the `gpg` command.                           |
| `--dearmor` | Converts the ASCII key to binary so it can be used by APT.                            |
| `-o`        | Defines the output location and stores the binary key in the trusted GPG folder.      |

</details>

**2.2 Key Verification**: Verify if the Grafana Key was added using the _gpg_ command.

```sh
gpg --no-default-keyring --keyring /etc/apt/trusted.gpg.d/grafana.gpg --list-keys
```

<details>
<summary>Full Command Explanation</summary>

| Flag                   | Description                                                           |
| ---------------------- | --------------------------------------------------------------------- |
| `--no-default-keyring` | Avoids loading the user‚Äôs default keyring in `~/.gnupg`.              |
| `--keyring`            | Explicitly defines which keyring to use for listing trusted GPG keys. |
| `--list-keys`          | Displays all public keys of a specified keyring for verification.     |

</details>

You should find an entry similar to this:

```text
/etc/apt/trusted.gpg.d/grafana.gpg
----------------------------------
pub   rsa3072 2023-01-06 [SC] [expires: DATE]
      0E22EB88E39E12277A7760AE9E439B102CF3C0C6
uid           [ unknown] Grafana Labs <engineering@grafana.com>
sub   rsa3072 2023-01-06 [E] [expires: DATE]
```

**2.3 List Repository**: Add Grafana to the trusted repository list, to allow it's installation.

```sh
sudo add-apt-repository "deb https://packages.grafana.com/oss/deb stable main"
```

Press _Enter_ to continue fetching all the necessary packages.

:::info

The `add-apt-repository` is the standard way to add additional repositories to your sources in Ubuntu and many other Debian-based systems. However, it requires additional software packages that were installed during the [**Software Preparation**](/docs/guides/monitoring/software-preparation.md). Ensure you've completed the previous steps.

:::

**2.4 Update Package List**: Update the package list using the previous Grafana GPG key.

```sh
sudo apt update
```

**2.5 List Grafana Versions**: Check available Grafana versions that can be installed.

```sh
apt list -a grafana
```

**2.6 Install Grafana**: Download the latest supported Grafana build from the package list.

<Tabs groupId="grafana">
  <TabItem value="latest" label="Latest Grafana Version" default>

```sh
sudo apt install grafana
```

</TabItem> <TabItem value="9.5.2" label="Grafana Version 9.5.2">

```sh
sudo apt install grafana=9.5.2
```

</TabItem>
</Tabs>

**2.7 Freeze Updates**: Put Grafana Updates on hold so dashboards dont break during regular package updates.

```sh
sudo apt-mark hold grafana
```

**2.8 Set Binary Permissions**: Set the correct owner and access rights for the executables.

<Tabs groupId="grafana">
  <TabItem value="latest" label="Grafana Version 11+" default>

```sh
sudo chown -R grafana-server-worker:grafana-server-worker /usr/sbin/grafana-server
sudo chmod 755 /usr/sbin/grafana-server
```

</TabItem> <TabItem value="9.5.2" label="Grafana Version 9.5.2">

```sh
sudo chown -R grafana-server-worker:grafana-server-worker /usr/sbin/grafana
sudo chown -R grafana-server-worker:grafana-server-worker /usr/sbin/grafana-server
sudo chmod 755 /usr/sbin/grafana
sudo chmod 755 /usr/sbin/grafana-server
```

</TabItem>
</Tabs>

**2.9 Set File Permissions**: Set the correct owner and access rights for the configuration and log files.

```sh
sudo chown -R grafana-server-worker:grafana-server-worker /etc/grafana
sudo chown -R grafana-server-worker:grafana-server-worker /var/lib/grafana
sudo chown -R grafana-server-worker:grafana-server-worker /var/log/grafana
sudo chmod 755 /var/lib/grafana
```

## 3. Service Configuration

Once the Grafana software was installed with the correct permissions, we can update it's default service configuration, that automatically starts Grafana during boot and restarts during crashes. The updated configuration will also check for logging and an internet connection before it starts up and uses the previously created user.

:::tip

Most of the default configuration remains untouched. Compare the content and only add missing or updated properties.

:::

**4.1 Create Service File**: Create a system service file using your preferred text editor.

<Tabs groupId="editor">
<TabItem value="vim" label="Vim" default>

```sh
sudo vim /lib/systemd/system/grafana-server.service
```

</TabItem>
<TabItem value="nano" label="Nano">

```sh
sudo nano /lib/systemd/system/grafana-server.service
```

</TabItem>
</Tabs>

**4.2 Add Configuration**: Paste the following content using your preferred logging tool, then save and exit the file.

:::tip

Further details on Journal and System Logging can be found on the [**Utility Tools**](/docs/theory/node-operation/utility-tools.md) page in the the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

<Tabs groupId="logging-tool">
<TabItem value="journal" label="Journal Logging" default>

```text
[Unit]
Description=Grafana instance
Documentation=http://docs.grafana.org
Wants=network-online.target
After=network.target network-online.target postgresql.service mariadb.service mysql.service influxdb.service

[Service]
EnvironmentFile=/etc/default/grafana-server
User=grafana-server-worker
Group=grafana-server-worker
Type=simple
Restart=on-failure
WorkingDirectory=/usr/share/grafana
RuntimeDirectory=grafana
RuntimeDirectoryMode=0750
ExecStart=/usr/share/grafana/bin/grafana server                                     \
                            --config=${CONF_FILE}                                   \
                            --pidfile=${PID_FILE_DIR}/grafana-server.pid            \
                            --packaging=deb                                         \
                            cfg:default.paths.logs=${LOG_DIR}                       \
                            cfg:default.paths.data=${DATA_DIR}                      \
                            cfg:default.paths.plugins=${PLUGINS_DIR}                \
                            cfg:default.paths.provisioning=${PROVISIONING_CFG_DIR}

LimitNOFILE=10000
TimeoutStopSec=20
CapabilityBoundingSet=
DeviceAllow=
LockPersonality=true
MemoryDenyWriteExecute=false
NoNewPrivileges=true
PrivateDevices=true
PrivateTmp=true
ProtectClock=true
ProtectControlGroups=true
ProtectHome=true
ProtectHostname=true
ProtectKernelLogs=true
ProtectKernelModules=true
ProtectKernelTunables=true
ProtectProc=invisible
ProtectSystem=full
RemoveIPC=true
RestrictAddressFamilies=AF_INET AF_INET6 AF_UNIX
RestrictNamespaces=true
RestrictRealtime=true
RestrictSUIDSGID=true
SystemCallArchitectures=native
UMask=0027
RestartSec=5
SyslogIdentifier=grafana-server
StandardOutput=journal
StandardError=journal
PrivateUsers=true

[Install]
WantedBy=multi-user.target
```

</TabItem>
<TabItem value="system" label="System Logging">

```text
[Unit]
Description=Grafana instance
Documentation=http://docs.grafana.org
Wants=network-online.target
After=network.target network-online.target postgresql.service mariadb.service mysql.service influxdb.service

[Service]
EnvironmentFile=/etc/default/grafana-server
User=grafana-server-worker
Group=grafana-server-worker
Type=simple
Restart=on-failure
WorkingDirectory=/usr/share/grafana
RuntimeDirectory=grafana
RuntimeDirectoryMode=0750
ExecStart=/usr/share/grafana/bin/grafana server                                     \
                            --config=${CONF_FILE}                                   \
                            --pidfile=${PID_FILE_DIR}/grafana-server.pid            \
                            --packaging=deb                                         \
                            cfg:default.paths.logs=${LOG_DIR}                       \
                            cfg:default.paths.data=${DATA_DIR}                      \
                            cfg:default.paths.plugins=${PLUGINS_DIR}                \
                            cfg:default.paths.provisioning=${PROVISIONING_CFG_DIR}

LimitNOFILE=10000
TimeoutStopSec=20
CapabilityBoundingSet=
DeviceAllow=
LockPersonality=true
MemoryDenyWriteExecute=false
NoNewPrivileges=true
PrivateDevices=true
PrivateTmp=true
ProtectClock=true
ProtectControlGroups=true
ProtectHome=true
ProtectHostname=true
ProtectKernelLogs=true
ProtectKernelModules=true
ProtectKernelTunables=true
ProtectProc=invisible
ProtectSystem=full
RemoveIPC=true
RestrictAddressFamilies=AF_INET AF_INET6 AF_UNIX
RestrictNamespaces=true
RestrictRealtime=true
RestrictSUIDSGID=true
SystemCallArchitectures=native
UMask=0027
RestartSec=5
SyslogIdentifier=grafana-server
StandardOutput=syslog
StandardError=syslog
PrivateUsers=true

[Install]
WantedBy=multi-user.target
```

</TabItem>
</Tabs>

<details>
<summary>Full Property Explanation</summary>

| Property                  | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| ------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `Description`             | A human-readable description of the service shown in `systemctl status`.                                                                                                                                                                                                                                                                                                                                                                                                                              |
| `Documentation`           | Link to documentation of the software that is being used for this service file.                                                                                                                                                                                                                                                                                                                                                                                                                       |
| `Wants`                   | The service should try to start `network-online.target` before starting Grafana.                                                                                                                                                                                                                                                                                                                                                                                                                      |
| `After`                   | - `network.target`: Ensures networking setup is enabled before the service is started. <br/> - `network-online.target`: Waits for the network to be fully online. <br/> - `postgresql.service`: Ensures the PostgreSQL database service is started. <br/> - `mariadb.service`: Waits for the MariaDB backend database to launch. <br/> - `mysql.service`: Ensures the MySQL server is running for data sourcing. <br/> - `influxdb.service`: Waits for the InfluxDB database as dashboard dependency. |
|                           |
| `EnvironmentFile`         | Specifies a file containing the service's environment variables used during startup.                                                                                                                                                                                                                                                                                                                                                                                                                  |
| `User`                    | Executes the service as the `grafana-server-worker` user.                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| `Group`                   | Executes the service under the `grafana-server-worker` group.                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| `Type`                    | Indicates running at a `simple` service in the foreground without forking.                                                                                                                                                                                                                                                                                                                                                                                                                            |
| `Restart`                 | Restarts the service `on-failure` for a variety of reasons.                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| `WorkingDirectory`        | Sets the working directory for the executed process.                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| `RuntimeDirectory`        | Sets the runtime directory before start, removed when the service stops.                                                                                                                                                                                                                                                                                                                                                                                                                              |
| `RuntimeDirectoryMode`    | Sets the file mode permissions for the runtime directory.                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| `ExecStart`               | Link to binary at `/usr/share/grafana/bin/grafana`, started with the command.                                                                                                                                                                                                                                                                                                                                                                                                                         |
| `LimitNOFILE`             | Controls the maximum number of file descriptors the service can open.                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| `TimeoutStopSec`          | Specifies the maximum time the service should stop before being forcibly terminated.                                                                                                                                                                                                                                                                                                                                                                                                                  |
| `LockPersonality`         | The service's kernel personality setting will be locked to prevent changes.                                                                                                                                                                                                                                                                                                                                                                                                                           |
| `MemoryDenyWriteExecute`  | Determines whether the service can create writable and executable memory mappings.                                                                                                                                                                                                                                                                                                                                                                                                                    |
| `NoNewPrivileges`         | Prevents privilege escalation which processes can be apply for.                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| `PrivateDevices`          | The service will not have access to any physical devices.                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| `PrivateTmp`              | Creates an isolated `/tmp` directory for the service.                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| `ProtectClock`            | The service cannot change the system clock if enabled.                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| `ProtectControlGroups`    | Prevents the service from altering process resource limits and accounting settings.                                                                                                                                                                                                                                                                                                                                                                                                                   |
| `ProtectHome`             | Used to prevent the service from accessing the user's home directories.                                                                                                                                                                                                                                                                                                                                                                                                                               |
| `ProtectHostname`         | The service cannot change the system's hostname if enabled.                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| `ProtectKernelLogs`       | Prevents the service to access sensitive kernel log ring data.                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| `ProtectKernelModules`    | Prevents the service from altering the system's hardware capabilities.                                                                                                                                                                                                                                                                                                                                                                                                                                |
| `ProtectKernelTunables`   | Denies modifying kernel variables, restricting its ability to alter the system's behavior.                                                                                                                                                                                                                                                                                                                                                                                                            |
| `ProtectProc`             | Restricts the visibility of other processes in `/proc`.                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| `ProtectSystem`           | Specifies where the service can write files to the disk.                                                                                                                                                                                                                                                                                                                                                                                                                                              |
| `RemoveIPC`               | If enabled, it ill remove all connection objects when logging out.                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| `RestrictAddressFamilies` | Restricts the socket address families the service can use.                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| `RestrictNamespaces`      | Limits the types of Linux namespaces the process can access.                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| `RestrictRealtime`        | Blocks acquiring real-time scheduling of the operation system.                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| `RestrictSUIDSGID`        | Restricts creation or use of privilege files.                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| `SystemCallArchitectures` | Restricts the system calls the service can execute to a specific architecture.                                                                                                                                                                                                                                                                                                                                                                                                                        |
| `UMask`                   | Sets the default file creation permissions for the service.                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| `WantedBy`                | Binds the service to the `multi-user.target`, so it starts during all boot processes.                                                                                                                                                                                                                                                                                                                                                                                                                 |
| `RestartSec`              | Delay in seconds before restarting the service.                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| `SyslogIdentifier`        | Tags logs from the service with `grafana-server` to help distinguish them.                                                                                                                                                                                                                                                                                                                                                                                                                            |
| `StandardOutput`          | Sends regular service logs to the journal or syslog system.                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| `StandardError`           | Sends error service logs to the journal or syslog system.                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| `PrivateUsers`            | Runs the service in its own namespace mapped to `nobody` and `nogroup`.                                                                                                                                                                                                                                                                                                                                                                                                                               |

</details>

:::warning

If you renamed the user, make sure to update both `User` and `Group` values to prevent running the service as `root`.

:::

## 5. Start the Grafana Service

After setting up the service, you can enable and start the system service.

**5.1 Reload Daemon**: Reload the system daemon to include the new service.

```sh
sudo systemctl daemon-reload
```

**5.2 Start Service**: Start the Grafana service using the system control.

```sh
sudo systemctl start grafana-server
```

**5.3 Enable Autostart on Boot**: Enable the service to start automatically during boot.

```sh
sudo systemctl enable grafana-server
```

The output should look similar to this:

```text
Synchronizing state of grafana-server.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable grafana-server
Created symlink /etc/systemd/system/multi-user.target.wants/grafana-server.service ‚Üí /lib/systemd/system/grafana-server.service.
```

## 6. Check Service Status

You can fetch the current status from the system control to check if the Grafana service is running and configured correctly. The command will display whether it is active, enabled, or disabled and show recent log entries.

```sh
sudo systemctl status grafana-server
```

The output should look similar to this:

```text
‚óè grafana-server.service - Grafana instance
     Loaded: loaded (/lib/systemd/system/grafana-server.service; enabled; vendo>
     Active: active (running) since [DATE] UTC; [TIME] ago
       Docs: http://docs.grafana.org
   Main PID: 84000 (grafana)
      Tasks: 17 (limit: 38043)
     Memory: 65.7M
        CPU: 3.855s
     CGroup: /system.slice/grafana-server.service
             ‚îî‚îÄ84000 /usr/share/grafana/bin/grafana server --config=/etc/grafan>

[DATE] [TIME] [USER] grafana[84000]: logger=modules t=2023-05-18T15:09:2>...
...
```

## 7. Adjusting the Time Zone

To solve issues when having different timezones set on your node and your personal computer, but also ensure sure that metrics have the correct timestamp, you can update the default time settings which Grafana is applying under the hood.

**7.1 Verify Timezone**: Check if the wanted timezone is already set on your node.

```sh
timedatectl
```

**7.2 Update Timezone**: If there is an time offset, update your node's timezone.

```sh
sudo timedatectl set-timezone <your-timezone>
```

:::info

Exchange `<your-timezone>` with one of the [Available Timezone Names](https://gist.github.com/adamgen/3f2c30361296bbb45ada43d83c1ac4e5).

:::

:::tip

Timestamp changes take immediate effect for all services and log files.

:::

## Maintenance

Proper maintenance ensures that all the components are working as intended and can be updated on the fly.
**Logging**: Check the latest status of the system service.

<Tabs groupId="logging-tool">
<TabItem value="journal" label="Journal Logging" default>

```sh
sudo journalctl -f -u grafana-server
```

</TabItem>
<TabItem value="system" label="System Logging">

```sh
sudo tail -f /var/log/syslog | grep grafana-server
```

</TabItem>
</Tabs>

**Restarting**: If you made any changes or updates to configuration, reload the system daemon and start the exporter.

```sh
sudo systemctl daemon-reload
sudo systemctl restart grafana-server
```

**Stopping**: You can stop the exporter using the system control.

```sh
sudo systemctl stop grafana-server
```

:::tip

Further information about system control or logging can be found on the [**Utility Tools**](/docs/theory/node-operation/utility-tools.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

## Revert Setup

If something went wrong, you can remove the user or delete the service and related files all together.

**1. Stop and Disable Service**: Stop the tool and remove it's service link from the system's boot.

```sh
sudo systemctl stop grafana-server
sudo systemctl disable grafana-server
```

**2. Change Binary Ownership**: Change the owner of the Grafana and Grafana Server executables.

```sh
sudo chown -R root:root /usr/sbin/grafana
sudo chown -R root:root /usr/sbin/grafana-server
```

**3. Change Folder Ownership**: Change the owner of the configuration and database folers.

```sh
sudo chown -R root:root /etc/grafana
sudo chown -R root:root /var/lib/grafana
sudo chown -R root:root /var/log/grafana
```

**4. Remove the Service and Config Files**: Delete all service files and reload the system daemon.

```sh
sudo rm /lib/systemd/system/grafana-server.service
sudo rm -rf /etc/grafana
sudo rm -rf /var/lib/grafana
sudo rm -rf /var/log/grafana
sudo systemctl daemon-reload
```

**5. Delete Binary**: Remove the executable Grafana and Grafana Server from your system.

```sh
sudo rm -rf /usr/sbin/grafana-server
sudo rm -rf /usr/sbin/grafana
```

**6. Remove User and Group**: Prune the user and all it's cached configurations.

```sh
sudo deluser --remove-all-files grafana-server-worker
sudo delgroup grafana-server-worker
```

---

// File: guides/monitoring/dashboard-configuration

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 8.8 Dashboard Configuration

A Grafana dashboard is a powerful interface for visualizing real-time metrics, allowing node operators to monitor client performance, hardware usage, validator income, and network health. This guide will cover how to configure the dashboard interface after previously setting up the Prometheus data collector and exporter services.

![Dashboard Preview](/img/guides/monitoring/dashboard.jpeg)

:::tip

Further details about node analytics can be found on the [**Monitoring Tools**](/docs/theory/node-operation/monitoring-tools.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

:::info

The following step is performed on your üìü **node server**.

:::

## 1. Resolve IP Address

<Tabs>
<TabItem value="local-ip" label="Local IP Check" default>

:::info

You can use the `ip` tool to display the system‚Äôs default package route and source IP when connecting to the router. The default gateway's IP address is the intermediate route the system takes when sending data to an IP address outside its local network.

:::

```sh
ip route show default
```

The output will look like this:

```sh
default via <GATEWAY_IP_ADDRESS> dev eno1 proto dhcp src <NODE_IP_ADDRESS> metric <ROUTING_WEIGHT>
```

</TabItem>
<TabItem value="public-ip" label="Public IP Check">

:::info

You can use the `ip` tool to query a stable external address like the Google DNS address `8.8.8.8` to reveal your source IP and further filter the IP parameter from the server's response using the text-processing tool `awk`.

:::

```sh
ip route get 8.8.8.8 | awk '{print $7}'
```

</TabItem>
</Tabs>

Remember or copy your node's IP address, then log out of your node and continue using your personal computer's browser.

```sh
exit
```

:::info

The following steps are performed on your üíª **personal computer**.

:::

## 2. Access Web Interface

Open your browser and access your node's IP address on the [previously opened](/docs/guides/monitoring/port-configuration.md) Grafana port.

```text
http://<static-node-ip>:3000
```

:::info

Exchange `your-static-node-ip` with the actual retreived IP address.

:::

The default login credentials to the Grafana dashboard will be the following:

```text
DEFAULT CREDENTIALS
-------------------
username: admin
password: admin
```

:::warning

Set a new secure and long password when prompted by Grafana. Security is vital as this page will be exposed through VPNs.

:::

## 3. Add Prometheus Data Source

By default, Grafana is not listening to any metrics that were previously set up using [Prometheus](/docs/guides/monitoring/prometheus.md) and all it's data sources. You have to first attach the running Prometheus service to the Grafana Dashboard so it can listen and gather metrics in it's own database.

1. Open the **Burger Menu** icon on the left side
2. Click **Connections** to manage data sources
3. Clic **Data sources** on the left menu bar
4. Click the **Add Data Source** button at the top right
5. Click the **Prometheus** card in the middle screen
6. Enter `http://127.0.0.1:9090/` as **URL** to listen for data
7. Click **Save & Test** before continuing with the setup

:::tip

You should see a green _Data source is working_ checkmark before continuing to import the dashboard.

:::

## 4. Import Dashboard

After configuring the data source, you can continue to add the dashboard to vizualize the collected data and configure alerts. This guide already comes with a set of prebuilt Grafana templates that are ready to use. If you want, those dashboards can later be adjusted and modified to further customize your experience.

1. Navigate to the üìù [**Template**](/templates) section of this page
2. Choose the **JSON File** based on your [Consensus Client](/docs/guides/monitoring/prometheus.md), [Grafana Version](/docs/guides/monitoring/grafana.md), and [Fiat Currency](/docs/guides/monitoring/json-exporter.md).
3. Copy the raw **JSON File** contents by opening the file with a text editor
4. Open the **Grafana Landing Page** by clicking on the logo on the top left
5. Click the **Plus Icon** on the top right corner of the page
6. Click on **Import Dashboard** to add a new interface
7. Paste the raw contents to the **Import via Panel JSON** text box
8. Click the **Load** button to apply validity checks
9. Click the **Import** button to install the dashboard

:::tip

If you chose different **Ports** or **Prometheus Job-Names**, you will have to modify and match all configuration files.

1. Consensus client ports can be adjusted within the [Prometheus Dataset Configuration](/docs/guides/monitoring/prometheus.md#3-dataset-configuration).
2. Price Conversions require updating the [JSON Explorer Configuration](/docs/guides/monitoring/json-exporter.md#3-price-configuration) and [Prometheus Dataset Configuration](/docs/guides/monitoring/prometheus.md#3-dataset-configuration).
3. Job Names of the [Prometheus Dataset](/docs/guides/monitoring/prometheus.md#3-dataset-configuration) must match the Jobs of the [Grafana Dashboard](/templates).

:::

:::info

Great and free examples of editors with JSON formatting are ü¶é [**Notepad++**](https://notepad-plus-plus.org/) or üîπ [**Visual Studio Code**](https://code.visualstudio.com/).

:::

---

// File: guides/monitoring/external-monitoring

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 8.9 External Monitoring Tools

Instead of only using local monitoring tools like [Prometheus](/docs/guides/monitoring/prometheus.md) and [Grafana](/docs/guides/monitoring/grafana.md), there are a bunch of web-based service tools that help track node performance and validator duties from anywhere. These platforms typically focus on uptime, validator proposals, reward tracking, and network participation rates. This means node operators are not solely relying on local metrics and alerts, but can also gain external insights as a second safety net.

## Execution Block Explorer

The Execution Block Explorer is a valuable tool for examining detailed transactions and blocks. The serivce provides data like who validated the block and the number of blocks a certain validator has validated in total. Additionally, the tool displays the balance of the transaction recipient's fees addresses.

- [Mainnet Execution Explorer ‚Üó](https://explorer.execution.mainnet.lukso.network/)
- [Testnet Execution Explorer ‚Üó](https://explorer.execution.testnet.lukso.network/)

![Execution Block Explorer](/img/guides/monitoring/explorer-pages-1.png)

## Execution Status Page

The Execution Status Page is crucial for tracking your node's overall health and performance. If you received an ETHStats secret from the LUKSO Team prior to the Mainnet Launch, the service provides the public node names, their execution client versions and types, latencies, and the number of their current peers. It also shows their pending transactions based on their current [gas price configuration](/docs/guides/maintenance/gas-price-configuration.md), the last synced block and its hash, as well as the timing of the last block.

- [Mainnet Execution Status Page ‚Üó](https://stats.execution.mainnet.lukso.network/)
- [Testnet Execution Status Page ‚Üó](https://stats.execution.testnet.lukso.network/)
- [Stakingverse Status Page ‚Üó](https://community.stats.execution.stakingverse.io/)

![Execution Status Page](/img/guides/monitoring/explorer-pages-2.png)

:::tip

A guide on how to list your node on an Execution Status Page can be found on the [Execution Dashboard](/docs/guides/modifications/execution-dashboard.md) page.

:::

:::info

Both, the LUKSO Community and the LUKSO Team are running Execution Status Pages. While the community dashboard is open for everyone, the LUKSO Team only list nodes of core contributors that got in contact via the [**LUKSO Discord Server**](https://discord.gg/lukso).

:::

## Consensus Block Explorer

The Consensus Block Explorer offers comprehensive insights into the current consensus status. It displays the present epoch, slot, active and pending validator counts, the total staked LYX, and the average balance. For each slot, the explorer provides information about the proposer, the sync participation, time, and status. On top, the explorer also allows for an in-depth examination of each block, revealing the proposer's graffiti and all associated metadata.

From the validator's perspective, it provides critical information about attestations and deposits, the validators' status and effectiveness, and their balance. Validators can even check for slashed nodes, and execute their network exits while using the broadcast tool and checking their status on the withdrawals screen.

- [Mainnet Consensus Explorer ‚Üó](https://explorer.consensus.mainnet.lukso.network/)
- [Mainnet Consensus Broadcast Tool ‚Üó](https://explorer.consensus.mainnet.lukso.network/tools/broadcast)
- [Mainnet Consensus Slashing Board ‚Üó](https://explorer.consensus.mainnet.lukso.network/validators/slashings)
- [Mainnet Consensus Withdrawals and BLS Changes ‚Üó](https://explorer.consensus.mainnet.lukso.network/validators/withdrawals)
- [Mainnet Consensus Slot Inspector ‚Üó](https://explorer.consensus.mainnet.lukso.network/slots)
- [Testnet Consensus Explorer ‚Üó](https://explorer.consensus.testnet.lukso.network/)
- [Testnet Consensus Broadcast Tool ‚Üó](https://explorer.consensus.testnet.lukso.network/tools/broadcast)
- [Testnet Consensus Slashing Board ‚Üó](https://explorer.consensus.testnet.lukso.network/validators/slashings)
- [Testnet Consensus Withdrawals and BLS Changes ‚Üó](https://explorer.consensus.testnet.lukso.network/validators/withdrawals)
- [Testnet Consensus Slot Inspector ‚Üó](https://explorer.consensus.testnet.lukso.network/slots)

![Consensus Block Explorer](/img/guides/monitoring/explorer-pages-3.png)

:::tip

For further details about slots, epochs, and status types, look at the [**Proof of Stake**](/docs/theory/blockchain-knowledge/proof-of-stake.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

## External Validator Checks

The consensus explorer is considered the main status page for validators when it comes to monitoring uptime, withdrawals, block proposals, and earnings. While you can search for single validator indecies, the service also offers to **build a personalized validator status page** from an URL. This link can then be bookmarked in your browser to access a consolidated overview of all your validators at any time.

:::tip

Up to 250 validator keys can be added in a single URL. If exceeded, you must split keys across multiple links.

:::

:::info

The following steps are performed on your üìü **node server**.

:::

**1. Move into Node Folder**: Navigate into your log folder within your node setup.

<Tabs groupId="network">
  <TabItem value="mainnet" label="Mainnet" default>

```sh
cd
cd <lukso-working-directory>/mainnet-logs/
```

</TabItem> <TabItem value="testnet" label="Testnet">

```sh
cd
cd <lukso-working-directory>/testnet-logs/
```

</TabItem>
</Tabs>

:::info

Exchange `<lukso-working-directory>` with the actual folder name of your node setup.

:::

**2. Search Resent Log File**: Find the latest validator log file to retrieve the imported validators.

```sh
find . -type f -name "*validator*" -printf "%T@ %p\n" | sort -n | tail -1 | awk '{print $2}'
```

<details>
  <summary>Full Command Description</summary>

| Component                            | Description                                                                   |
| ------------------------------------ | ----------------------------------------------------------------------------- |
| <nobr> `find .` </nobr>              | Current directory as the starting point for the file search.                  |
| <nobr> `-type f` </nobr>             | Tells `find` to only consider regular files and ignore directories.           |
| <nobr> `-name "*validator*"` </nobr> | Matches files with "validator" anywhere in their names.                       |
| <nobr> `-printf "%T@ %p\n"` </nobr>  | Formats the output to show modification time `%T@` followed by the path `%p`. |
| <nobr> `sort -n` </nobr>             | Pipes the list and sorts the lines numerically by the modification time.      |
| <nobr> `tail -1` </nobr>             | Selects the last line, corresponding to the most recently modified file.      |
| <nobr> `awk '{print $2}'` </nobr>    | Extracts and prints the file path from the output line.                       |

</details>

**3. Create Monitoring Link**: Search the most recent log file and access all imported validators.

<Tabs groupId="network">
  <TabItem value="mainnet" label="Mainnet" default>

```sh
cat <validator-log.log> | grep -o 'index=[0-9]* ' | awk -F'=' '{printf "%s,", $2}' | sed 's/,$//' | tr -d ' ' | awk '{print "https://explorer.consensus.mainnet.lukso.network/dashboard?validators=" $0}'
```

</TabItem> <TabItem value="testnet" label="Testnet">

```sh
cat <validator-log.log> | grep -o 'index=[0-9]* ' | awk -F'=' '{printf "%s,", $2}' | sed 's/,$//' | tr -d ' ' | awk '{print "https://explorer.consensus.testnet.lukso.network/dashboard?validators=" $0}'
```

</TabItem>
</Tabs>

:::info

Exchange `<validator-log.log>` with the actual filename of the most recent validator log file.

:::

<details>
  <summary>Full Command Description</summary>

| Component                                       | Description                                                                                        |
| ----------------------------------------------- | -------------------------------------------------------------------------------------------------- |
| <nobr> `cat file` </nobr>                       | Displays all file contents including all the validator information.                                |
| <nobr> `grep -o 'index=[0-9]* '` </nobr>        | Extracts all occurrences of `index=` followed by digits, using `-o` to return only matching parts. |
| <nobr> `awk -F'=' '{printf "%s,", $2}'` </nobr> | Splits each match on `=`, and prints only the validator number followed by a comma.                |
| <nobr> `sed 's/,$//'` </nobr>                   | Removes the trailing comma from the end of the list.                                               |
| <nobr> `tr -d ' '` </nobr>                      | Deletes all spaces from the output, resulting in a compact list of comma-separated index numbers.  |
| <nobr> `awk '{print URL $0}'` </nobr>           | Prepends the `URL` to the entire index string, constructing a full link.                           |

</details>

The output will look similar to this one, having all your index numbers:

```text
https://explorer.consensus.mainnet.lukso.network/dashboard?validators=111,222,888
```

**4. Access Validator Page**: Copy and open the link to gather uptime, proposal, and withdrawal metrics of your node.

![Validator Overview](/img/guides/monitoring/explorer-pages-5.png)

:::tip

Safe the link in your notes or as browser bookmark to be able to check the validator status from any device.

:::

---

// File: guides/alert-systems/telegram-bot

# 9.1 Telegram Bot

Once the [Grafana Dashboard](/docs/guides/monitoring/dashboard-configuration.md) is configured, your node can send alerts through various channels, such as Discord, Telegram, or Email. The alert system can be used to notify you during unregular behavior from metrics, or when certain services cant be reached anymore.

:::tip

It is convenient to temporarily open a text editor to store information needed for these steps.

:::

:::info

The following steps are performed on your üíª **personal computer**.

:::

## 1. Create Telegram Bot

1. Open the web-based or Desktop version of [Telegram](https://telegram.org/apps).
2. Register or login to your [Telegram](https://telegram.org/) account.
3. Open the Botfather chat using the [t.me/botfather](https://t.me/botfather) link.
4. A new BotFather channel will be opened.
5. Type and send `/newbot` in the message line.
6. You will be promted to choose a full name for your future bot.
7. A message will appear with information about your bot.
8. Highlight and copy the API token and username.
9. Paste the information into your notes.

## 2. Create Group Chat

1. Open the Telegram menu and set up a new group.
2. Choose a name for the group of you and your bot.
3. Add your bot to the group by typing the exact username.
4. Create the group once the username was selected.
5. Type and send `/my_id` to trigger the API refresh.

## 3. Fetch the Chat Number

1. Copy `https://api.telegram.org/bot<your-api-token>/getUpdates` to a text document.
2. Replace `<your-api-token>` with your API token.
3. Copy the link and access it from a web browser and look for the `{"id"}:` element.
4. Copy and paste the `id` into your notes. It might have a `-` symbol in front.

## 4. Add Contact Points

1. Return to Grafana and login using your credentials.
2. On the left-hand menu, click **Alerting** and select the **Contact Points** heading.
3. Click **Add contact point** and fill in a name for your notification channel.
4. Select the **Telegram Integration** and add the API Token and your chat ID.
5. Click **Test** within the Integration Panel.
6. Wait until you see a new message in Telegram.
7. Click **Save contact point**.

## 5. Update Notification Policies

1. Visit the **Grafana Landing Page**, click **Alerting** on the left-hand menu, and select **Notification Policies**.
2. On the right side of the **Default Notification**, click the **3-Dot-Menu** and choose **Edit**.
3. Change the **Default Contact Point** to the Telegram's Contact Point and click **Update Default Policy**

---

// File: guides/alert-systems/grafana-notifications

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 9.2 Grafana Notifications

Grafana Notifications allow you to monitor the health of your node and its components in real-time. By configuring alerts for critical metrics, you can proactively resolve issues before they impact performance or security. Once a notification channel like [Telegram](/docs/guides/alert-systems/telegram-bot.md), Discord or E-Mail has been set up, you will be able to configure custom rules on when the [Grafana Dashboard](/docs/guides/monitoring/dashboard-configuration.md) sends messages based on gathered metrics.

:::tip

This guide uses the default Grafana üìù [**Templates**](/templates) to configure notification behaviour.

:::

:::info

The following steps are performed on your üíª **personal computer**.

:::

## 1. Add Notifications

To be notified once some process is down or something is off, you will have to create notifications for every metric.

1. Click the Granfana Icon to get to the **Landing Page** and select the **LUKSO Dashboard** from the list.
2. Scroll down to the dashboard's **Alerts** section, select an alert, and click **Edit** on the **3-Dot-Menu** on the right side.
3. Within the **Alert** tab, select **Create Alert Rule from this Panel** to open up a new window.
4. Click **Preview** to print out the graph and adjust the **Threshold** section to your likings on when the alert should happen.
5. In case the **Reduce** section is showing **NaN**, **Replace Non-numeric Values** with a custom number above the alert range.
6. For metrics that rely on the network, its recommended to set a **NaN** value, so it triggers when the network is down.
7. Within the **Alert Evaluation Behavior** section, add a **node-alerts** folder where all the alert data will be stored.
8. Within the **Evaluation Group** selection, add a **node-group** or select it from the panel.
9. Its recommended to always choose the same alert folder and group for one node, so you do not mix up any targets.
10. Scroll up and click **Save** to enable this alert for the specific metric.

:::info

The steps need to be repeated for every Alert on the Grafana Dashboard you want to receive notifications for.

:::

## 2. Set Metrics Presets

This section outlines every alert setup from the default dashboard. You can check the picures and validate your configurations.

:::tip

Below metric presets are based on default Grafana üìù [**Templates**](/templates). If you used different service job names within the [Prometheus Dataset Configuration](/docs/guides/monitoring/prometheus.md#3-dataset-configuration), you will have to adjust the job names to match your Prometheus installation.

:::

![Grafana Alert Board](/img/guides/alert-systems/grafana-alerts-1.png)

**Alert: Consensus Process Down**

```text
1: Process up
0: Process down
```

![Consensus Process Down Metric](/img/guides/alert-systems/grafana-alerts-2.png)

<Tabs groupId="client">
<TabItem value="lighthouse-prysm-teku" label="Lighthouse, Prysm, Teku">

```text
up{job="consensus-client-job"}
```

</TabItem><TabItem value="nimbus" label="Nimbus-Eth2">

```text
up{job="beacon-client-job"}
```

</TabItem> 
</Tabs>

**Alert: Validator Process Down**

```text
1: Process up
0: Process down
```

![Validator Process Down Metric](/img/guides/alert-systems/grafana-alerts-3.png)

<Tabs groupId="client">
<TabItem value="lighthouse-prysm-teku" label="Lighthouse, Prysm, Teku">

```text
up{job="validator-client-job"}
```

</TabItem>
</Tabs>

:::warning

The **Validator Proccess Down Alert** does not exist for **Nimbus-Eth2**, as it uses a single **Beacon Proccess**.

:::

**Alert: Consensus Process Restarted**

```text
1:   Process up
0:   Process down
NaN: Not available (likely down --> 0)
```

![Consensus Process Restarted Metric](/img/guides/alert-systems/grafana-alerts-4.png)

<Tabs groupId="client">
<TabItem value="lighthouse-prysm-teku" label="Lighthouse, Prysm, Teku">

```text
(time()-process_start_time_seconds{job="consensus-client-job"})/3600
```

</TabItem><TabItem value="nimbus" label="Nimbus-Eth2">

```text
(time()-process_start_time_seconds{job="beacon-client-job"})/3600
```

</TabItem> 
</Tabs>

**Alert: Validator Process Restarted**

```text
1:   Process up
0:   Process down
NaN: Not available (likely down --> 0)
```

![Validator Process Restarted Metric](/img/guides/alert-systems/grafana-alerts-5.png)

<Tabs groupId="client">
<TabItem value="lighthouse-prysm-teku" label="Lighthouse, Prysm, Teku">

```text
(time()-process_start_time_seconds{job="validator-client-job"})/3600
```

</TabItem>
</Tabs>

:::warning

The **Validator Proccess Restarted Alert** does not exist for **Nimbus-Eth2**, as it uses a single **Beacon Proccess**.

:::

**Alert: Below 40 Peers**

```text
above 30: Ideal healthy connections
below 30: Resyncing or weak connections
NaN:      Not available (no connections --> 0)
```

![Below 40 Peers Metric](/img/guides/alert-systems/grafana-alerts-6.png)

<Tabs groupId="client">
<TabItem value="lighthouse-prysm" label="Lighthouse & Prysm">

```text
p2p_peer_count{state="Connected",job="consensus-client-job"}
```

</TabItem><TabItem value="teku" label="Teku">

```text
libp2p_peers{job="consensus-client-job"}
```

</TabItem><TabItem value="nimbus" label="Nimbus-Eth2">

```text
connected_libp2p_peers{job="beacon-client-job"}
```

</TabItem> 
</Tabs>

**Alert: Participation Rate below 80%**

```text
above 80: Ideal healthy network
below 80: Unstable network
NaN:      2nd data feed (ignore metric --> 100)
```

![Participation Rate below 80% Metric](/img/guides/alert-systems/grafana-alerts-7.png)

<Tabs groupId="client">
<TabItem value="lighthouse-prysm-teku" label="Lighthouse, Prysm, Teku">

```text
(beacon_prev_epoch_target_gwei{job="consensus-client-job"} / beacon_prev_epoch_active_gwei{job="consensus-client-job"}) *100
```

</TabItem><TabItem value="teku-nimbus" label="Nimbus-Eth2">

```text
(beacon_prev_epoch_target_gwei{job="beacon-client-job"} / beacon_prev_epoch_active_gwei{job="beacon-client-job"}) *100
```

</TabItem> 
</Tabs>

**Alert: 50 Slots Behind**

```text
below 50: Ideal syncing speed
above 50: Unstable syncing
NaN:      Not available (likely unstable --> 51)
```

![50 Slots Behind Metric](/img/guides/alert-systems/grafana-alerts-8.png)

<Tabs groupId="client">
<TabItem value="prysm-teku" label="Prysm & Teku">

```text
beacon_clock_time_slot{job="consensus-client-job"} - beacon_head_slot{job="consensus-client-job"}
```

</TabItem><TabItem value="lighthouse" label="Lighthouse">

```text
slotclock_present_slot{job="consensus-client-job"} - beacon_head_slot{job="consensus-client-job"}
```

</TabItem><TabItem value="nimbus" label="Nimbus-Eth2">

```text
beacon_clock_time_slot{job="beacon-client-job"} - beacon_head_slot{job="beacon-client-job"}
```

</TabItem> 
</Tabs>

**Alert: No Hourly Earnings**

```text
above 0,0001: Earning rewards
below 0,0001: Syncing or negative rewards
NaN:          Not available (likely negative rewards --> 0)
```

![No Hourly Earnings Metric](/img/guides/alert-systems/grafana-alerts-9.png)

<Tabs groupId="client">
<TabItem value="prysm" label="Prysm">

```text
sum(validator_balance{job="validator-client-job"}) - sum(validator_balance{job="validator-client-job"} offset 1h != 0) - (32 * count(validator_balance{job="validator-client-job"} > 16)) + (32 * count(validator_balance{job="validator-client-job"} offset 1h > 16))
```

</TabItem><TabItem value="lighthouse" label="Lighthouse">

```text
((sum(validator_monitor_balance_gwei{job="validator-client-job"}) - sum(validator_monitor_balance_gwei{job="validator-client-job"} offset 1h != 0)) / 1e9) - (32 * count(validator_monitor_status{job="validator-client-job",status="active_ongoing"})) + (32 * count(validator_monitor_status{job="validator-client-job",status="active_ongoing"} offset 1h))
```

</TabItem><TabItem value="nimbus" label="Nimbus-Eth2">

```text
((sum(validator_monitor_balance_gwei{job="beacon-client-job"}) - sum(validator_monitor_balance_gwei{job="beacon-client-job"} offset 1h != 0)) / 1e9) - 32 * count(validator_monitor_status{job="beacon-client-job",status="active_ongoing"}) + 32 * count(validator_monitor_status{job="beacon-client-job",status="active_ongoing"} offset 1h)
```

</TabItem> 
</Tabs>

:::warning

The **Hourly Earnings Alert** does not exist for **Teku**, as it's client does not expose any **Validator Balance Metrics**.

:::

**Alert: Less than 2GB Free Memory**

```text
above 2000000000: More than 2GB remaining
below 2000000000: Less than 2GB remaining
```

![Less than 2GB Free Memory Metric](/img/guides/alert-systems/grafana-alerts-10.png)

```text
(node_memory_MemFree_bytes{job="node-exporter-job"} or node_memory_MemFree{job="node-exporter-job"}) + (node_memory_Cached_bytes{job="node-exporter-job"} or node_memory_Cached{job="node-exporter-job"})
```

**Alert: CPU Usage above 40%**

```text
above 4: More than 40% of computation resources used
below 4: Less than 40% of computation resources used
```

![CPU Usage above 40% Metric](/img/guides/alert-systems/grafana-alerts-11.png)

```text
sum(irate(node_cpu_seconds_total{mode="user",job="node-exporter-job"}[5m])) or sum(irate(node_cpu{mode="user",job="node-exporter-job"}[5m]))
```

**Alert: Disk Usage above 60%**

```text
above 0,6: Disk more than 60% occupied by tasks
below 0,6: Disk less than 60% occupied by tasks
```

![Disk Usage above 60% Metric](/img/guides/alert-systems/grafana-alerts-12.png)

```text
(sum(node_filesystem_size_bytes{job="node-exporter-job"})-sum(node_filesystem_avail_bytes{job="node-exporter-job"}))/sum(node_filesystem_size_bytes{job="node-exporter-job"})
```

**Alert: CPU Temperature above 75 ¬∞C**

```text
above 75: Processor is running hot
below 75: Processor is running normally
```

![CPU Temperature above 75 ¬∞C Metric](/img/guides/alert-systems/grafana-alerts-13.png)

```text
node_hwmon_temp_celsius{chip="platform_coretemp_0",job="node-exporter-job",sensor="temp1"}
```

**Alert: Google Ping above 30ms**

```text
above 0,03: Connection takes longer than 30ms, not ideal
below 0,03: Connection takes less than 30ms, everything alright
```

![Google Ping above 30ms Metric](/img/guides/alert-systems/grafana-alerts-14.png)

```text
probe_duration_seconds{job="google-ping-job"}
```

## 3. Configure Intervals

Once an alert is triggered, you can define how frequently the message will be sent out to your notification channel.

1. Navigate to the **Alerting** section on the left menu and click on the **Notification Policies** heading.
2. Select the **3-Dot-Menu** on the default notification channel and choose **Edit** within the popup.
3. Expand the **Timing Options** field to a duration or message frequency of your liking.

![Grafana Alert Interval](/img/guides/alert-systems/grafana-alerts-15.png)

:::info

Besides intervals, Grafana will also send a **Resolved** message once the issue is not present anymore.

:::

## 4. Continuous Notifications

Within the Grafana Dashboard, you can also enable _Alert Reminders_ that send notifications after a certain period of time. Setting it to one hour will send a notification every hour if a critical error or status has not changed yet.

## 5. Permanent Alerts

For a metric to send out permanent notifications, you can clone or create a new alert rule for a metric and define a rule that it is never supposed to be reached, so it permanently triggers. If you want hourly updates on the participation rate, you could select the alert for under 100% participation. In this case, you would constantly get notified about the network participation.

---

// File: guides/alert-systems/image-rendering

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 9.3 Image Rendering

Usually, regular notifications through Grafana can be quite hard to read and understand. However, instead of receiving text-based [Grafana Notifications](/docs/guides/alert-systems/grafana-notifications.md) through your alert channels, you can enable Grafana to render a picture of the metric, just as it is shown when logging in to the Grafana dashboard directly.

:::info

The following steps are performed on your üìü **node server**.

:::

## Install Image Renderer

To add the Image Rendering tool to your Grafana server, you have to install it's package.

**1.1 Check Grafana Version**: Verify which Grafana Version you have installed before breaking support.

```sh
grafana-server -v
```

**1.2 Install Render Plugin**: Use the built-in Grafana-CLI to install the suited image renderer for your Grafana installation.

<Tabs groupId="grafana">
  <TabItem value="latest" label="Grafana Version 11+" default>

```sh
sudo grafana-cli plugins install grafana-image-renderer 3.10.1
```

</TabItem> <TabItem value="9.5.2" label="Grafana Version 9.5.2">

```sh
sudo grafana-cli plugins install grafana-image-renderer 3.7.1
```

</TabItem>
</Tabs>

**1.3 Enable Image Capturing**: Add image captures to the global Grafana cofiguration file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
sudo vim /etc/grafana/grafana.ini
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
sudo nano /etc/grafana/grafana.ini
```

</TabItem>
</Tabs>

Then search for the following text section:

```text
#################################### Unified Alerting ####################

[unified_alerting]
```

**1.4 Set Image Capturing**: Underneath the Unified Alerting section, add the screenshot settings and safe the file.

```text
[unified_alerting.screenshots]
capture = true
```

The final section will look like this:

```text
#################################### Unified Alerting ####################

[unified_alerting.screenshots]
capture = true

[unified_alerting]
```

**1.5 Install Dependencies**: Install all necessary packages for the image rendering software.

<Tabs groupId="os">
  <TabItem value="ubuntu" label="Ubuntu" default>

```sh
sudo apt install -y libx11-6 libx11-xcb1 libxcomposite1 libxcursor1 libxdamage1 libxext6 libxfixes3 libxi6 libxrender1 libxtst6 libglib2.0-0 libnss3 libcups2  libdbus-1-3 libxss1 libxrandr2 libgtk-3-0 libasound2 libxcb-dri3-0 libgbm1 libxshmfence1
```

</TabItem> <TabItem value="debian" label="Debian">

```sh
sudo apt install -y libxdamage1 libxext6 libxi6 libxtst6 libnss3 libcups2 libxss1 libxrandr2 libasound2 libatk1.0-0 libatk-bridge2.0-0 libpangocairo-1.0-0 libpango-1.0-0 libcairo2 libatspi2.0-0 libgtk3.0-cil libgdk3.0-cil libx11-xcb-dev libgbm1 libxshmfence1
```

</TabItem>
</Tabs>

**1.6 Grant Permissions**: Grant the Grafana service user all necessary rights to read and execute plugins.

```sh
sudo chown -R grafana-server-worker:grafana-server-worker /var/lib/grafana/plugins
```

**1.7 Refresh Grafana**: Restart your Grafana server for the dependency to show up.

```sh
sudo systemctl restart grafana-server
```

**1.8 Verify Grafana Status**: Check if the Grafana Server restarted correctly.

```sh
systemctl status grafana-server
```

The output should look similar to this:

```text
‚óè grafana-server.service - Grafana instance
     Loaded: loaded (/lib/systemd/system/grafana-server.service; enabled; vendo>
     Active: active (running) since [DATE]; [TIME] ago
       Docs: http://docs.grafana.org
   Main PID: 28472 (grafana)
      Tasks: 30 (limit: 38043)
     Memory: 150.4M
        CPU: 6min 59.027s
     CGroup: /system.slice/grafana-server.service
             ‚îú‚îÄ28472 /usr/share/grafana/bin/grafana server --config=/etc/grafan>
             ‚îî‚îÄ28490 /var/lib/grafana/plugins/grafana-image-renderer/plugin_sta>

[DATE] [TIME] [USER] grafana-server[28472]: logger=context userId=1 orgI>...
...
```

:::tip

From now on, all notifications will automatically send graphs once the alert is triggered.

:::

## Revert Setup

If something went wrong, you can disable image rendering or remove the plugin all together.

**1. Disable Image Capturing**: Open the Grafana configuration file and remove or comment out the screenshot settings.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
vim /etc/grafana/grafana.ini
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
nano /etc/grafana/grafana.ini
```

</TabItem>
</Tabs>

Locate and remove or comment out the following section:

```ini
[unified_alerting.screenshots]
capture = true
```

**2. Remove the Render Plugin**: Uninstall the image renderer plugin using the Grafana CLI.

```sh
sudo grafana-cli plugins uninstall grafana-image-renderer
```

**3. Clean Up Plugin Directory**: Manually ensure all images and cache are removed from the plugin directory.

```sh
sudo rm -rf /var/lib/grafana/plugins/grafana-image-renderer
```

**4. Revert File Permissions**: Reset ownership of the plugin folder if it was changed previously.

```sh
sudo chown -R root:root /var/lib/grafana/plugins
```

**5. Restart Grafana**: Restart Grafana to apply the changes.

```sh
sudo systemctl restart grafana-server
```

**6. Verify Grafana Status**: Ensure Grafana is running properly after reverting the changes.

```sh
systemctl status grafana-server
```

The output should look similar to this:

```text
‚óè grafana-server.service - Grafana instance
     Loaded: loaded (/lib/systemd/system/grafana-server.service; enabled; vendo>
     Active: active (running) since [DATE]; [TIME] ago
       Docs: http://docs.grafana.org
   Main PID: 28472 (grafana)
      Tasks: 30 (limit: 38043)
     Memory: 150.4M
        CPU: 6min 59.027s
     CGroup: /system.slice/grafana-server.service
             ‚îú‚îÄ28472 /usr/share/grafana/bin/grafana server --config=/etc/grafan>
             ‚îî‚îÄ28490 /var/lib/grafana/plugins/grafana-image-renderer/plugin_sta>

[DATE] [TIME] [USER] grafana-server[28472]: logger=context userId=1 orgI>...
...
```

:::tip

Grafana will now stop rendering images in alert notifications and revert back to text-based alerts.

:::

---

// File: guides/alert-systems/custom-messages

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 9.4 Custom Messages

Grafana's default alert messages often include excessive technical details and raw values that make it difficult to quickly assess the situation or determine next steps. This guide walks you through how to customize and simplify those messages using annotations and templates, helping you to get actionable alerts across any Grafana version.

<Tabs groupId="message">
  <TabItem value="firing" label="Default Firing Message" default>

```text
**Firing**

Value: B=45.07955651176187, C=1
Labels:
 - alertname = Participation Rate below 80%
 - grafana_folder = node-alerts
 - instance = 127.0.0.1:8080
 - job = consensus-client-job
Annotations:
Source: http://localhost:3000/alerting/grafana/e10d1256-082f-4ca3-a936-aceea7759d78/view?orgId=1
Silence: http://localhost:3000/alerting/silence/new?alertmanager=grafana&matcher=alertname%3DParticipation+Rate+below+80%25&matcher=grafana_folder%3Dnode-alerts&matcher=instance%3D127.0.0.1%3A8080&matcher=job%3Dconsensus-client-job
Dashboard: http://localhost:3000/d/dashboard-id?orgId=1
Panel: http://localhost:3000/d/dashboard-id?orgId=1&viewPanel=120
```

</TabItem> <TabItem value="resolved" label="Default Resolved Message">

```text
**Resolved**

Value: B=85.07955651176187, C=1
Labels:
 - alertname = Participation Rate below 80%
 - grafana_folder = node-alerts
 - instance = 127.0.0.1:8080
 - job = consensus-client-job
Annotations:
Source: http://localhost:3000/alerting/grafana/e10d1256-082f-4ca3-a936-aceea7759d78/view?orgId=1
Silence: http://localhost:3000/alerting/silence/new?alertmanager=grafana&matcher=alertname%3DParticipation+Rate+below+80%25&matcher=grafana_folder%3Dnode-alerts&matcher=instance%3D127.0.0.1%3A8080&matcher=job%3Dconsensus-client-job
Dashboard: http://localhost:3000/d/dashboard-id?orgId=1
Panel: http://localhost:3000/d/dashboard-id?orgId=1&viewPanel=120
```

</TabItem>
</Tabs>

## Add Message Annotations

First, we have to add custom or additional context to the alert rule, that can later be displayed within our custom message.

![Grafana Alert Board](/img/guides/alert-systems/grafana-alerts-1.png)

:::tip

You can further customize the summary and description annotations beyond the default values in the following steps.

:::

1. Navigate to the **Alert Rules** from the top right menu of Grafana.
2. Edit the Alert Rule by clicking the **Edit Icon** on the right side of the list.
3. Copy the Name and scroll down the **Annotations** to **Configure the Notification Message**.
4. Choose the **Summary** annotation and input the previously copied **Alert Rule Name**.
5. Choose the **Description** annotation and input `{{ $values.B.Value }}` to reference the triggering value.
6. Safe and Exit the Alert Rule and repeat the process for all the remaining rules.

:::info

If you modified the default alert rules that were set up within the [**Grafana Notifications**](/docs/guides/alert-systems/grafana-notifications.md), you can exchange the referenced value with `{{ $values.C.Value }}` or `{{ $values.D.Value }}` depending on the applied rules at the top of the page.

:::

## Edit Contact Point Message

Once your alert rules are filled, you have to customize how the messages are sent via contact points. In Grafana, contact points aggregate the alert rules and manage how it's data is delivered through your notification setup. Using contact points, you have the chance to write fully customized messages and texts depending on what data is abailable or which rule is triggered.

1. Navigate to the **Contact Points** from the top right menu of Grafana.
2. Edit your [**Telegram Contact Point**](/docs/guides/alert-systems/telegram-bot.md) by clicking the **Edit Icon** on the right side of the list.
3. Within the **Integration Section**, extend the **Optional Telegram Settings**.
4. On the **Message** heading, click **Edit Message** to customize your text.
5. Click _Enter Custom Message_ and paste the following preset, then hit safe
6. On the **Contact Point Page**, click **Safe Contact Point**.

```text
{{ range .Alerts }}
LUKSO Alert Rule is: {{ .Status }}
Summary: {{ .Annotations.summary }}
Value: {{ .Annotations.description }}
{{ end }}
```

:::info

If you want to test messages, you can use the **Test Icon** on the **Contact Point Page** to send example notifications. To test the **Alert Rules** in production, you can modify a metric so it is triggered Immediately and sends off a message.

:::

Your updated Telegram Messages will now look like the following:

<Tabs groupId="message">
  <TabItem value="firing" label="New Firing Message" default>

```text
LUKSO Alert Rule is firing
Summary: Disk Usage above 60%
Value: 0.7462574211663442
```

</TabItem> <TabItem value="resolved" label="New Resolved Message">

```text
LUKSO Alert Rule is resolved
Summary: Disk Usage above 60%
Value: 0.2462574211663442
```

</TabItem>
</Tabs>

:::tip

Further message templates and customization options can be found on the [**Grafana Contact Points Documentation**](https://grafana.com/docs/grafana/latest/alerting/configure-notifications/manage-contact-points/).

:::

---

// File: guides/alert-systems/selfnode-alerts

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 9.5 Selfnode Alerts

The [Selfnode Validator Monitoring](https://www.selfnodes.com/validatormonitoring) is a free and user-friendly alerting service that helps LUKSO validators monitor the performance and health of their nodes. Unlike setting up a custom alerting system using [Grafana Notifications](/docs/guides/alert-systems/grafana-notifications.md) and a [Telegram Bot](/docs/guides/alert-systems/telegram-bot.md), Selfnode does not requires any advanced setup. Once you provide your validator indices, the service automatically tracks events and sends you alerts via various channels. It‚Äôs ideal for homestakers who prefer simplicity and reliability without the overhead.

![Selfnode Validator Monitoring Frontpage](/img/guides/monitoring/selfnode.png)

:::tip Supported Notification Methods

- üì© Email Inbox
- üì± Telegram Channels
- üëæ Discord Webhooks
- üì• Push Notifications

:::

## 1. Retrieve Validator Indices

To begin receiving alerts, you must submit a list of your validator indices to Selfnode. These indices identify your validators on the LUKSO network. You can retrieve them by scanning your local validator logs, generated by the clients or [LUKSO CLI](https://github.com/lukso-network/tools-lukso-cli).

:::info

The following steps are performed on your üìü **node server**.

:::

**1. Move into Node Folder**: Navigate into your log folder within your node setup.

<Tabs groupId="network">
  <TabItem value="mainnet" label="Mainnet" default>

```sh
cd
cd <lukso-working-directory>/mainnet-logs/
```

</TabItem> <TabItem value="testnet" label="Testnet">

```sh
cd
cd <lukso-working-directory>/testnet-logs/
```

</TabItem>
</Tabs>

:::info

Exchange `<lukso-working-directory>` with the actual folder name of your node setup.

:::

**2. Search Resent Log File**: Find the latest validator log file to retrieve the imported validators.

```sh
find . -type f -name "*validator*" -printf "%T@ %p\n" | sort -n | tail -1 | awk '{print $2}'
```

<details>
  <summary>Full Command Description</summary>

| Component                            | Description                                                                   |
| ------------------------------------ | ----------------------------------------------------------------------------- |
| <nobr> `find .` </nobr>              | Current directory as the starting point for the file search.                  |
| <nobr> `-type f` </nobr>             | Tells `find` to only consider regular files and ignore directories.           |
| <nobr> `-name "*validator*"` </nobr> | Matches files with "validator" anywhere in their names.                       |
| <nobr> `-printf "%T@ %p\n"` </nobr>  | Formats the output to show modification time `%T@` followed by the path `%p`. |
| <nobr> `sort -n` </nobr>             | Pipes the list and sorts the lines numerically by the modification time.      |
| <nobr> `tail -1` </nobr>             | Selects the last line, corresponding to the most recently modified file.      |
| <nobr> `awk '{print $2}'` </nobr>    | Extracts and prints the file path from the output line.                       |

</details>

**3. Create Monitoring Link**: Search the most recent log file and access all imported validators.

```sh
cat <validator-log.log> | grep -o 'index=[0-9]* ' | awk -F'=' '{printf "%s,", $2}' | sed 's/,$//' | tr -d ' ' | awk '{print $0}'
```

:::info

Exchange `<validator-log.log>` with the actual filename of the most recent validator log file.

:::

<details>
  <summary>Full Command Description</summary>

| Component                                       | Description                                                                                        |
| ----------------------------------------------- | -------------------------------------------------------------------------------------------------- |
| <nobr> `cat file` </nobr>                       | Displays all file contents including all the validator information.                                |
| <nobr> `grep -o 'index=[0-9]* '` </nobr>        | Extracts all occurrences of `index=` followed by digits, using `-o` to return only matching parts. |
| <nobr> `awk -F'=' '{printf "%s,", $2}'` </nobr> | Splits each match on `=`, and prints only the validator number followed by a comma.                |
| <nobr> `sed 's/,$//'` </nobr>                   | Removes the trailing comma from the end of the list.                                               |
| <nobr> `tr -d ' '` </nobr>                      | Deletes all spaces from the output, resulting in a compact list of comma-separated index numbers.  |
| <nobr> `awk '{print $0}'` </nobr>               | Prints the entire index number string                                                              |

</details>

The output will look similar to this one, having all your index numbers:

```text
111,222,888
```

## 2. Configure Validator Alerts

Once you have your complete validator index list, you're ready to activate the related monitoring service.

1. Open the [**Selfnode Validator Monitoring**](https://www.selfnodes.com/validatormonitoring) service.
2. Select the **LUKSO Logo** from the dropdown menu on the left.
3. Paste your comma-separated **Validator Index String** into the input field.
4. Press the **Arrow Button** on the right to submit your validator list.
5. Log in or **Create an Account** to configure your alerts.

:::tip

Within the Selfnode Dashboard, you can configure when and how frequently messages are sent out by:

- üì© Attaching your _Email_ address.
- üì± Adding your _Telegram_ handle for a message channel.
- üëæ Configuring a _Discord Webhook_ for your server or message channel.
- üì• Setting up _Push Notifications_ for a mobile device or desktop browser.

:::

---

// File: guides/external-access/tailscale

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 10.1 Tailscale

Tailscale is a modern VPN service that allows you to create a secure, encrypted connection between your devices using a simple and user-friendly interface. It is especially useful for remote server access, such as connecting to your node from anywhere in the world without exposing public ports or relying on complicated firewall configurations.

:::tip

Further details about SSH and VPN protocols can be found on the [**SSH and VPN Tunnel**](/docs/theory/node-operation/ssh-and-vpn-tunnel.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Software Installation

Visit the [Tailscale Webpage](https://tailscale.com/) and register for the service. It's a free for a limited amount of users and devices. After logging in with your favorite identity provider, you will be prompted to connect your first two devices. Click on _Linux_ to connect your node.

```sh
sudo apt-get update
sudo apt-get install tailscale
```

You can also enable auto-updates for Tailscale.

```sh
tailscale set --auto-update
```

After the installation, activate Tailscale.

```sh
tailscale up
```

You will receive a link that you must copy and paste to the terminal of your node in order to connect the device with your account.

:::info

Continue with the second device, like your personal computer or smartphone. The Guide on the Tailscale webpage will give you a selection of possible installations. After activating Tailscale on both, your devices will be able to communicate.

:::

## 2. Configure Auto Startup

Tailscale comes with its own CLI tool called _tailscaled_. By default, it will list itself as a system service for easy maintenance. You can retreive the service's status directly from the system control or further stop, restart, or disable autostarts in a similar way.

```sh
systemctl status tailscaled
```

The output should be something similar to the following:

```text
‚óè tailscaled.service - Tailscale node agent
     Loaded: loaded (/lib/systemd/system/tailscaled.service; enabled; vendor preset: enabled)
     Active: active (running) since Fri 2023-05-19 20:01:42 UTC; 3h 19min ago
       Docs: https://tailscale.com/kb/
   Main PID: 1005 (tailscaled)
     Status: "Connected; [EMAIL-ACCOUNT]; [TAILSCALE-IP] [MAC-ADDRESS]"
      Tasks: 17 (limit: 38043)
     Memory: 40.6M
        CPU: 1min 29.134s
     CGroup: /system.slice/tailscaled.service
             ‚îî‚îÄ1005 /usr/sbin/tailscaled --state=/var/lib/tailscale/tailscaled.state --socket=/run/tailsc>

[DATE] [TIME] [USER] tailscaled[4974]: control: NetInfo: NetInfo{varies=false hairpin=false ipv6=true ipv>...
```

The service should already be configured to start and connect during boot or failure. Verify it once again.

```sh
sudo systemctl enable tailscaled
```

If it was not set already, the command created a _symlink_ and print out the filenames.

:::info

The following steps are performed on your üíª **personal computer**.

:::

## 3. Update SSH Config

As Tailscale uses internal static IP addresses on both ends of the tunnel, you must also update the SSH configuration to connect to the new IP once outside of your home network. On your personal computer, open up the SSH file using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
vim ~/.ssh/config
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
nano ~/.ssh/config
```

</TabItem>
</Tabs>

If you want to connect to your node via Tailscale, you must use the new Tailscale IP instead. You will find this static and internal IP on the _Tailscale Device Dashboard_. You can copy it over to a text file. Then dplicate the node's _Host_ entry and exchange the _HostName_ with the new IP and the _Host_ property with a new alias. The final entry should look like this:

```text
Host <ssh-device-alias-for-home-environment>
  User <node-username>
  HostName <node-ip>
  Port <ssh-port>
  IdentityFile ~/.ssh/<my-chosen-keyname>

Host <ssh-device-alias-for-tailscale-environment>
  User <node-username>
  HostName <tailscale-node-ip>
  Port <ssh-port>
  IdentityFile ~/.ssh/<my-chosen-keyname>
```

Save the file and exit. Then try to connect to your node while Tailscale is active.

```sh
ssh <ssh-device-alias-for-tailscale-environment>
```

:::info

Exchange the `<ssh-device-alias-for-tailscale-environment>` with the actual SSH device name.

:::

## 4. Update Grafana Dashboard

If you want to visit your Grafana Dashboard outside your home network using Tailscale, you will need to adjust the IP once again. As you did with the SSH, having two different browser bookmarks is recommended: one for your home environment and one for the static Tailscale IP. Within your browser, you can find Grafana at the following address in case your VPN is activated:

```text
http://<tailscale-node-ip>:3000/login
```

:::info

Exchange the `<tailscale-node-ip>` with the actual IP address found in the _Tailscale Device Dashboard_.

:::

## 5. Disable Key Expiry

By default, Tailscale session keys from devices expire after 180 days of being unused, meaning you wont be able to re-connect to your node without maintenance. If you want to raise the limit or turn key expiry off for your main devices, you can do so by navigating into the _Tailscale Device Dashboard_ once logged in to their web service. On your node device, click on the three dots menu behind the static Tailscale IP and either select _Disable Expiry Date_ or _Specify Expiry Period_.

:::tip

Expiry settings are device-specific and can be adjusted anytime within the _Tailscale Device Dashboard_.

:::

---

// File: guides/maintenance/software-updates

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 11.1 Software Updates

This guide explains how to update system software, and perform cleanups, important for security and performance.

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Retrieve Outdated Packages

```sh
# Update Package List
sudo apt update

# List Upgradable Packages
apt list --upgradable
```

:::warning Monitoring Compatability

The monitoring tool [Grafana](/docs/guides/monitoring/grafana.md) is installed as a system package. If you want to prevent incompatibilities, its recommended to pause these updates until the latest dashboard templates are available for your blockchain clients.

:::

<Tabs >
  <TabItem value="hold" label="Pause Grafana Updates" default>

```sh
sudo apt-mark hold grafana
```

</TabItem> <TabItem value="unhold" label="Resume Grafana Updates">

```sh
sudo apt-mark unhold grafana
```

</TabItem>
</Tabs>

## 2. Stop Node Operation

Depending on your setup method, there are different ways to stop your node before applying updates.

<Tabs groupId="setup">
  <TabItem value="cli" label="LUKSO CLI" default>

```sh
cd <lukso-working-directory>
lukso stop
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl stop lukso-validator
```

</TabItem>
</Tabs>

<details>
<summary>Force Client Shutdown</summary>

<Tabs>
<TabItem value="geth" label="Geth">

```sh
sudo pkill geth
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
sudo pkill erigon
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
sudo pkill nethermind
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
sudo pkill besu
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
sudo pkill teku
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
sudo pkill nimbus_beacon_node
sudo pkill nimbus_validator_client
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```sh
sudo pkill lighthouse
```

:::tip

The Lighthouse client uses a single binary for both the consensus and validator processes.

:::

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
sudo pkill prysm
sudo pkill validator
```

</TabItem>
</Tabs>

</details>

## 3. Apply Software Updates

Update all currently installed packages and hardware drivers to their latest versions and reboot to apply changes.

```sh
sudo apt upgrade
```

:::info

When prompted during upgrade:

- Choose to keep your current SSH configuration (`<OK>`)
- Acknowledge updates to system libraries and services (`<OK>`)

:::

:::tip

Kernel and background services will update after a system reboot.

:::

```sh
sudo reboot
```

:::info

You will be logged out of the SSH connection. Once the system rebooted, reconnect using SSH to continue.

:::

## 4. System Cleanup

Remove unnecessary packages and clean up outdated cache data of system installation processes.

```sh
# Remove Unused Dependencies
sudo apt autoremove

# Clean Cached Package Files
sudo apt autoclean
```

## 5. Restart the Node

Depending on your setup method, there are different ways to start your node.

<Tabs groupId="setup">
  <TabItem value="clinode" label="LUKSO CLI Node" default>

```sh
cd <lukso-working-directory>
lukso start --checkpoint-sync
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="clivalidator" label="LUKSO CLI Validator" default>

```sh
cd <lukso-working-directory>
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync
```

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path of the node folder
- `<your-fee-recipient-address>` with the wallet address receiving staking profits

:::

</TabItem> <TabItem value="automation" label="Service Automation">

:::info

If the system was rebooted before, automated services like the validator node should restart automatically. You can check the current status of the service to clarify whether it is necessary to start it manually or if updates introduced any problems.

:::

```sh
sudo systemctl status lukso-validator
```

If the service is not active or you did not reboot your node, you can start the service manually.

```sh
sudo systemctl start lukso-validator
```

</TabItem>
</Tabs>

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

:::tip

[**Monitoring Tools**](/docs/theory/node-operation/monitoring-tools.md) like [Grafana](/docs/guides/monitoring/grafana.md), [Prometheus](/docs/guides/monitoring/prometheus.md), or the [Exporter](/docs/guides/monitoring/node-exporter.md) services will automatically start during the system reboot.

:::

---

// File: guides/maintenance/client-updates

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 11.2 Client Updates

This guide explains how to update your LUKSO CLI, blockchain clients, configuration files, and validator permissions.

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Stop Node Operation

Depending on your setup method, there are different ways to stop your node before applying updates.

<Tabs groupId="setup">
  <TabItem value="cli" label="LUKSO CLI" default>

```sh
cd <lukso-working-directory>
lukso stop
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl stop lukso-validator
```

</TabItem>
</Tabs>

<details>
<summary>Force Client Shutdown</summary>

<Tabs groupId="client">
<TabItem value="geth" label="Geth">

```sh
sudo pkill geth
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
sudo pkill erigon
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
sudo pkill nethermind
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
sudo pkill besu
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
sudo pkill teku
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
sudo pkill nimbus_beacon_node
sudo pkill nimbus_validator_client
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```sh
sudo pkill lighthouse
```

:::tip

The Lighthouse client uses a single binary for both the consensus and validator processes.

:::

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
sudo pkill prysm
sudo pkill validator
```

</TabItem>
</Tabs>

</details>

## 2. Update CLI and CLients

Install the latest CLI version and update the client software.

```sh
# Install Latest LUKSO CLI
sudo curl https://install.lukso.network | sh

# Verify CLI Version
lukso version
```

:::info

Check your current client versions.

<Tabs groupId="client">
<TabItem value="geth" label="Geth">

```sh
geth version
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
erigon --version
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
nethermind --version
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
besu --version
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
teku --version
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
nimbus_beacon_node --version
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```sh
lighthouse --version
```

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
prysm --version
```

</TabItem>
</Tabs>

:::

```sh
# Move into Node Directory
cd <lukso-working-directory>

# Update the Blockchain Clients
sudo lukso update
```

:::tip

Check your updated client versions again using the commands above to verify they were installed correctly.

:::

## 3. Update Client Configs

This optional step ensures your client configuration files stay aligned with the latest specifications and network forks.

```sh
sudo lukso init
sudo lukso update configs
```

:::info

None of your client-specific settings will be overwritten.

- The `lukso update configs` command only updates the global `/configs/<network>/shared/` files.
- The `lukso init` command only creates missing files and folders within the `/configs/` folder.

:::

:::warning

The LUKSO Network Team regularly introduces changes to the default client-specific configurations. It's recommended to update them manually. Further guidance can be found on the [**Configuration Updates**](/docs/archive/network/configuration-updates.md) page of the üèõÔ∏è [**Archive**](/docs/archive/network/blockchain-timeline.md) section.

:::

## 4. Remove Genesis Flags

Make sure that you no longer use Genesis flags to start the node, as the network was launched and flags are no longer needed.

:::tip

This step is only required for genesis validators using a [service automation](/docs/guides/modifications/service-automation.md) setup to manage their node. Regular node setups simply do no longer attach the `--genesis-json` and `--genesis-ssz` flags during the startup.

:::

**4.1 Open the Service File**: Open the startup script with your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/static/
sudo vim ./lukso_startup.sh
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/static/
sudo nano ./lukso_startup.sh
```

</TabItem>
</Tabs>

:::info

Exchange `<lukso-working-directory>` with the path to the node folder.

:::

**4.2 Modify the Service File**: Remove the following lines from the startup script.

```text
        --genesis-json ./configs/mainnet/shared/genesis_42.json \
        --genesis-ssz ./configs/mainnet/shared/genesis_42.ssz \
```

## 5. Restart the Node

Depending on your setup method, there are different ways to start your node after updates have been applied.

<Tabs groupId="setup">
  <TabItem value="clinode" label="LUKSO CLI Node" default>

```sh
cd <lukso-working-directory>
lukso start --checkpoint-sync
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="clivalidator" label="LUKSO CLI Validator" default>

```sh
cd <lukso-working-directory>
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync
```

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path of the node folder
- `<your-fee-recipient-address>` with the wallet address receiving staking profits

:::

</TabItem> <TabItem value="automation" label="Service Automation">

:::warning

For improved security, the service automation is started from a separate user with restricted rights. New permissions must be assigned to all data and software folders affected by the previous updates before the node should be restarted.

:::

```sh
sudo chown -R lukso-validator-worker:lukso-validator-worker /home/<user-name>/<lukso-working-directory>
sudo chown lukso-validator-worker:lukso-validator-worker /usr/local/bin/lukso
sudo chmod -R 750 /home/<user-name>/<lukso-working-directory>
sudo chmod 755 /home/<user-name>/<lukso-working-directory>
sudo chmod 400 /home/<user-name>/<lukso-working-directory>/static/<your-generic-password-file>
sudo chmod 500 /home/<user-name>/<lukso-working-directory>/static/lukso_startup.sh
```

:::info

The following properties need to be exchanged:

- `<user-name>` with the user name used to login to your node
- `<lukso-working-directory> ` with the path of the node folder
- `<your-generic-password-file>` with the full name of the password file to start the validator

:::

<details>
  <summary>Full Command Descriptions</summary>

| **Setting**                                              | **Description**                                                     |
| -------------------------------------------------------- | ------------------------------------------------------------------- |
| <nobr> `sudo chown -R <user>:<user> <directory>` </nobr> | Recursively assign user ownership to all directory contents.        |
| <nobr> `sudo chown <user>:<user> <directory>` </nobr>    | Assign ownership to a single folder or file.                        |
| <nobr> `sudo chmod -R 750 <directory>` </nobr>           | Set executable and readable permissions for a user and group.       |
| <nobr> `sudo chmod 755 <directory>` </nobr>              | Set readable permissions for everyone, typically for general files. |
| <nobr> `sudo chmod 400 <directory>/<file>` </nobr>       | Read-only access for owner, typically for secret information.       |
| <nobr> `sudo chmod 500 <directory>/<file>` </nobr>       | Executable-only by owner, typically for service scripts.            |

</details>

Once the original rights have been restored, the service can be started.

```sh
sudo systemctl start lukso-validator
```

:::warning

If the service does not start up, check the service status before and reapply the necessary permissions.

:::

```sh
sudo systemctl status lukso-validator
```

</TabItem>
</Tabs>

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

---

// File: guides/maintenance/problem-scanning

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 11.3 Problem Scanning

This guide shows how to identify synchronization or configuration problems, to help solve problems in advance.

:::info

The following steps are performed on your üìü **node server**.

:::

## Check the Node Status

The [LUKSO CLI](https://github.com/lukso-network/tools-lukso-cli) comes with a built-in status command to check the health of execution, consensus, and validator clients.

```sh
lukso status
```

## Listen to Live Logs

The [LUKSO CLI](https://github.com/lukso-network/tools-lukso-cli) comes with its own logging functionality, directly printed to the terminal and stored in the node directory.

<Tabs groupId="network">
  <TabItem value="mainnet" label="Mainnet" default>

```sh
# Check execution logs
lukso logs execution

# Check consensus logs
lukso logs consensus
```

</TabItem> <TabItem value="testnet" label="Testnet">

```sh
# Check execution logs
lukso logs execution --testnet

# Check consensus logs
lukso logs consensus --testnet
```

</TabItem>
</Tabs>

## Search Log Files

The file logging system of the [LUKSO CLI](https://github.com/lukso-network/tools-lukso-cli) also enables keyword-based filtering for log file contents.

:::info

You can search the extending log files using the `grep` tool for global expression search.

:::

<Tabs groupId="network">
  <TabItem value="mainnet" label="Mainnet" default>

```sh
# Fetch all execution warnings
lukso logs execution | grep "warning"

# Fetch all validator warnings
lukso logs validator | grep "warning"

# Fetch all consensus warnings
lukso logs consensus | grep "warning"

# Fetch all execution errors
lukso logs execution | grep "error"

# Fetch all validator errors
lukso logs validator | grep "error"

# Fetch all consensus errors
lukso logs consensus | grep "error"
```

</TabItem> <TabItem value="testnet" label="Testnet">

```sh
# Fetch all execution warnings
lukso logs execution --testnet | grep "warning"

# Fetch all validator warnings
lukso logs validator --testnet | grep "warning"

# Fetch all consensus warnings
lukso logs consensus --testnet | grep "warning"

# Fetch all execution errors
lukso logs execution --testnet | grep "error"

# Fetch all validator errors
lukso logs validator --testnet | grep "error"

# Fetch all consensus errors
lukso logs consensus --testnet | grep "error"
```

</TabItem>
</Tabs>

:::tip

After executing the command, the terminal is waiting for an input. You will have to press the _ENTER_ key to see the outputs.

:::

:::warning

If you run the LUKSO CLI through service automation, ensure to execute all `lukso` commands with `sudo` permissions.

:::

## Attach Execution Clients

Execution clients have JSON-RPC endpoints allowing users to request information and access the blockchain state of their local nodes directly. Erigon and Geth even have built-in JavaScript consoles linked with such endpoints for programming capabilities. Both tools are helpful for manual checking of syncing progress, peers, blocks, and balances.

:::info JSON RPC

JSON-RPC is a lightweight communication protocol encoded in JSON, allowing calls to be sent to a service or server. Each execution client exposes a related interface at port `8545` to retreive calls to interact with the Ethereum network though the local node. The RPC allows to query network stats, node metadata, blockchain data, or even send transactions and interact with smart contracts.

:::

:::tip

By default, the [LUKSO Network Configuration](https://github.com/lukso-network/network-configs) allows a variety of JSON RPC modules for the Nethermind and Besu client, while restricting their use for Erigon and Geth clients due to their JavaScript console. If you're using Geth or Erigon, you will first have to adjust the client-configuration to allow the regular data packages from being accessed.

:::

<Tabs>
<TabItem value="geth-erigon" label="Geth and Erigon" default>

**1. Stop Node Operation**: _Depending on your setup method, there are different ways to stop your node to adjust configurations._

<Tabs groupId="setup">
  <TabItem value="cli" label="LUKSO CLI" default>

```sh
cd <lukso-working-directory>
lukso stop
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl stop lukso-validator
```

</TabItem>
</Tabs>

<details>
<summary>Force Client Shutdown</summary>

<Tabs>
<TabItem value="geth" label="Geth">

```sh
sudo pkill geth
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
sudo pkill erigon
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
sudo pkill teku
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
sudo pkill nimbus_beacon_node
sudo pkill nimbus_validator_client
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```sh
sudo pkill lighthouse
```

:::tip

The Lighthouse client uses a single binary for both the consensus and validator processes.

:::

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
sudo pkill prysm
sudo pkill validator
```

</TabItem>
</Tabs>

</details>

**2. Enable Full RPC Data**: _Modify the default network configuration of your execution client._

<Tabs groupId="client">
<TabItem value="geth" label="Geth">

Use your preferred editor to modify the client configuration file.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>
vim geth/geth.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>
nano geth/geth.toml
```

</TabItem>
</Tabs>

:::info

Exchange `<lukso-working-directory>` and `<network>` with the path of the node folder and the network type.

:::

Change the included module list to include the default execution client commands.

```text
# Default Value
HTTPModules = ["net"] # ["net", "eth", "web3", "debug", "engine", "txpool"]

# Updated Value
HTTPModules = ["net", "engine", "eth", "web3"] # ["net", "eth", "web3", "debug", "engine", "txpool"]
```

</TabItem> <TabItem value="erigon" label="Erigon">

Use your preferred editor to modify the client configuration file.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>
vim erigon/erigon.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>
nano erigon/erigon.toml
```

</TabItem>
</Tabs>

:::info

Exchange `<lukso-working-directory>` and `<network>` with the path of the node folder and the network type.

:::

Change the included module list to include the default execution client commands.

```text
# Default Value
"http.api" = "erigon,engine" # "eth,erigon,engine,debug,trace"

# Updated Value
"http.api" = "erigon,engine,eth,net,web3" # "eth,erigon,engine,debug,trace"
```

</TabItem>
</Tabs>

:::warning

Ensure there are no missing characters or additional spaces within the configuration file.

:::

<details>
    <summary>Full Module Explanation</summary>

| Module     | Description                                   | Potential Risks                                       |
| ---------- | --------------------------------------------- | ----------------------------------------------------- |
| **ETH**    | Core blockchain operations.                   | None. Enabled by default without configuration.       |
| **NET**    | Retrieve network status and connections.      | None. Enabled by default without configuration.       |
| **WEB3**   | Blockchain helpers and client metadata.       | None. Enabled by default without configuration.       |
| **ENGINE** | Engine API used by consensus client.          | None. Enabled by default for validator nodes.         |
| **TXPOOL** | Inspect pending and queued transaction pool.  | Exposes pool and consumes computing power.            |
| **ADMIN**  | Low-level node management for peers and RPCs. | Lets attackers shut down RPCs, or export chain data.  |
| **DEBUG**  | Deep execution tracing and state inspection.  | Exposes call stacks, storage slots and pre-images.    |
| **TRACE**  | Block and transaction replay traces.          | Heavy EVM-execution calls can freeze or crash a node. |

</details>

Save the file and exit the editor.

**3. Restart the Node**: _Depending on your setup, there are different ways to start your node with the updated configuration._

<Tabs groupId="setup">
  <TabItem value="clinode" label="LUKSO CLI Node" default>

```sh
cd <lukso-working-directory>
lukso start --checkpoint-sync
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="clivalidator" label="LUKSO CLI Validator" default>

```sh
cd <lukso-working-directory>
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync
```

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path of the node folder
- `<your-fee-recipient-address>` with the wallet address receiving staking profits

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl start lukso-validator
```

</TabItem>
</Tabs>

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

**4. Connect to Interface**: _While the node is running, connect to the interface of the specific execution client._

<Tabs groupId="client">
<TabItem value="geth" label="Geth">

```sh
geth attach http://localhost:8545
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
erigon attach http://localhost:8545
```

</TabItem>
</Tabs>

**5. Retrieve Data**: _If you are listening to the port, you can check your connections and interact with the execution client._

```sh
# Check Available Commands
> eth
> net
> web3

# Check Current Block Height
> parseInt(eth.blockNumber, 16)

# Check Syncing Status
# -- Syncing: Object
# -- Synced: False
> eth.syncing

# Retrieve Execution Peers
> parseInt(net.peerCount, 16)

# Get Current Gas Price
> parseInt(eth.gasPrice)

# Check External Connections
> net.listening

# Verify Network Chain ID
> parseInt(eth.chainId, 16)

# Verify Client Version
> web3.clientVersion

# Quit Port Connection
> exit
```

:::info

The `parseInt()` function will convert the hexadecimal output to a human-readable decimal number.

:::

</TabItem><TabItem value="Nethermind-besu" label="Nethermind and Besu">

**1. Install Querying Tool**: _Install the JSON query service for data processing from the RPC endpoint._

```sh
sudo apt install jq
```

**2. Call Endpoints**: _While the node is running, call the JSON RPC of the execution client._

```sh
# Check Current Block Height
curl -s -X POST -H "content-type: application/json" \
  --data '{"jsonrpc":"2.0","method":"eth_blockNumber","params":[],"id":1}' \
  http://localhost:8545 | jq -r '.result' | xargs printf '%d\n'

# Check Syncing Status
curl -s -X POST -H "Content-Type: application/json" \
  --data '{"jsonrpc":"2.0","method":"eth_syncing","params":[],"id":1}' \
  http://localhost:8545 | jq -r '.result'

# Retrieve Execution Peers
curl -s -X POST -H "content-type: application/json" \
  --data '{"jsonrpc":"2.0","method":"net_peerCount","params":[],"id":1}' \
  http://localhost:8545 | jq -r '.result' | xargs printf '%d\n'

# Get Current Gas Price
curl -s -X POST -H "Content-Type: application/json" \
  --data '{"jsonrpc":"2.0","method":"eth_gasPrice","params":[],"id":1}' \
  http://localhost:8545 | jq -r '.result' | xargs printf '%d\n'

# Check External Connections
curl -s -X POST -H "Content-Type: application/json" \
  --data '{"jsonrpc":"2.0","method":"net_listening","params":[],"id":1}' \
  http://localhost:8545 | jq -r '.result'

# Verify Network Chain ID
curl -s -X POST -H "Content-Type: application/json" \
  --data '{"jsonrpc":"2.0","method":"eth_chainId","params":[],"id":1}' \
  http://localhost:8545 | jq -r '.result' | xargs printf '%d\n'

# Verify Client Version
curl -s -X POST -H "Content-Type: application/json" \
  --data '{"jsonrpc":"2.0","method":"web3_clientVersion","params":[],"id":1}' \
  http://localhost:8545 | jq -r '.result'
```

<details>
    <summary>Full Command Explanation</summary>

| **Command**                                                               | **Description**                                                                                                                                     |
| ------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> `curl -s -X POST -H <text> ` <br /> `--data <text> <port>` </nobr> | Executes `-X` a silent `-s` HTTP `POST` request to the given `<port>`, while attaching custom header `-H` and `--data` content as `<text>` payload. |
| <nobr> `jq -r '.result'` </nobr>                                          | Filters the raw `-r` JSON object and extracts the `.result` value of the data object.                                                               |
| <nobr> `xargs printf '%d\n'` </nobr>                                      | Converts the hexadecimal result to a human-readable decimal `%d` number.                                                                            |

</details>

</TabItem>
</Tabs>

## Fetch Consensus API

Access to the consensus endpoint allows for fetching validator status, health checks, peer counts, and metadata of the beacon chain. The feature can help verify client performance and check synchronization health directly from the beacon node's HTTP port.

:::info REST API

A REST API is a web-based interface for querying structured data. Ethereum consensus clients expose their status and internal metrics on various ports like `3500`, `5051`, or `5052`, to allow users to access information such as synchronization progress, network stability, node metadata, or the current chain head.

:::

:::tip

By default, the [LUKSO Network Configuration](https://github.com/lukso-network/network-configs) opens the REST API ports for all consensus clients.

:::

**1. Install Querying Tool**: _Install the JSON query service for data processing from the REST API endpoint._

```sh
sudo apt install jq
```

**2. Call Endpoints**: _While the node is running, call the REST endpoint of the consensus client._

<Tabs>
  <TabItem value="teku" label="Teku">

```sh
# Check Syncronization Status
curl -s http://localhost:5051/eth/v1/node/syncing | jq

# Check Overall Health
curl -s http://localhost:5051/eth/v1/node/health | jq

# Check Node Identity
curl -s http://localhost:5051/eth/v1/node/identity | jq

# Check Number of Peers
curl -s http://localhost:5051/eth/v1/node/peer_count | jq

# Fetch Latest Block Header
curl -s http://localhost:5051/eth/v1/beacon/headers/head | jq
```

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
# Check Syncronization Status
curl -s http://localhost:3500/eth/v1/node/syncing | jq

# Check Overall Health
curl -s http://localhost:3500/eth/v1/node/health | jq

# Check Node Identity
curl -s http://localhost:3500/eth/v1/node/identity | jq

# Check Number of Peers
curl -s http://localhost:3500/eth/v1/node/peer_count | jq

# Fetch Latest Block Header
curl -s http://localhost:3500/eth/v1/beacon/headers/head | jq
```

</TabItem> <TabItem value="lighthouse-nimbus2" label="Lighthouse and Nimbus-Eth2">

```sh
# Check Syncronization Status
curl -s http://localhost:5052/eth/v1/node/syncing | jq

# Check Overall Health
curl -s http://localhost:5052/eth/v1/node/health | jq

# Check Node Identity
curl -s http://localhost:5052/eth/v1/node/identity | jq

# Check Number of Peers
curl -s http://localhost:5052/eth/v1/node/peer_count | jq

# Fetch Latest Block Header
curl -s http://localhost:5052/eth/v1/beacon/headers/head | jq
```

</TabItem>
</Tabs>

---

// File: guides/maintenance/revert-client-versions

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 11.4 Revert Client Versions

The [LUKSO CLI](https://github.com/lukso-network/tools-lukso-cli) allows to downgrade clients to an earlier version below the latest supported one. This might solve potential stability, database, or configuration issues that happen after an upgrade or maintenance. However, keep in mind that older versions must feature support for the latest [network fork](/docs/archive/network/network-forks.md) to keep up with the current chain head and stake funds.

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Stop Node Operation

Depending on your setup method, there are different ways to stop your node before applying updates.

<Tabs groupId="setup">
  <TabItem value="cli" label="LUKSO CLI" default>

```sh
cd <lukso-working-directory>
lukso stop
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl stop lukso-validator
```

</TabItem>
</Tabs>

<details>
<summary>Force Client Shutdown</summary>

<Tabs>
<TabItem value="geth" label="Geth">

```sh
sudo pkill geth
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
sudo pkill erigon
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
sudo pkill nethermind
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
sudo pkill besu
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
sudo pkill teku
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
sudo pkill nimbus_beacon_node
sudo pkill nimbus_validator_client
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```sh
sudo pkill lighthouse
```

:::tip

The Lighthouse client uses a single binary for both the consensus and validator processes.

:::

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
sudo pkill prysm
sudo pkill validator
```

</TabItem>
</Tabs>

</details>

Then move into the node directory:

```sh
cd
cd <lukso-working-directory>
```

:::info

Exchange `<lukso-working-directory>` with the actual folder name of your node setup.

:::

## 2. Install Custom Version

Custom client versions can be installed using the regular installation command with additional flags. The terminal interface will give you the option to choose your execution and consensus client and will download the specified version from the flags. Multiple flags can be attached to install a custom consensus and execution client version simultaneously.

```sh
# Overwrite default Geth Version after Pectra
sudo lukso install --geth-tag 1.15.11 --geth-commit-hash 36b2371c

# Overwrite default Geth Version before Pectra
sudo lukso install --geth-tag 1.14.3 --geth-commit-hash ab48ba42

# Overwrite default Erigon Version
sudo lukso install --erigon-tag 2.52.1

# Overwrite default Besu Version
sudo lukso install --besu-tag 24.5.1

# Overwrite default Nethermind Version
sudo lukso install --nethermind-tag v1.22.0 --nethermind-commit-hash ae444a4

# Overwrite default Prysm Version
sudo lukso install --prysm-tag v4.0.8

# Overwrite default Lighthouse Version
sudo lukso install --lighthouse-tag v4.1.0

# Overwrite default Teku Version
sudo lukso install --teku-tag v23.10.0

# Overwrite default Nimbus-Eth2 Version
sudo lukso install --nimbus2-tag v24.2.1 --nimbus2-commit-hash 7fe43fc
```

:::tip

The **Geth**, **Nethermind**, and **Nimbus-Eth2** clients require an additional commit hash to the release tag, both attached as flags.

:::

:::warning

Each release tag has different version formatting. Ensure you are using the correct format as shown in above examples.

:::

:::info

Version numbers and commit hashes can be derived from the client repositories:

- [Geth Releases](https://github.com/ethereum/go-ethereum/releases)
- [Geth Commit Hashes](https://geth.ethereum.org/downloads)
- [Erigon Releases](https://github.com/ledgerwatch/erigon/releases)
- [Besu Releases](https://github.com/hyperledger/besu/releases)
- [Nethermind Releases](https://github.com/nethermindeth/nethermind/releases)
- [Prysm Releases](https://github.com/prysmaticlabs/prysm/releases)
- [Lighthouse Releases](https://github.com/sigp/lighthouse/releases)
- [Teku Releases](https://github.com/ConsenSys/teku/releases)
- [Nimbus-Eth2 Releases](https://github.com/status-im/nimbus-eth2/releases)

:::

## 3. Restart the Node

Depending on your setup method, there are different ways to start your node after custom versions have been installed.

<Tabs groupId="setup">
  <TabItem value="clinode" label="LUKSO CLI Node" default>

```sh
cd <lukso-working-directory>
lukso start --checkpoint-sync
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder

:::

</TabItem> <TabItem value="clivalidator" label="LUKSO CLI Validator" default>

```sh
cd <lukso-working-directory>
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync
```

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path of the node folder
- `<your-fee-recipient-address>` with the wallet address receiving staking profits

:::

</TabItem> <TabItem value="automation" label="Service Automation">

:::warning

For improved security, the service automation is started from a separate user with restricted rights. New permissions must be assigned to all data and software folders affected by the previous updates before the node should be restarted.

:::

```sh
sudo chown -R lukso-validator-worker:lukso-validator-worker /home/<user-name>/<lukso-working-directory>
sudo chown lukso-validator-worker:lukso-validator-worker /usr/local/bin/lukso
sudo chmod -R 750 /home/<user-name>/<lukso-working-directory>
sudo chmod 755 /home/<user-name>/<lukso-working-directory>
sudo chmod 400 /home/<user-name>/<lukso-working-directory>/static/<your-generic-password-file>
sudo chmod 500 /home/<user-name>/<lukso-working-directory>/static/lukso_startup.sh
```

:::info

The following properties need to be exchanged:

- `<user-name>` with the user name used to login to your node
- `<lukso-working-directory> ` with the path of the node folder
- `<your-generic-password-file>` with the full name of the password file to start the validator

:::

<details>
  <summary>Full Command Descriptions</summary>

| **Setting**                                              | **Description**                                                     |
| -------------------------------------------------------- | ------------------------------------------------------------------- |
| <nobr> `sudo chown -R <user>:<user> <directory>` </nobr> | Recursively assign user ownership to all directory contents.        |
| <nobr> `sudo chown <user>:<user> <directory>` </nobr>    | Assign ownership to a single folder or file.                        |
| <nobr> `sudo chmod -R 750 <directory>` </nobr>           | Set executable and readable permissions for a user and group.       |
| <nobr> `sudo chmod 755 <directory>` </nobr>              | Set readable permissions for everyone, typically for general files. |
| <nobr> `sudo chmod 400 <directory>/<file>` </nobr>       | Read-only access for owner, typically for secret information.       |
| <nobr> `sudo chmod 500 <directory>/<file>` </nobr>       | Executable-only by owner, typically for service scripts.            |

</details>

Once the original rights have been restored, the service can be started.

```sh
sudo systemctl start lukso-validator
```

:::warning

If the service does not start up, check the service status before and reapply the necessary permissions.

:::

```sh
sudo systemctl status lukso-validator
```

</TabItem>
</Tabs>

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

:::warning

If you are still running into issues, [scan for problems](/docs/guides/maintenance/problem-scanning.md) or [update your clients](/docs/guides/maintenance/client-updates.md) and their specific [network configurations](/docs/archive/network/configuration-updates.md).

:::

---

// File: guides/maintenance/switch-clients

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 11.5 Switch Clients

Client diversity refers to the use of multiple independent software implementations across a network, written by different teams and with different coding languages. Through the diverse setup, the network security is improved, and the risk of single points of failure get reduced as errors in a single client do not affect the overall network's security.

:::tip

Further details can be found on the [**Client Diversity**](/docs/theory/blockchain-knowledge/client-diversity.md) page of the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section

:::

:::danger Client Imbalances

The majority of nodes on the LUKSO network [**is running Geth and Prysm**](https://clientdiversity.lukso.network/#distribution) setups. Node operators are responsible to ensure they **split their client usage evenly** across [**officially supported clients**](/docs/theory/blockchain-knowledge/client-providers.md) to improve resilence of the blockchain. If you are in a position to do so, you should adapt your client setup to ensure greater diversity.

:::

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Stop Node Operation

Depending on your setup method, there are different ways to stop your node before applying updates.

<Tabs groupId="setup">
  <TabItem value="cli" label="LUKSO CLI" default>

```sh
cd <lukso-working-directory>
lukso stop
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl stop lukso-validator
```

</TabItem>
</Tabs>

<details>
<summary>Force Client Shutdown</summary>

<Tabs>
<TabItem value="geth" label="Geth">

```sh
sudo pkill geth
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
sudo pkill erigon
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
sudo pkill nethermind
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
sudo pkill besu
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
sudo pkill teku
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
sudo pkill nimbus_beacon_node
sudo pkill nimbus_validator_client
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```sh
sudo pkill lighthouse
```

:::tip

The Lighthouse client uses a single binary for both the consensus and validator processes.

:::

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
sudo pkill prysm
sudo pkill validator
```

</TabItem>
</Tabs>

</details>

## 2. Switch Client Software

Depending on whether you're switching only the execution client or both execution and consensus clients, the process and complexity will vary. While execution clients can be swapped directly within the existing node folder, changing the consensus client requires a full validator reconfiguration and monitoring updates.

| **Type**                               | **Description**                                                                            |
| -------------------------------------- | ------------------------------------------------------------------------------------------ |
| <nobr> Execution Client Only </nobr>   | Replaces client binary and reinitalizes the node folder while keeping the validator setup. |
| <nobr> Execution and Consensus </nobr> | Requires new folder setup, new validator wallet, and firewall reconfiguration.             |

:::info

If you switch the consensus client, you must re-import your _keystore-xxx.json_ key files generated within the [**Validator Setup**](/docs/guides/validator-setup/precautions.md).
Additionally, you also have to update the [**Prometheus Ports**](/docs/guides/monitoring/port-configuration.md), [**Prometheus Service**](/docs/guides/monitoring/prometheus.md), and [**Grafana Dashboard**](/docs/guides/monitoring/dashboard-configuration.md), as the monitoring software will not be able to read from the old consensus ports.

:::

<Tabs groupId="client-type">
  <TabItem value="execution" label="Execution Client Only" default>

**2.1 Navigate into the Node Folder**: _Move into the node's working directory to initialize your node clients._

```sh
cd ./<lukso-working-directory>
```

**2.2 Remove Old State**: _Delete client-specific blockchain state and logs, and re-initialize the folder._

```sh
# Remove Blockchain Data
rm -rf <network>-data

# Remove Logs
rm -rf <network>-logs

# Initialize the Folder
sudo lukso init
```

:::tip

The `lukso init` command only adds missing files within the `/configs/` folder without overwriting existing ones.

:::

**2.3 Install Client**: _Select and install a minority execution client alongside your old consensus client._

```sh
lukso install
```

Check if both clients were installed correctly using their version commands:

<Tabs>
<TabItem value="geth" label="Geth">

```sh
geth --version
```

</TabItem> 
<TabItem value="erigon" label="Erigon">

```sh
erigon --version
```

</TabItem> 
<TabItem value="nethermind" label="Nethermind">

```sh
nethermind --version
```

</TabItem> 
<TabItem value="besu" label="Besu">

```sh
besu --version
```

</TabItem> 
<TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
nimbus_beacon_node --version
```

</TabItem> 
<TabItem value="lighthouse" label="Lighthouse">

```sh
# Consensus Client
lighthouse --version

# Validator Client
lighthouse vc --version
```

</TabItem> 
<TabItem value="teku" label="Teku">

```sh
# Consensus Client
teku --version

# Validator Client
teku validator-client --version
```

</TabItem> 
<TabItem value="prysm" label="Prysm">

```sh
# Consensus Client
prysm --version

# Validator Client
prysm validator --version
```

</TabItem> 
</Tabs>

:::info

If you encounter errors during the download or checkups, re-do the installation process.

:::

</TabItem> <TabItem value="consensus-execution" label="Consensus and Execution Clients">

**2.1 Apply New Firewall Rules**: _Apply the new consensus client's [firewall rules](/docs/guides/client-setup/firewall-settings.md) to your system._

**2.2 Arrange New Router Ports**: _Apply the new consensus client's [port rules](/docs/guides/client-setup/firewall-settings.md) to your router._

**2.3 Fresh Node Setup**: _Redo the [LUKSO CLI Installation](/docs/guides/client-setup/lukso-cli-installation.md) within a new node folder._

**2.4 Add Validator Configuration**: _Redo the [Validator Configuration](/docs/guides/client-setup/validator-configuration.md) to setup the new validator wallet._

**2.5 Arrange New Prometheus Ports**: _Reconfigure the [Prometheus Ports](/docs/guides/monitoring/port-configuration.md) to allow reading consensus data._

**2.6 Update the Prometheus Service**: _Update the [Prometheus Service File](/docs/guides/monitoring/prometheus.md) to dock onto the new consensus port_

**2.7 Update the Grafana Dashboard**: _Import the correct [Grafana Dashboard](/docs/guides/monitoring/dashboard-configuration.md) for your new consensus client._

</TabItem>
</Tabs>

## 3. Apply Client Modifications

In case you did any modifications to your previous client configuration files, please re-apply them to your new client configuration files within the _config_ folder of your node directory before starting up your updated validator node. Modifications may include:

- [Attaching the Node Explorer](https://stats.execution.mainnet.lukso.network/)
- [Configuring a Dynamic DNS](/docs/guides/modifications/dynamic-dns.md)
- [Adding a Node Name or Graffiti](/docs/guides/modifications/custom-node-name.md)
- [Attaching the Public IP](/docs/guides/modifications/public-ip-setup.md)
- [Adjusting Peer Count Limits](/docs/guides/modifications/peer-count-limits.md)
- [Enabling RPC Modules](/docs/guides/maintenance/problem-scanning.md#attach-execution-clients)
- ...

## 4. Restart the Validator

After installing and configuring the new client setup, you can start up the node again.

<Tabs>
<TabItem value="regular-sync" label="Regular Synchronization">

```sh
# Starting the Mainnet Node as Validator
lukso start --validator --transaction-fee-recipient "<transaction-fee-recipient-address>"

# Starting the Testnet Node as Validator
lukso start --validator --transaction-fee-recipient "<transaction-fee-recipient-address>" --testnet
```

:::info

Replace `<transaction-fee-recipient-address>` with your actual withdrawal address.

:::

</TabItem> 
<TabItem value="automated-checkpoints" label="Automated Checkpoints">

```sh
# Starting the Mainnet Node as Validator
lukso start --validator --transaction-fee-recipient "<transaction-fee-recipient-address>" --checkpoint-sync

# Starting the Testnet Node as Validator
lukso start --validator --testnet --transaction-fee-recipient "<transaction-fee-recipient-address>" --checkpoint-sync
```

:::info

Replace `<transaction-fee-recipient-address>` with your actual withdrawal address.

:::

</TabItem> 
<TabItem value="manual-checkpoints" label="Manual Checkpoints">

- Visit the [Mainnet Checkpoint Explorer](https://checkpoints.mainnet.lukso.network/) or [Testnet Checkpoint Explorer](https://checkpoints.testnet.lukso.network/)
- Pass the latest **Block Root** and **Epoch** values to the consensus client flags

<Tabs>
<TabItem value="lighthouse" label="Lighthouse">

```sh
# Starting the Mainnet Node as Validator
lukso start --validator \
  --transaction-fee-recipient "<transaction-fee-recipient-address>" \
  --lighthouse-checkpoint-sync-url=https://checkpoints.mainnet.lukso.network \
  --lighthouse-genesis-state-url=https://checkpoints.mainnet.lukso.network \
  --lighthouse-wss-checkpoint=$<BLOCK_ROOT>:$<EPOCH>

# Starting the Testnet Node as Validator
lukso start --validator --testnet \
  --transaction-fee-recipient "<transaction-fee-recipient-address>" \
  --lighthouse-checkpoint-sync-url=https://checkpoints.testnet.lukso.network \
  --lighthouse-genesis-state-url=https://checkpoints.testnet.lukso.network \
  --lighthouse-wss-checkpoint=$<BLOCK_ROOT>:$<EPOCH>
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
# Starting the Mainnet Node as Validator
lukso start --validator \
  --transaction-fee-recipient "<transaction-fee-recipient-address>" \
  --teku-checkpoint-sync-url=https://checkpoints.mainnet.lukso.network \
  --teku-ws-checkpoint=$<BLOCK_ROOT>:$<EPOCH>

# Starting the Testnet Node as Validator
lukso start --validator --testnet \
  --transaction-fee-recipient "<transaction-fee-recipient-address>" \
  --teku-checkpoint-sync-url=https://checkpoints.testnet.lukso.network \
  --teku-ws-checkpoint=$<BLOCK_ROOT>:$<EPOCH>
```

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
# Starting the Mainnet Node as Validator
lukso start --validator \
  --transaction-fee-recipient "<transaction-fee-recipient-address>" \
  --prysm-checkpoint-sync-url=https://checkpoints.mainnet.lukso.network \
  --prysm-genesis-beacon-api-url=https://checkpoints.mainnet.lukso.network \
  --prysm-weak-subjectivity-checkpoint=$<BLOCK_ROOT>:$<EPOCH>

# Starting the Testnet Node as Validator
lukso start --validator --testnet \
  --transaction-fee-recipient "<transaction-fee-recipient-address>" \
  --prysm-checkpoint-sync-url=https://checkpoints.testnet.lukso.network \
  --prysm-genesis-beacon-api-url=https://checkpoints.testnet.lukso.network \
  --prysm-weak-subjectivity-checkpoint=$<BLOCK_ROOT>:$<EPOCH>
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
# Starting the Mainnet Node as Validator
lukso start --validator \
  --transaction-fee-recipient "<transaction-fee-recipient-address>" \
  --nimbus2-external-beacon-api-url=https://checkpoints.mainnet.lukso.network \
  --nimbus2-trusted-block-root=$<BLOCK_ROOT> \
  --nimbus2-weak-subjectivity-checkpoint=$<BLOCK_ROOT>:$<EPOCH>

# Starting the Testnet Node as Validator
lukso start --validator --testnet \
  --transaction-fee-recipient "<transaction-fee-recipient-address>" \
  --nimbus2-external-beacon-api-url=https://checkpoints.testnet.lukso.network
  --nimbus2-trusted-block-root=$<BLOCK_ROOT> \
  --nimbus2-weak-subjectivity-checkpoint=$<BLOCK_ROOT>:$<EPOCH>
```

</TabItem> 
</Tabs>

:::info

Replace the following parameters of the commands:

- `<BLOCK_ROOT>` and `<EPOCH>` with the current hash and number while keeping the `$` sign.
- `<transaction-fee-recipient-address>` with your actual withdrawal address.

:::

</TabItem> 
</Tabs>

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

## 5. Data Cleanup

After switching clients, unused files and binaries can be removed from the old setup to avoid conflicts and free up storage.

<Tabs groupId="client-type">
  <TabItem value="execution" label="Execution Client Only" default>

**Delete Old Client**: _Remove the unused execution client service from the system._

<Tabs groupId="client">
<TabItem value="geth" label="Geth">

```sh
sudo rm -rf /usr/local/geth
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
sudo rm -rf /usr/local/erigon
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
sudo rm -rf /usr/local/nethermind
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
sudo rm -rf /usr/local/besu
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="consensus-execution" label="Consensus and Execution Clients">

**5.1 Remove Old Firewall Settings**: _Remove the old consensus client's [firewall rules](/docs/guides/client-setup/firewall-settings.md) from your system._

**5.2 Remove Old Router Ports**: _Remove the old consensus client's [port rules](/docs/guides/client-setup/firewall-settings.md) from your router._

**5.3 Delete Old Node Folder**: _Remove the working directory of the previous node setup._

```sh
cd ~
sudo rm -rf <old-lukso-working-directory>
```

:::info

Exchange `<old-lukso-working-directory>` with the path of the previous node folder.

:::

**5.4 Delete Old Clients**: _Remove unused client services from the system._

<Tabs groupId="client">
<TabItem value="geth" label="Geth">

```sh
sudo rm -rf /usr/local/geth
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
sudo rm -rf /usr/local/erigon
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
sudo rm -rf /usr/local/nethermind
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
sudo rm -rf /usr/local/besu
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
sudo rm -rf /usr/local/teku
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
sudo rm -rf /usr/local/nimbus_beacon_node
sudo rm -rf /usr/local/nimbus_validator_client
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```sh
sudo rm -rf /usr/local/lighthouse
```

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
sudo rm -rf /usr/local/prysm
```

</TabItem>
</Tabs>

  </TabItem>
</Tabs>

---

// File: guides/maintenance/gas-price-configuration

# 11.6 Gas Price Configuration

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

Within the network configuration files, validators can adjust the minimum gas price for transactions they accept to propose blocks to the network. The minimum gas price is an **individual client setting**. Validators can choose the value they desire for block approval depending on the current network occupation.

:::warning Balancing Gas Fees

If most of the network accepts transactions with a small gas price, overall fees will remain lower. However, if the gas price is too high, the validator will propose empty blocks without transaction fees. As the network throughput rises, these values should be adjusted.

:::

:::tip Default Gas Price

The gas price mainly causes issues for Geth, as the execution client is using a strict default value that must be overwritten. The [**LUKSO Network Configuration**](https://github.com/lukso-network/network-configs) was recently updated to a base gas price of **0.001 Gwei** for **Geth Execution Clients**. Further details can be found on the [**Configuration Updates**](/docs/archive/network/configuration-updates.md) of the üèõÔ∏è [**Archive**](/docs/archive/network/blockchain-timeline.md) section.

:::

:::info

The following steps are performed on your üìü **node server**.

:::

## Adjusting the Gas Price

If you are running the Geth execution client and experience block reward issues, reduce the minimum accepted gas fee.

:::info

Erigon and Besu clients adjust their minimum gas fee based on the network's gas price dynamically without further redo.

:::

<Tabs>
<TabItem value="cli" label="üëæ LUKSO CLI" default>

**1. Stop Node Operation**: _Depending on your setup method, there are different ways to stop your node to adjust configurations._

<Tabs groupId="setup">
  <TabItem value="cli" label="LUKSO CLI" default>

```sh
cd <lukso-working-directory>
lukso stop
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl stop lukso-validator
```

</TabItem>
</Tabs>

<details>
<summary>Force Client Shutdown</summary>

<Tabs>
<TabItem value="geth" label="Geth">

```sh
sudo pkill geth
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
sudo pkill erigon
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
nethermind --version
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
besu --version
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
sudo pkill teku
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
sudo pkill nimbus_beacon_node
sudo pkill nimbus_validator_client
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```sh
sudo pkill lighthouse
```

:::tip

The Lighthouse client uses a single binary for both the consensus and validator processes.

:::

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
sudo pkill prysm
sudo pkill validator
```

</TabItem>
</Tabs>

</details>

**2. Adjust Gas Price**: _Modify the default network configuration of Geth using your preferred editor._

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>
vim geth/geth.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>
nano geth/geth.toml
```

</TabItem>
</Tabs>

:::info

Exchange `<lukso-working-directory>` and `<network>` with the path of the node folder and the network type.

:::

Change the regular gas price setting to your preferred or the [currently recommended](https://github.com/lukso-network/network-configs/blob/main/mainnet/geth/geth.toml) one.

```text
# Regular Value
GasPrice = 1000000000 # 1 Gwei

# Updated Value
GasPrice = 1000000 # 0.001 Gwei
```

Save the file and exit the editor.

**3. Restart the Node**: _Depending on your setup, there are different ways to start your node with the updated configuration._

<Tabs groupId="setup">
  <TabItem value="clinode" label="LUKSO CLI Node" default>

```sh
cd <lukso-working-directory>
lukso start --checkpoint-sync
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="clivalidator" label="LUKSO CLI Validator" default>

```sh
cd <lukso-working-directory>
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync
```

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path of the node folder
- `<your-fee-recipient-address>` with the wallet address receiving staking profits

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl start lukso-validator
```

</TabItem>
</Tabs>

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

</TabItem>
<TabItem value="dappnode" label="üé® Dappnode">

**1. Stop Node Operation**: Stop the execution and consensus client within the _Node Operation View_.

**2. Navigate to Staker Menu**: Open the _LUKSO Stakers_ menu and move into the _Lukso Geth Package_.

**3. Adjust Gas Price**: Navigate to the _Configs_ window and add the gas price flag in the _EXTRA_OPTS_ field.

```text
  --miner.gasprice 1000000
```

:::info

The above value represents the [currently recommended](https://github.com/lukso-network/network-configs/blob/main/mainnet/geth/geth.toml) gas price of 0.001 Gwei.

:::

**4. Restart the Node**: Restart the execution and consensus client within the _Node Operation View_.

</TabItem>
<TabItem value="docker" label="üê≥ Docker Image">

**1. Stop Node Operation**: Stop the docker containers for both execution and consensus clients.

**2. Adjust Gas Price**: Open the _docker-compose.yml_ file of Geth, adjust the gas price value, and safe the file.

```text
  --miner.gasprice 1000000
```

:::info

The above value represents the [currently recommended](https://github.com/lukso-network/network-configs/blob/main/mainnet/geth/geth.toml) gas price of 0.001 Gwei.

:::

**3. Restart the Node**: Restart the docker containers for execution and consensus clients.

</TabItem>
<TabItem value="custom" label="üóÇÔ∏è Custom Setup">

**1. Stop Node Operation**: _Stop the execution and consensus services._

<Tabs groupId="customization">
  <TabItem value="file" label="File Configuration" default>

**2. Adjust Gas Price**: Adjusting the _geth.toml_ file within your setup using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
vim geth/geth.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
nano geth/geth.toml
```

</TabItem>
</Tabs>

Change the regular gas price setting to your preferred or the [currently recommended](https://github.com/lukso-network/network-configs/blob/main/mainnet/geth/geth.toml) one.

```text
# Regular Value
GasPrice = 1000000000 # 1 Gwei

# Updated Value
GasPrice = 1000000 # 0.001 Gwei
```

Save the file and exit the editor.

**3. Restart the Node**: _Restart the execution and consensus services._

</TabItem> <TabItem value="flag" label="Flag Customization">

**2. Custom Restart**: Restart the Geth service and attach a customization flag for your gasprice setting.

```sh
  --miner.gasprice 1000000
```

</TabItem>
</Tabs>

:::info

The above value represents the [currently recommended](https://github.com/lukso-network/network-configs/blob/main/mainnet/geth/geth.toml) gas price of 0.001 Gwei.

:::

</TabItem>
</Tabs>

---

// File: guides/maintenance/reset-blockchain-state

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 11.7 Reset Blockchain State

When updating or switching execution clients, incompatibilities may arise with the existing blockchain state. These errors often occur due to changes in the client‚Äôs internal database structure, chain data corruption, or leftover logs. Resetting the blockchain state can resolve sync issues, failed starts, and client crashes by reinitializing a clean local environment.

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Stop Node Operation

Depending on your setup method, there are different ways to stop your node before applying updates.

<Tabs groupId="setup">
  <TabItem value="cli" label="LUKSO CLI" default>

```sh
cd <lukso-working-directory>
lukso stop
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl stop lukso-validator
```

</TabItem>
</Tabs>

<details>
<summary>Force Client Shutdown</summary>

<Tabs>
<TabItem value="geth" label="Geth">

```sh
sudo pkill geth
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
sudo pkill erigon
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
sudo pkill nethermind
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
sudo pkill besu
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
sudo pkill teku
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
sudo pkill nimbus_beacon_node
sudo pkill nimbus_validator_client
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```sh
sudo pkill lighthouse
```

:::tip

The Lighthouse client uses a single binary for both the consensus and validator processes.

:::

</TabItem> <TabItem value="prysm" label="Prysm">

```sh
sudo pkill prysm
sudo pkill validator
```

</TabItem>
</Tabs>

</details>

## 2. Remove Blockchain Data

```sh
# Move into Node Directory
cd <lukso-working-directory>

# Remove Blockchain Data
rm -rf <network>-data

# Remove Logs
rm -rf <network>-logs

# Initialize the Folder
sudo lukso init
```

:::tip

The `lukso init` command only adds missing files within the `/configs/` folder without overwriting existing ones.

:::

:::info

Exchange `<lukso-working-directory>` and `<network>` with the path of the node folder and the configured network.

:::

## 3. Restart the Node

Depending on your setup method, there are different ways to start your node after the blockchain state was cleared.

<Tabs groupId="setup">
  <TabItem value="clinode" label="LUKSO CLI Node" default>

```sh
cd <lukso-working-directory>
lukso start --checkpoint-sync
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="clivalidator" label="LUKSO CLI Validator" default>

```sh
cd <lukso-working-directory>
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync
```

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path of the node folder
- `<your-fee-recipient-address>` with the wallet address receiving staking profits

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl start lukso-validator
```

</TabItem>
</Tabs>

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

:::warning

If you are still running into issues, [scan for problems](/docs/guides/maintenance/problem-scanning.md), [update your clients and configuration](/docs/guides/maintenance/client-updates.md), or [revert the client version](/docs/guides/maintenance/revert-client-versions.md).

:::

---

// File: guides/maintenance/monitoring-settings

# 11.8 Monitoring Settings

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

Within the network configuration files, validators can adjust which metrics are exposed to allow more detailed [Grafana Dashboard](/templates) insights. By default, the [LUKSO Network Configuration](https://github.com/lukso-network/network-configs) already exposes [Ports and APIs](/docs/guides/monitoring/port-configuration.md) for every consensus client. Extended access or data can be enabled individually.

:::warning Support

The **Nimbus-Eth2** client is not supported for Staking within the [**LUKSO CLI**](https://github.com/lukso-network/tools-lukso-cli). Additionally, the consensus client requires a custom `--validator-monitor-details` flag to expose regular blockchain metrics. When using the LUKSO CLI, the dashboard will still lack metrics until staking is fully supported.

:::

:::tip

Further details on client versions and support can be found on the [**Client Providers**](/docs/theory/blockchain-knowledge/client-providers.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.
:::

:::info

The following steps are performed on your üìü **node server**.

:::

## Add Validator Metrics

If you are running the Nimbus-Eth2 consensus client and lack dashboard metrics, you can enable advanced validator monitoring.

<Tabs>
<TabItem value="cli" label="üëæ LUKSO CLI" default>

**1. Stop Node Operation**: _Depending on your setup method, there are different ways to stop your node to adjust configurations._

<Tabs groupId="setup">
  <TabItem value="cli" label="LUKSO CLI" default>

```sh
cd <lukso-working-directory>
lukso stop
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl stop lukso-validator
```

</TabItem>
</Tabs>

<details>
<summary>Force Client Shutdown</summary>

<Tabs>
<TabItem value="geth" label="Geth">

```sh
sudo pkill geth
```

</TabItem> <TabItem value="erigon" label="Erigon">

```sh
sudo pkill erigon
```

</TabItem> <TabItem value="nethermind" label="Nethermind">

```sh
nethermind --version
```

</TabItem> <TabItem value="besu" label="Besu">

```sh
besu --version
```

</TabItem> <TabItem value="nimbus2" label="Nimbus-Eth2">

```sh
sudo pkill nimbus_beacon_node
sudo pkill nimbus_validator_client
```

</TabItem>
</Tabs>

</details>

**2. Adjust Validator Metrics**: _Modify the default validator configuration of Nimbus-Eth2 using your preferred editor._

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
cd <lukso-working-directory>/configs/<network>
vim nimbus2/nimbus.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
cd <lukso-working-directory>/configs/<network>
nano nimbus2/nimbus.toml
```

</TabItem>
</Tabs>

:::info

Exchange `<lukso-working-directory>` and `<network>` with the path of the node folder and the network type.

:::

Add the validator monitor details setting to enable extended metrics.

```text
validator-monitor-details = true
```

Save the file and exit the editor.

**3. Restart the Node**: _Depending on your setup, there are different ways to start your node with the updated configuration._

<Tabs groupId="setup">
  <TabItem value="clinode" label="LUKSO CLI Node" default>

```sh
cd <lukso-working-directory>
lukso start --checkpoint-sync
```

:::info

Exchange `<lukso-working-directory>` with the path of the node folder.

:::

</TabItem> <TabItem value="clivalidator" label="LUKSO CLI Validator" default>

```sh
cd <lukso-working-directory>
lukso start --validator --transaction-fee-recipient "<your-fee-recipient-address>" --checkpoint-sync
```

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>` with the path of the node folder
- `<your-fee-recipient-address>` with the wallet address receiving staking profits

:::

</TabItem> <TabItem value="automation" label="Service Automation">

```sh
sudo systemctl start lukso-validator
```

</TabItem>
</Tabs>

After the clients were started, verify that their services are still up.

```sh
sudo lukso status
```

</TabItem>
<TabItem value="docker" label="üê≥ Docker Image">

**1. Stop Node Operation**: Stop the docker containers for both execution and consensus clients.

**2. Adjust Validator Metrics**: Open the _docker-compose.yml_ file of Nimbus-Eth2, add validator monitoring, and safe the file.

```text
  --validator-monitor-details
```

**3. Restart the Node**: Restart the docker containers for execution and consensus clients.

</TabItem>
<TabItem value="custom" label="üóÇÔ∏è Custom Setup">

**1. Stop Node Operation**: _Stop the execution and consensus services._

<Tabs groupId="customization">
  <TabItem value="file" label="File Configuration" default>

**2. Adjust Validator Metrics**: Adjusting the nimbus.toml\_ file within your setup using your preferred text editor.

<Tabs groupId="editor">
  <TabItem value="vim" label="Vim" default>

```sh
vim nimbus2/nimbus.toml
```

</TabItem> <TabItem value="nano" label="Nano">

```sh
nano nimbus2/nimbus.toml
```

</TabItem>
</Tabs>

Add the validator monitor details setting to enable extended metrics.

```text
validator-monitor-details = true
```

Save the file and exit the editor.

**3. Restart the Node**: _Restart the execution and consensus services._

</TabItem> <TabItem value="flag" label="Flag Customization">

**2. Custom Restart**: Restart the service and attach a customization flag for your monitor setting.

```sh
  --validator-monitor-details
```

</TabItem>
</Tabs>

</TabItem>
</Tabs>

---

// File: guides/maintenance/restart-monitoring

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 11.9 Restart Monitoring

Monitoring services collect and display important performance, health, and status metrics of your node. While these services are designed to start automatically with the system, issues like stalled exporters, configuration changes, or failed updates can require a manual restart. Resetting ensures metrics are refreshed, dashboards are populated correctly, and alerts are based on accurate data.

:::info

The following steps are performed on your üìü **node server**.

:::

:::note

Monitoring tools can be restarted while the node is running.

:::

```sh
# Restart System & Hardware Metrics
sudo systemctl restart node_exporter

# Restart LYX Price Metrics
sudo systemctl restart json_exporter

# Restart Ping Metrics
sudo systemctl restart blackbox_exporter

# Restart Node Client Metrics
sudo systemctl restart prometheus

# Restart Grafana Dashboard
sudo systemctl restart grafana-server
```

:::info

Check the monitoring service's status and uptimes.

<Tabs>
<TabItem value="node" label="Node Exporter">

```sh
sudo systemctl status node_exporter
```

</TabItem> <TabItem value="json" label="JSON Exporter">

```sh
sudo systemctl status json_exporter
```

</TabItem> <TabItem value="blackbox" label="Blackbox Exporter">

```sh
sudo systemctl status blackbox_exporter
```

</TabItem> <TabItem value="prometheus" label="Prometheus">

```sh
sudo systemctl status prometheus
```

</TabItem> <TabItem value="grafana" label="Grafana Server">

```sh
sudo systemctl status grafana-server
```

</TabItem>
</Tabs>

:::

:::tip

Further details can be found within the [**Monitoring Tools**](/docs/theory/node-operation/monitoring-tools.md) page in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section or the [**Monitoring Setup**](/docs/guides/monitoring/software-preparation.md).

:::

---

// File: guides/reports/validator-income

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 13.1 Validator Income

Generating accurate income reports can be challenging for LUKSO homestakers. Unlike staking providers, who often supply structured annual summaries, self-hosted validators must track their own consensus rewards and tips. Operators often point to a single withdrawal address. However, this method lacks clarity not supported by most tax systems, as the balance does not distinguish between earned staking income, withdrawals, or regular wallet transactions. While Portfolion Managers like [Rotki](https://rotki.com/) aim to help, they often only support bigger chains, making it hard for smaller networks to obtain reliable data.

The [Validator Income Reporter](https://github.com/fhildeb/validator-income-reporter) is a command-line tool specifically designed to help LUKSO validators generate yearly staking income reports as CSV and PDF files. It uses the [CoinMarketCap API](https://coinmarketcap.com/api/documentation/v1/) to calculate historical fiat value, based on real-time price data for the given year and evaluates all withdrawals and mining rewards for a given address. Additional check ensure that normal transfers or trading activity is excluded.

![Income Reporter Preview](/img/guides/reports/income-reporter.png)

:::tip Features

- ü™ô Collects daily income data from an ETH1 address for any given year
- üí∏ Calculates FIAT revenue based on daily historical coin prices
- üìä Exports collected metrics into a yearly CSV and PDF file

:::

:::info

CoinMarketCap typically offers a free Hobbyist API tier for one month every year, sufficient for annual report generation. If you **dont want to use the CoinMarketCap API**, you can optionally use the `--dry-run` flag to run the reporter **with a local CSV** file of daily median LYX prices. A sample file for EUR is attached to the repository.

:::

:::warning Tax Disclaimer

The tool's outputs should not be considered a substitute for professional advice from a qualified tax advisor, accountant, or lawyer. Users are advised to consult with appropriate professionals before making any decisions based on the data provided by the tool. The developers of this tool shall not be held responsible for any legal or tax-related consequences resulting from using the tool or its outputs, as they make no guarantees or warranties regarding the data's completeness, reliability, or accuracy.

:::

:::info

The following steps are performed on your üíª **personal computer**.

:::

## 1. Install Dependencies

To run the reporting tool, you must install [Python3](https://www.python.org/) on your system.

<Tabs groupId="os">
  <TabItem value="windows" label="Windows" default>

```sh
winget install Python.Python.3
```

</TabItem> <TabItem value="mac" label="Mac">

```sh
# Install Homebrew
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Install Python
brew install python
```

</TabItem>
<TabItem value="linux" label="Linux">

```sh
# Update Package Manager
sudo apt update

# Install Python and necessary Tools
sudo apt install python3 python3-pip python3-venv
```

</TabItem>
</Tabs>

## 2. Download and Setup

First, clone the repository and set up a Python virtual environment to keep dependencies isolated.

<Tabs groupId="os">
  <TabItem value="windows" label="Windows" default>

```sh
# Clone the Repository
git clone https://github.com/fhildeb/validator-income-reporter.git

# Move into Directory
cd validator-income-reporter

# Create a Virtual Python Environment
python -m venv reporter-environment

# Install Necessary Dependencies
pip install requests pandas fpdf
```

</TabItem> <TabItem value="mac-linux" label="Mac and Linux">

```sh
# Clone the Repository
git clone https://github.com/fhildeb/validator-income-reporter.git

# Move into Directory
cd validator-income-reporter

# Create a Virtual Python Environment
python3 -m venv reporter-environment

# Install Necessary Dependencies
pip3 install requests pandas fpdf
```

</TabItem>
</Tabs>

## 3. Configuration

**3.1 API Preparation**: To fetch historical fiat prices, the tool requires you to provide a [CoinMarketCap](https://coinmarketcap.com/api/) API key.

1. Create or log into your [**CoinmarketCap Account**](https://coinmarketcap.com/api/) and open the dashboard.
2. Add your Credentials to apply for a **Hobbist Tier** to fetch historical data.
3. Copy your **CoinmarketCap API** key to your notes for later reference.

**3.2 Create Config File**: Create your personal configuration file based on the default template.

```sh
cp config-sample.py config.py
```

**3.3 Adjust Config File**: Configure your report settings using the provided template.

1. Open the **config.py** file using a text or code editor.
2. Edit the **COINMARKETCAP_API_KEY** to house your copied API key.
3. Set your **ETH1_ADDRESS** and **YEAR** to define your withdrawal address and period.
4. Choose the **COINMARKETCAP_FIAT_ID** based on your native currency.
5. Edit the **COINMARKETCAP_CRYPTO_ID** and chose **LYXe** for pre-2024 or **LYX** for post-2024 reports.
6. Define the **COIN_NAME** and **FIAT_CURRENCY** based on your preferences.
7. Specify the **REPORT_TITLE** to customize your printed PDF.

:::tip

An complete documentation can be found within the [Default Configuration File](https://github.com/fhildeb/validator-income-reporter/blob/main/config-sample.py) of the Repository.

:::

:::info

Great and free examples for code editors are ü¶é [**Notepad++**](https://notepad-plus-plus.org/) or üîπ [**Visual Studio Code**](https://code.visualstudio.com/).

:::

## 4. Generate Report

Once the software has been installed and configured, you can run the report script.

<Tabs groupId="os">
  <TabItem value="windows" label="Windows" default>

<Tabs groupId="prices">
  <TabItem value="api" label="CoinMarketCap API" default>

```sh
# Activate the Virtual Python Environment
source report-environment\Scripts\activate

# Run Income Reporter Script
python income_reporter.py
```

</TabItem> <TabItem value="local" label="Local CSV">

```sh
# Activate the Virtual Python Environment
source report-environment\Scripts\activate

# Run Income Reporter Script
python income_reporter.py --dry-run ./price-data/median_lyx_prices_eur.csv
```

</TabItem>
</Tabs>

</TabItem> <TabItem value="mac-linux" label="Mac and Linux">

<Tabs groupId="prices">
  <TabItem value="api" label="CoinMarketCap API" default>

```sh
# Activate the Virtual Python Environment
source report-environment/bin/activate

# Run Income Reporter Script
python3 income_reporter.py
```

</TabItem> <TabItem value="local" label="Local CSV">

```sh
# Activate the Virtual Python Environment
source report-environment/bin/activate

# Run Income Reporter Script
python3 income_reporter.py --dry-run ./price-data/median_lyx_prices_eur.csv
```

</TabItem>
</Tabs>

</TabItem>
</Tabs>

:::info

The script's run-time will depend on the number of validators. If you have 10 validator keys and generate a report that is one year in the past, the script will need around 18 minutes. Every additional validator will approximately add 90 seconds.

:::

## 5. Exit Report Tool

After the tool finished sucessfully, you will see the generated CSV and PDF files within the folder. They are both called income report and include the year and your address within the file name. After the files have been generated, the virtual environment can be deactivated.

```sh
# Deactivate the Virtual Python Environment
deactivate
```

---

// File: guides/reports/client-logs

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 13.2 Client Logs

Clients automatically generate log files that record important operational data, such as network status, validator events, and errors. While these logs can be accessed directly in the terminal, it can be cumbersome due to the lack advanced search tools, formatting, or the ability to view multiple logs side-by-side. For easier analysis, you can download these log files to your local computer to read them in a styled editor, share them with others for troubleshooting, or archive them for performance tracking.

:::warning

Log files can expose sensitive data. Only share log files with trusted people or modify them before sharing at own risk.

- **Execution Logs**: Expose client name, version, folder path, operator name, and IP or DDNS address.
- **Consensus Logs**: Reveal client name, version, IP, ENRs, and RPC configuration.
- **Validator Logs**: Record validator indices, attestations, proposals, and graffitis.

:::

:::info

The following steps are performed on your üìü **node server**.

:::

## 1. Access Log Folder

Navigate to the node folder of the [LUKSO CLI](https://github.com/lukso-network/tools-lukso-cli) to access client logs.

<Tabs groupId="network-type">
<TabItem value="mainnet" label="Mainnet">

```sh
cd
cd <lukso-working-directory>/mainnet-logs
```

</TabItem>
<TabItem value="testnet" label="Testnet">

```sh
cd
cd <lukso-working-directory>/testnet-logs
```

</TabItem>
</Tabs>

:::info

Exchange `<lukso-working-directory>` with the name of your node folder.

:::

## 2. Copy Log Files

Since log files are typically owned by a specific user and SSH sessions cannot elevate directly to superuser for file transfers, its best to copy the files to a temporary folder where you have full permissions. This ensures the original logs remain untouched and the node does not have to be stopped.

```sh
# Retrieve Current File Path
pwd

# Copy Content to Temporary Folder
sudo cp -r <my-logging-folder> /tmp/client-logs

# Change Permisions to Current Owner
sudo chown -R <user-name>:<user-name> /tmp/client-logs
```

:::info

Within the commands, exchange the following properties:

- `<my-logging-folder>` with the path that was printed from the `pwd` command.
- `<user-name>` with the name of the user you're logging into the node.

:::

## 3. Download Log Files

After the temporary folder was prepared, you can download it to your computer that is used to log into your node using SSH.

:::info

The following step is performed on your üíª **personal computer**.

:::

```sh
scp -r <node-username>@<ssh-device-alias>:/tmp/client-logs ~/Downloads/
```

:::info

Within the command, exchange the following properties:

- `<node-username>` with the name of the user you're logging into the node.
- `<ssh-device-alias>` with the name of the SSH server entry.

:::

:::tip

You can now reference, open, or share all client log files from your default _Downloads_ folder.

:::

## 4. Cleanup

After successfully exporting the logs, remove the temporary folder from your node server to free up disk space and ensure sensitive data is not left accessible.

:::info

The following step is performed on your üìü **node server**.

:::

```sh
rm -rf /tmp/client-logs
```

---

// File: guides/withdrawals/adding-withdrawals

# 12.1 Adding Withdrawals

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

In case you did not attach a [withdrawal address](/docs/theory/node-operation/validator-credentials.md) while [generating your validator keys](/docs/guides/validator-setup/precautions.md), the earnings of your validator will not be paid out to any address and you won't be able to access your staked funds while [exiting your validators](/docs/guides/withdrawals/exit-validators.md) from the network.

The following guide will teach you how to update your plain BLS Validator Key to reference an ETH1 Address, so your validator keys are able to withdraw staked funds and earnings. If an ETH1 Address is referenced to the BLS Key, the validator's stake can be exited to any wallet. Once enabled, all validator earnings above the 32 LYX or LYXt threshold will be periodically withdrawn to your ETH1 Address every few days.

| **Name**                          | **Description**                                                                                                                                           | <nobr> **Network Layer** </nobr> |
| --------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------- |
| <nobr> **BLS Keys** </nobr>       | BLS Keys are the backbone of the digital signature type to secure the EVM blockchain. Every validator uses them to sign blocks and stake on the network.  | <nobr> _Consensus Layer_ </nobr> |
| <nobr> **ETH1 Addresses** </nobr> | ETH1 Addresses are the traditional Ethereum addresses from Externally Owned Accounts, Wallets, or Smart Contracts which can receive funds on the network. | <nobr> _Execution Layer_ </nobr> |

:::info

- The update is only necessary for [**CLI Key Generation**](/docs/guides/validator-setup/cli-key-generation.md) users that did not attach the _eth1_withdrawal_address_ flag.
- The [**Wagyu Key Generation**](/docs/guides/validator-setup/wagyu-key-generation.md) automatically asks for the mandatory withdrawal address during the setup.

:::

:::tip

Further details about withdrawals can be found on the [**Tokenomics**](/docs/theory/blockchain-knowledge/tokenomics.md) and [**Validator Credentials**](/docs/theory/node-operation/validator-credentials.md) pages.

:::

:::note Additional Sources

As LUKSO is an EVM-based blockchain, the withdrawal update is similar to Ethereum. For questions, please refer to:

- [Prysm Withdrawal Guide](https://docs.prylabs.network/docs/wallet/withdraw-validator)
- [Lighthouse Exit Description](https://lighthouse-book.sigmaprime.io/voluntary-exit.html#withdrawal-of-exited-funds)
- [Teku Credential Updates](https://docs.teku.consensys.io/how-to/update-withdrawal-keys)
- [Nimbus-Eth2 Withdrawal Changes](https://nimbus.guide/withdrawals.html)
- [Official ETH2 Book Withdrawal Explanation](https://eth2book.info/capella/part2/deposits-withdrawals/withdrawal-processing/)
- [Official Ethereum Withdrawal FAQ](https://notes.ethereum.org/@launchpad/withdrawals-faq)

:::

## 1. Check Withdrawal Status

If you've never updated your validator withdrawals after the initial deposit, you can check the _deposit_data.json_ file of the validator locally. To check if your withdrawals are executed on the network, you can check them using the consensus explorer.

<Tabs>
  <TabItem value="local-deposit-check" label="Local Deposit File Check">

**1.1 Deposit Lookup**: Open the deposit _json_ file and copy the _pubkey_ element of the validator key.

**1.2 Withdrawal Index**: Search for the _withdrawal_credentials_ properties for every key

    - If the hexadecimal number starts with _01_, withdrawals are **already enabled**
    - If the hexadecimal number starts with _00_, withdrawals **can be set** using this guide

</TabItem>
<TabItem value="consensus-explorer-check" label="Consensus Explorer Check">

**1.1 Deposit Lookup**: Open the deposit _json_ file and copy the _pubkey_ element of the validator key.

**1.2 Consensus Index**: Search for your validator by searching for the public key in the consensus explorer.

    - [LUKSO Mainnet Consensus Explorer](https://explorer.consensus.mainnet.lukso.network/)
    - [LUKSO Testnet Consensus Explorer](https://explorer.consensus.testnet.lukso.network/)

**1.3 Withdrawal Entries**: View the validator‚Äôs details and open the withdrawals section

    - If you see withdrawals, the withdrawal credentials **are working correctly**
    - If the withdrawal section is greyed out, you **can enable them** using this guide

  </TabItem>
</Tabs>

## 2. Prepare Validator Indices

To update your withdrawals, you have to specify the on-chain indices for each of the deposited validator keys. You can get them directly from the node machine or manually check your public keys on the consensus explorer.

<Tabs>
  <TabItem value="index-from-explorer" label="Get Index Numbers from Explorer">

**2.1 Open the Deposit File**: Within the validator's deposit _json_ file, copy the _pubkey_ element of a validator key.

**2.2 Validator Lookup**: Search for your validator by entering its public key into the search bar of the consensus explorer.

- [LUKSO Mainnet Consensus Explorer](https://explorer.consensus.mainnet.lukso.network/)
- [LUKSO Testnet Consensus Explorer](https://explorer.consensus.testnet.lukso.network/)

**2.3 Copy the Index**: Search for the validator index number within the top heading, like _8910_ or _236189_.

:::info

The steps **2.1** to **2.3** need to be repeated for every validator key that is used for staking.

:::

  </TabItem>
  <TabItem value="index-from-node" label="Get Index Numbers from Node">

**2.1 Node Login**: Log into your node‚Äôs terminal using SSH.

**2.2 Enter Log Folder**: Move into the logging folder of the node‚Äôs working directory.

```sh
cd <lukso-working-directory>/<network-type>-logs/
```

**2.3 Search Logs**: Search and print out all validator indices of the active validator.

```sh
cat <latest-validator-logs.log> | grep -o 'index=[0-9]* ' | awk -F'=' '{printf "%s,", $2}' | sed 's/,$//' | tr -d ' '
```

:::info

The following properties need to be exchanged:

- `<lukso-working-directory>`¬†with the actual folder name
- `<network-type>`¬†with¬†`mainnet`¬†or¬†`testnet`
- `<latest-validator-logs.log>` with the **latest** validator log file

:::

  </TabItem>
</Tabs>
 
:::tip

Copy all the validator indices so they can be used to generate the withdrawal credential later on.

:::

## 3. KeyGen CLI Download

:::warning

The LUKSO KeyGen CLI should only be used on a secure offline device.

:::

1. Download the latest version of the [LUKSO KeyGen CLI](https://github.com/lukso-network/tools-key-gen-cli/releases)
2. Transfer the archive to a secure device.
3. Extract the archive to receive the executable binary file
4. Open the terminal and move into the generated folder

## 4. Execute the BLS Change

Start the BLS to Execution process from the LUKSO KeyGen CLI.

```sh
./lukso-key-gen generate-bls-to-execution-change
```

:::info

You will need the following information:

- The **Validator Seed Phrase** from the initial key generation process
- The **Validator Indices** from the keys within the blockchain network
- The old **Withdrawal Credentials** for each deposit key in the deposit file
- The new ETH1 **Withdrawal Address** to receive funds

:::

:::tip

If you want different withdrawal credentials for different keys, the _BLS to Execution Change_ be repeated multiple times.

:::

1. Select your language
2. Select the network which your validators are running on
3. Enter your [Validator Seed Phrase](/docs/theory/node-operation/validator-credentials.md) that you‚Äôve used to generate your initial BSL keys
4. Enter the index position of the keys you want to create withdrawal credentials for
5. Enter all your validator indices to enable withdrawals for, separated with whitespaces or commas
6. Enter a list of the old BLS withdrawal credentials of your validator keys, separated with whitespaces or commas
7. Enter the ETH1 address that all earnings will be withdrawn to
8. The [LUKSO KeyGen CLI](https://github.com/lukso-network/tools-key-gen-cli/releases) will generate a _bls_to_execution_change.json_ file.

:::info

During **Step 4** you must define an index position.

    - To generate the withdrawal update from the `1st` key, set the index position to `0`
    - To generate the withdrawal update for the `11th` key onwards, set the index position to `10`

During **Step 6** and **Step 7** you will have to input hexadecimal values.

    - Ensure to add `0x` in front of the copied withdrawal credential
    - Verify that your EOA withdrawal address has the `0x` prefix

:::

:::warning Error Handling

The [LUKSO KeyGen CLI](https://github.com/lukso-network/tools-key-gen-cli) might show errors about _inputs no being hexadecimal_ or _invalid checksum values_. If the _JSON_ File was generated, such warnings can be ignored. However, please verify you inputs by regenerating the file and comparing the output.

:::

## 5. Credential Broadcast

The withdrawal credential can be shared directly from your node or the public consensus explorer.

<Tabs>
  <TabItem value="broadcast-from-node" label="Broadcast Message from Node" default>

**5.1 Copy File Contents**: Print and copy the contents of the _bls_to_execution_change.json_ file.

```sh
cat bls_to_execution_change.json
```

**5.2 Generate Terminal Command**: Paste the contents into the local broadcast command.

```sh
POST -H "Content-type: application/json" -d  '<file-content>'
```

**5.3 Broadcast Credential**: Log into your node‚Äôs terminal and execute the command to publish the withdrawal credential.

:::warning

Each consensus client with validator support uses a different internal consensus port, opened by the LUKSO CLI.

:::

<Tabs groupId="consensus">
  <TabItem value="prysm" label="Prysm" default>

```sh
curl -X POST -H "Content-type: application/json" -d '<file-content>'
http://localhost:3500/eth/v1/beacon/pool/bls_to_execution_changes
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
curl -X POST -H "Content-type: application/json" -d '<file-content>'
http://localhost:5051/eth/v1/beacon/pool/bls_to_execution_changes
```

</TabItem><TabItem value="lighthouse" label="Lighthouse">

```sh
curl -X POST -H "Content-type: application/json" -d '<file-content>'
http://localhost:5052/eth/v1/beacon/pool/bls_to_execution_changes
```

</TabItem>
</Tabs>

:::info

Exchange `<file-content>` with the actual content of the _bls_to_execution_change.json_ file.

:::

<details>
    <summary>Show Example Broadcast Messages</summary>

<Tabs groupId="consensus">
  <TabItem value="prysm" label="Prysm" default>

```sh
curl -X POST -H ‚ÄúContent-type: application/json‚Äù -d '[{"message": {"validator_index": "7", "from_bls_pubkey": "0x89a6dc1e83570b99cfb2557f01c852ab2bf00957367d0c35a5aa0e3101c9aad33645064e5da8a1efcd5cd501eb123ad0", "to_execution_address": "0x3daee8cd2e3c18dafe13332de33972ac5cf558f3"}, "signature": "0x80e4c40a543ffb99b6fc4b66e0d37726c1739830d27c229091bf8e792ffb98cac0971274bdc815dcba1042e33a4087d809113a0293614f8533f911cb6726c2efb03cf46470bff3ecf00ed962964262470f502208f6cd50e93f56e1b71ee61fa7", "metadata": {"network_name": "lukso", "genesis_validators_root": "0xd7cc24d150c617450dfa8176ef45a01dadb885a75a1a4c32d4a6828f8f088760", "deposit_cli_version": "2.5.6"}}]' http://localhost:3500/eth/v1/beacon/pool/bls_to_execution_changes
```

</TabItem> <TabItem value="teku" label="Teku">

```sh
curl -X POST -H ‚ÄúContent-type: application/json‚Äù -d '[{"message": {"validator_index": "7", "from_bls_pubkey": "0x89a6dc1e83570b99cfb2557f01c852ab2bf00957367d0c35a5aa0e3101c9aad33645064e5da8a1efcd5cd501eb123ad0", "to_execution_address": "0x3daee8cd2e3c18dafe13332de33972ac5cf558f3"}, "signature": "0x80e4c40a543ffb99b6fc4b66e0d37726c1739830d27c229091bf8e792ffb98cac0971274bdc815dcba1042e33a4087d809113a0293614f8533f911cb6726c2efb03cf46470bff3ecf00ed962964262470f502208f6cd50e93f56e1b71ee61fa7", "metadata": {"network_name": "lukso", "genesis_validators_root": "0xd7cc24d150c617450dfa8176ef45a01dadb885a75a1a4c32d4a6828f8f088760", "deposit_cli_version": "2.5.6"}}]' http://localhost:5051/eth/v1/beacon/pool/bls_to_execution_changes
```

</TabItem><TabItem value="lighthouse" label="Lighthouse">

```sh
curl -X POST -H ‚ÄúContent-type: application/json‚Äù -d '[{"message": {"validator_index": "7", "from_bls_pubkey": "0x89a6dc1e83570b99cfb2557f01c852ab2bf00957367d0c35a5aa0e3101c9aad33645064e5da8a1efcd5cd501eb123ad0", "to_execution_address": "0x3daee8cd2e3c18dafe13332de33972ac5cf558f3"}, "signature": "0x80e4c40a543ffb99b6fc4b66e0d37726c1739830d27c229091bf8e792ffb98cac0971274bdc815dcba1042e33a4087d809113a0293614f8533f911cb6726c2efb03cf46470bff3ecf00ed962964262470f502208f6cd50e93f56e1b71ee61fa7", "metadata": {"network_name": "lukso", "genesis_validators_root": "0xd7cc24d150c617450dfa8176ef45a01dadb885a75a1a4c32d4a6828f8f088760", "deposit_cli_version": "2.5.6"}}]' http://localhost:5052/eth/v1/beacon/pool/bls_to_execution_changes
```

</TabItem>
</Tabs>

</details>

</TabItem> <TabItem value="broadcast-from-explorer" label="Broadcast Message from Explorer">

**5.1. Open Consensus Explorer**: Open the broadcast tool of the consensus explorer.

- [LUKSO Mainnet Consensus Explorer Broadcast Tool](https://explorer.consensus.mainnet.lukso.network/tools/broadcast)
- [LUKSO Testnet Consensus Explorer Broadcast Tool](https://explorer.consensus.testnet.lukso.network/tools/broadcast)

**5.2 Upload Credential**: Upload the _bls_to_execution_change.json_ file to the server.

**5.3 Broadcast Credential**: Click _Submit & Broadcast_ to publish the withdrawal credential.

  </TabItem>
</Tabs>

## 6. Check Update Progress

:::tip

A maximum of 16 validator updates can be included per block. It might take several hours until the withdrawal went live.

:::

**6.1 Open Consensus Explorer**: Open the validator withdrawal page.

    - [LUKSO Mainnet Validator Withdrawals](https://explorer.consensus.mainnet.lukso.network/validators/withdrawals)
    - [LUKSO Testnet Validator Withdrawals](https://explorer.consensus.testnet.lukso.network/validators/withdrawals)

**6.2 Search Address Changes**: Scroll down to the list of recent _Address Changes_ that happend on the network.

**6.3 Verify Index Numbers**: Your Validator indices should show up as soon as the update went live.

:::info

If the withdrawal update hasn't shown up after several hours, consider resubmitting the file or using the terminal command.

:::

---

// File: guides/withdrawals/exit-validators

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# 12.2 Exit Validators

If you no longer want to be part of the blockchain and decide to take the node offline, you can withdraw your stake. To fully exit the validator keys, you must have a withdrawal address set, to which the staking income is transfered over. Depending on your node setup, there are multiple ways to withdraw your funds.

| Setup                                                                                                                                                                                        | Difficulty                 | Description                                                                                                            | Links                                                                                                                                                                                                                                                                                                                                                  |
| -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------- | ---------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| <nobr> üé® [**DAppNode**](https://dappnode.com) </nobr>                                                                                                                                       | <nobr> üü¢ Simple </nobr>   | Exit the validators directly from the central [StakingBrain](https://github.com/dappnode/StakingBrain) User Interface. | <nobr> **‚Üí** [Exit Dappnode Validators](https://discourse.dappnode.io/t/how-to-exit-your-validator-from-the-ui/1745) </nobr>                                                                                                                                                                                                                           |
| <nobr> üëæ [**LUKSO CLI**](https://github.com/lukso-network/tools-lukso-cli) </nobr>                                                                                                          | <nobr> üü¢ Simple </nobr>   | Exit the validators using the unified _lukso validator exit_ command.                                                  | <nobr> **‚Üí** [Lukso Validator Exit](https://github.com/lukso-network/tools-lukso-cli?tab=readme-ov-file#validator-exit) </nobr>                                                                                                                                                                                                                        |
| <nobr> üê≥ [**Docker**](https://github.com/lukso-network/network-docker-containers) / üóÇÔ∏è [**Custom**](https://docs.lukso.tech/networks/mainnet/running-a-node#-with-your-own-clients) </nobr> | <nobr> üîµ Advanced </nobr> | Exit the validators through the consensus client's wallet directly.                                                    | <nobr> **‚Üí** [Prysm Validator Exit Documentation](https://docs.prylabs.network/docs/wallet/exiting-a-validator)</nobr> <br /> <nobr> **‚Üí** [Lighthouse Withdrawal Guide](https://lighthouse-book.sigmaprime.io/voluntary-exit.html) </nobr> <br /> <nobr> **‚Üí** [Exit Teku Validators](https://docs.teku.consensys.io/how-to/voluntarily-exit) </nobr> |

:::warning

If you want to check or set the **required withdrawal address**, refer to the [**Adding Withdrawals**](/docs/guides/withdrawals/adding-withdrawals.md) guide before continuing.

:::

## 1. LUKSO CLI Withdrawal

Ensure you have the latest [LUKSO CLI](https://github.com/lukso-network/tools-lukso-cli) and [supported clients](/docs/guides/maintenance/client-updates.md) installed to guarantee compatibility. After your validator node is updated and synchronized with the network, start the exit process using the following command.

<Tabs>
  <TabItem value="prysm" label="Prysm or Teku" default>

```sh
# Start Mainnet Exit
sudo lukso validator exit

# Start Testnet Exit
sudo lukso validator exit --testnet
```

</TabItem> <TabItem value="lighthouse" label="Lighthouse">

```sh
# Start Mainnet Exit
sudo lukso validator exit --keystore "./mainnet-keystore/keystore-xxx.json"

# Start Testnet Exit
sudo lukso validator exit --testnet --keystore "./testnet-keystore/keystore-xxx.json"

```

</TabItem>
</Tabs>

The exit setup will be different depending on your consensus client. Within [Prysm](https://docs.prylabs.network/docs/getting-started) or [Teku](https://consensys.io/teku), you can either select all or a specific number of validators by navigating the terminal interface and selecting the public keys. For [Lighthouse](https://lighthouse-book.sigmaprime.io/intro.html), you can only exit one validator at the time.

:::note

You can use `Ctrl+C` to stop the exit process at any time.

:::

:::tip

If you want to exit specific validators, you can learn how to receive the validator indices on the [Adding Withdrawals](/docs/guides/withdrawals/adding-withdrawals.md#2-prepare-validator-indices) page.

:::

:::info

After the command was completed, the _validator exit credential_ is submitted to the blockchain without interruption.

:::

## 2. Check Withdrawal Status

:::tip

A maximum of 16 validator updates can be included per block. It might take several hours until the exit went live.

:::

**2.1 Open Consensus Explorer**: Open the Validator withdrawal page of the consensus explorer.

- [LUKSO Mainnet Validator withdrawals](https://explorer.consensus.mainnet.lukso.network/validators/withdrawals)
- [LUKSO Testnet Validator withdrawals](https://explorer.consensus.testnet.lukso.network/validators/withdrawals)

**2.2 Search Validator**: Input your validator's public key or index as described on the [Adding Withdrawals](/docs/guides/withdrawals/adding-withdrawals.md) page.

**2.3 Fetch Exit Time**: If the exit has been successfully submitted, the page will show an estimated exit time.

:::info

If the estemated exit time hasn't shown up after several hours, consider repeating the exit command in the terminal.

:::

:::warning

Ensure your node stays running until withdrawals were received to gain rewards without being penalized.

:::

---

// File: theory/preparations/node-specifications

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Node Specifications

Running a Ethereum node is not a one‚Äësize‚Äëfits‚Äëall affair. Hardware needs grow with the amount of historical data you keep‚ÄØand the additional services you plan to enable. The following table shows the typical node setups.

| Node Type                                 | Description                                                               |
| ----------------------------------------- | ------------------------------------------------------------------------- |
| <nobr> **Light Node** </nobr>             | Downloads block headers and verifies minimal parts of the chain.          |
| <nobr> **Full Node** </nobr>              | Keeps recent state only and prunes old data once hash tree is verifiable. |
| <nobr> **Node‚ÄØ+‚ÄØSlasher Service** </nobr> | Runs a proof‚Äëof‚Äëstake slasher service to the regular node services.       |
| <nobr> **Archive Node** </nobr>           | Stores all historical state ideal for explorers, research & analytics.    |

:::tip

Further details about node variations can be found on the [**Client Types**](/docs/theory/blockchain-knowledge/client-types.md) and [**Client Providers**](/docs/theory/blockchain-knowledge/client-providers.md) pages.

:::

## Hardware Requirements

Meeting or exceeding the hardware specs below keeps your specific node type synced, healthy and penalty‚Äëfree.

:::note Classification

- **Minimal**: Your node will synchronize but may lag under load or when synchronizing to the current chain head.
- **Recommended**: Smooth performance during synchronization with headroom for storage, metrics, and monitoring.

:::

<Tabs>
<TabItem value="minimal" label="Minimal">

| Node Type                                 | CPU     | RAM   | Storage | Network   | Typical Execution Clients              | [CLI Support](https://github.com/lukso-network/tools-lukso-cli) |
| ----------------------------------------- | ------- | ----- | ------- | --------- | -------------------------------------- | --------------------------------------------------------------- |
| <nobr> **Light Node** </nobr>             | 2‚ÄØCores | 2‚ÄØGB  | 2‚ÄØGB    | ‚â•‚ÄØ5‚ÄØMbps  | [Helios], [Nimbus-Eth2], [Lodestar]    | ‚ùå No                                                           |
| <nobr> **Full Node** </nobr>              | 4 Cores | 8‚ÄØGB  | 500‚ÄØGB  | ‚â•‚ÄØ25‚ÄØMbps | [Geth], [Erigon], [Nethermind], [Besu] | ‚úÖ Yes                                                          |
| <nobr> **Node‚ÄØ+‚ÄØSlasher Service** </nobr> | 6 Cores | 16‚ÄØGB | 1‚ÄØTB    | ‚â•‚ÄØ50‚ÄØMbps | [Geth], [Erigon], [Nethermind], [Besu] | ‚úÖ Yes                                                          |
| <nobr> **Archive Node** </nobr>           | 8 Cores | 16‚ÄØGB | 2 TB    | ‚â•‚ÄØ50‚ÄØMbps | [Erigon], [Besu]                       | ‚úÖ Yes                                                          |

</TabItem>

<TabItem value="recommended" label="Recommended">

| Node Type                                 | CPU           | RAM   | Storage   | Network   | Typical Execution Clients              | [CLI Support](https://github.com/lukso-network/tools-lukso-cli) |
| ----------------------------------------- | ------------- | ----- | --------- | --------- | -------------------------------------- | --------------------------------------------------------------- |
| <nobr> **Light Node** </nobr>             | 2‚ÄØ‚Äì‚ÄØ4‚ÄØCores   | 4‚ÄØGB  | 5‚ÄØ‚Äì‚ÄØ10‚ÄØGB | ‚â•‚ÄØ10‚ÄØMbps | [Helios], [Nimbus-Eth2], [Lodestar]    | ‚ùå No                                                           |
| <nobr> **Full Node** </nobr>              | 6‚ÄØ‚Äì‚ÄØ8 Cores   | 16‚ÄØGB | 1 - 2‚ÄØTB  | ‚â•‚ÄØ25‚ÄØMbps | [Geth], [Erigon], [Nethermind], [Besu] | ‚úÖ Yes                                                          |
| <nobr> **Node‚ÄØ+‚ÄØSlasher Service** </nobr> | 8‚ÄØ- 10 Cores  | 32‚ÄØGB | 2 - 4‚ÄØTB‚ÄØ | ‚â•‚ÄØ50‚ÄØMbps | [Geth], [Erigon], [Nethermind], [Besu] | ‚úÖ Yes                                                          |
| <nobr> **Archive Node** </nobr>           | 12‚ÄØ‚Äì‚ÄØ16 Cores | 32‚ÄØGB | 4 - 6‚ÄØTB  | ‚â•‚ÄØ50‚ÄØMbps | [Erigon], [Besu]                       | ‚úÖ Yes                                                          |

</TabItem>
</Tabs>

:::info SSD vs HDD Storage

A modern node performs millions of tiny random reads and writes every hour. Modern _NVMe_ or _SATA‚ÄØSSD_ drives are strongly recommended and deliver high access rates and low seek times that keep your execution client at the chain head. In comparison, traditional spinning‚Äëdisk _HDDs_ are houndred times slower for random access, and should only be used when

- you operate an **offline analytics node** that doesn‚Äôt need real‚Äëtime block execution
- you‚Äôre running a **minimal learning node** with higher synchronization times and frequent lags
- you're running an **archive node** with an SSD and want to extend the storage for historical data

:::

:::tip Network Connection

If you're staking with a validator, operating for the consensus network requires great network bandwidth and low latency to receive blocks information and attest them before the deadline. High latency leads to missed attestations, orphaned blocks, and potential penalties. More details can be found on the [**Router Requirements**](/docs/theory/preparations/router-requirements.md) and [**Network Demand**](/docs/theory/preparations/network-demand.md) pages.

:::

:::warning Consequences of under‚Äëpowered Hardware

- **Falling Behind Chain Head**: Slow processors or storage can‚Äôt process blocks quickly enough, leading to lags.
- **Consensus Penalties**: Missed validator duties from lags or crashes cause validator inactivity or even slashing.
- **Downtime**: Operation systems kill resource‚Äëstarved software, meaning clients, tools, or metrics stop responding.
- **Corrupted Data**: Hitting a disk‚Äëspace wall forces an emergency resynchronization, taking the node offline.
- **Resource Conflicts**: All clients and services fight for the same RAM and disk reads, cascading slow‚Äëdowns.
- **Security Risks**: Overloaded nodes may skip signature verification or leave vulnerable endpoints exposed.
  :::

## Slasher Requirements

The slasher tracks validator attestations to detect misbehaviour on the network. Its computational needs, especially memory and disk usage are significantly higher. Slasher services are recommended for advanced rigs, staking pools, or data‚Äëcenters, likely meeting the official requirements within the [Prysm], [Lighthouse], or [Teku] consensus clients.

:::tip

Further details about the slasher functionality can be found on the [**Slasher Service**](/docs/theory/node-operation/slasher-service.md) page.

:::

| Resource | Baseline                                      |
| -------- | --------------------------------------------- |
| CPU      | _Intel¬†Core¬†i7‚Äë4770_,‚ÄØ*AMD¬†FX‚Äë8310*, or newer |
| RAM      | 16 - 32‚ÄØGB                                    |
| Storage  | 1‚ÄØ- 4 TB SSD                                  |
| Network  | Reliable broadband with low latency           |

:::info Storage Growth

The **Slasher DB** could potentially expand from **0‚ÄØ‚Üí‚ÄØ200‚ÄØGB in one year**. Plan for continuous growth or a separate SSD drive.

:::

:::warning Consequences of Under‚Äëpowered Slasher

- **Delayed Detection**: Lagging behind the chain head means slashable events are missed, making the slasher node useless.
- **Cascading Crashes**: The slasher can starve the beacon or validator client of resources, meaning the node stops working.
- **Higher Penalty Risk**: Instability may cause your own validators to be penalised from other slashers.

:::

## Storage Demand

Since the [LUKSO Mainnet Launch](https://medium.com/lukso/genesis-validators-start-your-clients-fe01db8f3fba), the blockchain data has increased on a rather static level.

:::info Current DISK USAGE

As of **May 2025** fully synchronized **LUKSO Mainnet Full Node** occupies **‚âà‚ÄØ62‚ÄØGB** of data, and **‚âà‚ÄØ40‚ÄØGB** of slasher database.

:::

:::tip

An extended analysis and comparison of storage usage across execution clients can be found on the [**Client Providers**](/docs/theory/blockchain-knowledge/client-providers.md) page.

:::

| Network     | **Monthly** Growth | **Yearly** Growth | **Monthly** Slasher Growth | **Yearly** Slasher Growth | Genesis     |
| ----------- | ------------------ | ----------------- | -------------------------- | ------------------------- | ----------- |
| **Mainnet** | ~ 2.6‚ÄØGB           | ~ 31‚ÄØGB           | ~ 2‚ÄØGB                     | ~ 20‚ÄØGB                   | May‚ÄØ23‚ÄØ2023 |
| **Testnet** | ~ 0.3‚ÄØGB           | ~ 3.7‚ÄØGB          | ~ 0.2‚ÄØGB                   | ~ 2‚ÄØGB                    | May‚ÄØ03‚ÄØ2023 |

:::note Disclaimer

The above data was gathered from [Geth](/docs/theory/blockchain-knowledge/client-providers.md) and [Prysm](/docs/theory/blockchain-knowledge/client-providers.md) clients with an active [slasher service](/docs/theory/node-operation/slasher-service.md) without any data compromization since genesis. The storage numbers might vary based on other client providers and the total runtime of the slasher service.

:::

[Helios]: https://github.com/a16z/helios
[Lodestar]: https://chainsafe.github.io/lodestar/
[Geth]: https://geth.ethereum.org/docs/getting-started/hardware-requirements
[Erigon]: https://docs.erigon.tech/getting-started/hw-requirements
[Nethermind]: https://docs.nethermind.io/get-started/system-requirements/
[Besu]: https://besu.hyperledger.org/24.3.0/public-networks/get-started/system-requirements
[Prysm]: https://docs.prylabs.network/docs/prysm-usage/slasher
[Lighthouse]: https://lighthouse-book.sigmaprime.io/installation.html#recommended-hardware
[Teku]: https://docs.teku.consensys.io/development/get-started/system-requirements
[Nimbus-Eth2]: https://nimbus.guide/hardware.html

---

// File: theory/preparations/router-requirements

# Router Requirements

The router is the first, and often weakest, part when it comes to data exchange of blockchain nodes. Inadequate routers will drop packets, choke under high peer counts, or stall your synchronization while putting validators at risk.

:::danger ISP Router Issues

All‚Äëin‚Äëone routers from internet service providers are tuned for casual home use, **not for high‚Äëconnection workload** of a blockchain node. Even with correct port‚Äëforwarding, they will likely suffer heavy packet loss, drastic bandwidth drops, or complete lock‚Äëups of your home network's internet when peer traffic surges. Upgrading to a business or professional home router usually eliminates these issues.

:::

| Capability                                   | Why it matters                                                                                   | What to look for                                                                       |
| -------------------------------------------- | ------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------- |
| <nobr>**Throughput & Stability** </nobr>     | Sustained, symmetric bandwidth keeps dozens of peer connections flowing without stalls.          | Routing throughput of 1 Gigabit per second with stability for‚ÄØ10k concurrent sessions. |
| <nobr>**Quality of Service** </nobr>         | Lets you prioritise node traffic over bulk downloads or streaming, avoiding missed attestations. | Priority rules for devices and ports plus DiffServ and CoS support.                    |
| <nobr>**Port Forwarding & Firewall** </nobr> | Nodes must expose TCP or UDP listener ports and validators need inbound traffic.                 | Simple access to map ports and create stateful rules.                                  |
| <nobr>**Gigabit Ethernet** </nobr>           | Wired LAN removes Wi‚ÄëFi bottlenecks and fibre SFP slots will allow future‚Äëproof upgrades.        | RJ‚Äë45 ports with more than 1 Gigabit throughput and optional fibre SFP slots.          |
| <nobr>**IPv6** </nobr>                       | Many peers advertise only v6 addresses. Dual‚Äëstack ensures full reachability.                    | Native dual‚Äëstack with dynamic‚Äëprefix delegation.                                      |
| <nobr>**VPN Server & Client** </nobr>        | Lets you secure RPC or monitoring ports, or tunnel through restrictive ISPs.                     | WireGuard or OpenVPN clients built‚Äëin or ready to install via firmware.                |
| <nobr>**Dynamic DNS** </nobr>                | Publishes a stable hostname even when your IP changes, so peers & remote tools can reconnect.    | Built‚Äëin DDNS client that supports multiple providers or custom webhooks.              |
| <nobr>**Regular Firmware Updates** </nobr>   | Patch vulnerabilities and add protocol support                                                   | Vendor that publishes quarterly updates and offers long‚Äëterm firmware availability.    |

:::tip Priority

`Reliable Throughput` > `Flexible Port and Network Controls` > `Ongoing Firmware Support`.

:::

:::note Example Hardware

For central europe, [**üß≠ AVM**](https://fritz.com/) ranks high for build quality, intuitive UI, long warranty, and frequent updates. Their higher‚Äëend models add fibre and Wi‚ÄëFi¬†mesh support for greater connectivity, and even offer an integrated [**Dynamic DNS**](/docs/theory/node-operation/dynamic-dns.md) service.

Within the [**Router Setup**](/docs/guides/router-setup/static-ip-assignment), all configurations were done on a [**Fritz!Box¬†7590¬†AX**](https://en.fritz.com/products/fritzbox/fritzbox-7590-ax/).

:::

---

// File: theory/preparations/network-demand

# Network Demand

Running a validator or full node is as much a network exercise as a compute one. Blocks, attestations, and peer gossip is shared around the clock. If data packages arrive late or not at all, your node lags behind, drops out of synchronization, or becomes penalised.‚ÄØThis page breaks down the bandwidth, latency, and connection‚Äëquality targets you should hit before spinning up a node.

## Ethernet Connection

Using a wired Ethernet connection is the gold standard for any node operation.

| Benefit                            | Description                                                                               | Node Impact                                                                            |
| ---------------------------------- | ----------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- |
| <nobr> **Stability** </nobr>       | The data connection is immune to interference from walls, microwaves, or neighbours.      | Fewer disconnects and a steady peer count to other nodes participating in the network. |
| <nobr> **Speed** </nobr>           | The troughput of 1 gigabit or higher outperforms typical Wi‚ÄëFi connections.               | Faster initial synchronization and smoother catch‚Äëup after outages.                    |
| <nobr> **Great Latency** </nobr>   | As there is no airtime contention, the wired connection offers low and constant latency.  | Attestations and block proposals always reach other peers of the network in time.      |
| <nobr> **Security** </nobr>        | As the connection requires physical access, mobile devices cannot intercept or interfere. | Reduced risk of over‚Äëthe‚Äëair snooping or network attacks from third parties.           |
| <nobr> **Troubleshooting** </nobr> | As all packages are directed at one device, troubleshooting becomes predictable.          | Less effort and speculation when detecting package loss issues and latency drops.      |

:::tip Security Advice

Always connect via **Ethernet** and **turn off** air-based connections like **Wi‚ÄëFi and Bluetooth** on the node‚Äôs network interface.

:::

## Bandwidth Requirements

If you are considering running a node, the following values are the minimum troughput and latency you should keep.

| Metric                            | Minimum      | Recommendation | Why it matters                                                         |
| --------------------------------- | ------------ | -------------- | ---------------------------------------------------------------------- |
| <nobr> **Download** </nobr>       | 10‚ÄØ‚Äì‚ÄØ15‚ÄØMbps | above‚ÄØ50‚ÄØMbps  | Faster initial synchronization and head‚Äëof‚Äëchain catch‚Äëup.             |
| <nobr> **Upload** </nobr>         | 2‚ÄØ‚Äì‚ÄØ4‚ÄØMbps   | above‚ÄØ20‚ÄØMbps  | Sending attestations, block proposals, and peer requests in time.      |
| <nobr> **Latency / Ping** </nobr> | under‚ÄØ100‚ÄØms | under‚ÄØ30‚ÄØms    | Attestations close after‚ÄØ12‚ÄØseconds and every ms counts for inclusion. |
| <nobr> **Package Loss** </nobr>   | under‚ÄØ1‚ÄØ%    | under‚ÄØ0.1‚ÄØ%    | Steady peer gossip & fewer retransmissions.                            |

:::info Connection Tests

If you are unsure if the internet connection is stable and strong enough to power a node, consider running a 24‚Äëhour ping and bandwidth **monitoring service** or look-up your **router's network analytics**. If you‚Äôre consistently below the recommended bandwith and latency, consider upgrading to fibre connection, hosting your node in a data centre, or using an third party staking service.

:::

## Network Traffic Volumes

Bandwidth analysis within the [LUKSO Validator Community](https://discord.gg/lukso) have shown incoming and outgoing data package throughputs. These numbers correlate to the **default peer settings** within the [LUKSO Network Configuration](https://github.com/lukso-network/network-configs) and should be considered the minimum required capacity to keep the topography of the network and the peer count stable.

:::tip

The amount of **uploaded data** that is exchanged can be lowered or raised by adjusting the [**Peer Count Limits**](/docs/guides/modifications/peer-count-limits.md), useful when having connectivity issues, or running an **advanced node setup** as archive node, data center, or bootnode.

:::

| Interval    | Uploaded Data | Downloaded Data | **Total Throughput** |
| ----------- | ------------- | --------------- | -------------------- |
| **Daily**   | ~45‚ÄØGB        | ~43‚ÄØGB          | ~88‚ÄØGB               |
| **Weekly**  | ~330‚ÄØGB       | ~300‚ÄØGB         | ~630‚ÄØGB              |
| **Monthly** | ~1.4‚ÄØTB       | ~1.33‚ÄØTB        | ~2.73‚ÄØTB             |

:::info

Archive nodes transfer similar volumes but **store** far more because they keep **every historical state**.
:::

:::danger ISP Policy Issues

Many residential internet service providers impose fair‚Äëuse **throughput limits** between **1 to 3‚ÄØTB per‚ÄØmonth**. A single validator node can exceed this limit. Check your internet contract or upgrade to a _business_ or _unlimited_ plan to avoid throttling or retrospective payments.

:::

## Possible Network Issues

A stable, low‚Äëlatency connection is considered mandatory for any node operation. If you are unable to comply with network requirements, the following restrictions might apply.

:::warning Consequences of Network Issues

- **Delayed Block Sync**: Slow downloads delay the execution of new data payloads and blockchain synchonization.
- **Ignored Attestations**: Validators must reach their peers within the slot time to exclude low inactivity flags.
- **Missed Proposals**: Block rewards drop to zero if peer connections time‚Äëout, meaning another validator has to sign.
- **Validator Penalties**: An extended desynchronization time will cause panelties and reduce your staked funds.

:::

---

// File: theory/blockchain-knowledge/proof-of-stake

# Proof‚ÄØof‚ÄØStake

Proof‚ÄØof‚ÄØStake is the consensus algorithm that secures modern EVM‚Äëbased networks such as **Ethereum** and **LUKSO**. Validators stake coins, propose blocks of gathered transactions, and vote on the chain‚Äôs head via block attestations. The more cryptocurrency a person puts at risk, the higher the chances of being selected. Honest behaviour is rewarded through transaction fees. Faults or attacks are punished by removing a slice of the stake through panalizing or slashing the validators.

## Consensus Effects

Unlike Proof of Work on Bitcoin or previous generations of Ethereum, requiring miners to solve complex mathematical problems to add new blocks to the blockchain, Proof of Stake relies on the amount of cryptocurrency a person is willing to risk as collateral.

:::tip Advantages

- **Energy Efficiency**: Staking cuts power use by‚ÄØmore than 99 % in comparison to Proof of Work.
- **Economical Security**: Attacking the chain requires buying and risking large amounts of the native coin.
- **Deterministic Rewards**: Performance maps directly to APR; there is no luck factor like block‚Äëfinding races.
- **Strict Uptime**: Validators target‚ÄØ‚â•‚ÄØ98‚ÄØ% online time to avoid leaks within randomized epochs.

:::

:::warning Disadvantages

- **Early Centralisation Risk**: Stake often concentrates among a few early adopters and diversity must grows over time.
- **Additional Stake Vectors**: As forking is cheap, protocols need slashing and finality rules to prevent riskless attestations.
- **Operational Complexity**: Running two client layers and maintaining keys client and operational overhead.

:::

## Roles and Services

Running a validator can be thought of as providing infrastructure in exchange for protocol‚Äëlevel rewards.‚ÄØTo participate you deposit the network‚Äôs native token of 32‚ÄØLYX or LYXt into a one‚Äëway validator key and spin up the following software. Stake can only be [withdrawn](/docs/theory/node-operation/validator-credentials.md) once the [validator exists](/docs/guides/withdrawals/exit-validators.md) the network.

| Layer                 | Network Role                                                                       |
| --------------------- | ---------------------------------------------------------------------------------- |
| **Execution Client**  | Processes transactions and maintains the EVM state database.                       |
| **Consensus Client**  | Follows the beacon chain, selects proposers, aggregates attestations.              |
| **Validator Process** | Signs block proposals & attestations using your private keys.                      |
| **Slasher Service**   | Detects and reports double‚Äësigning or surround‚Äëvotes to maximise network security. |

## Network Lifecycle

The order of steps below summarises what happens every slot and epoch.

| #   | Stage                                  | Description                                                                                  |
| --- | -------------------------------------- | -------------------------------------------------------------------------------------------- |
| 1   | <nobr> **Providing Stake** </nobr>     | Coins are locked and each validator key joins the active set of stakers.                     |
| 2   | <nobr> **Proposing Blocks** </nobr>    | One validator is pseudo‚Äërandomly chosen each slot to build and submit a block.               |
| 3   | <nobr> **Attesting Blocks** </nobr>    | All other active validators vote on the head block and chain state.                          |
| 4   | <nobr> **Reaching Finality** </nobr>   | Once two thirds of total stake attests over two consecutive epochs, blocks become immutable. |
| 5   | <nobr> **Applying Incentives** </nobr> | Proposals and attestations earn funds while downtime or malicious acts reduce balance.       |

:::tip

Further details can be found on the [**Tokenomics**](/docs/theory/blockchain-knowledge/tokenomics.md) or [**Shashing and Panelties**](/docs/theory/blockchain-knowledge/slashing-and-panelties.md) pages.

:::

## Participation Rate

In Proof of Stake consensus, at least two-thirds of the total active validator stake must be online and actively participating for the chain to finalize blocks. If participation drops below this threshold, the network may fail to reach finality, causing stalls and potentially requiring manual intervention.

Network stalls can occur due to:

- A large number of validators going offline at the same time.
- Network partitions or infrastructure issues.
- Improper client configurations, bugs, or version mismatches.

:::tip

Keeping participation high ensures stable finality and robust network health. Redundant infrastructure is critical for minimizing correlated failures. Further information about network resilience can be found on the [**Client Diversity**](/docs/theory/blockchain-knowledge/client-diversity.md) page.

:::

## Node Operations

Each operation in the EVM requires a certain amount of gas, which is paid for in the blockchain's coin. The cost of gas is a crucial part of Ethereum's incentive structure, discouraging spam on the network and incentivizing miners to confirm transactions.

:::info Network Redundancy

Every full node runs its own Ethereum‚ÄØVirtual‚ÄØMachine, short EVM. Once a new block arrives, each execution client of the network's nodes **re‚Äëexecutes every transaction** in isolation to verify the proposer‚Äôs work, keeping the network trustless.

:::

## Gas and Fees

With each transaction, users attach a max‚ÄØfee they are willing to pay. Since the [London Update](https://eips.ethereum.org/EIPS/eip-1559), EVM-based networks has a predictable fee system. The protocol burns a **base fee**, which increases or decreases based on the network's current activity. Another **priority fee** is collected by the block proposer.

| Fee component                   | Recipient                                | Purpose                                        |
| ------------------------------- | ---------------------------------------- | ---------------------------------------------- |
| <nobr> **Base Fee** </nobr>     | Burnt through protocol                   | Elastic pricing to prevent spam                |
| <nobr> **Priority Fee** </nobr> | Gathered by block proposer               | Incentivises inclusion                         |
| <nobr> **MEV / Tips** </nobr>   | Gathered by block proposer and searchers | Optional extra payment for economic advantages |

:::warning Transaction Failures

If a transaction runs out of gas it reverts. However, the spent gas is still charged because the node had to do the work.

:::

:::tip MEV

The Maximal¬†Extractable¬†Value is the extra profit obtainable by re‚Äëordering, inserting, or censoring transactions.
On Proof-of-Stake chains, MEV is captured by proposers via off‚Äëchain relays or direct bundlers, while the protocol itself stays agnostic.

:::

## Epochs and Slots

An epoch in PoS is a fixed period during which slots occur. It is a larger time frame that helps to organize the work of validators who propose and attest to blocks. An epoch is comprised of 32 slots, which means an epoch lasts for about 6.4 minutes, given that each slot is about 12 seconds.

| Function                                | Details                                                                                                                                                                                                                                                                   |
| --------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> **Validator Shuffling** </nobr>  | At the start of each epoch, a random selection process determines which validators are active and assigns them to slots. This is done to ensure that the system remains decentralized and that no single validator can predict far in advance when they will be selected. |
| <nobr> **Reward Settlement** </nobr>    | At the end of each epoch, rewards and penalties are calculated for validators. Validators that correctly proposed and attested to blocks receive rewards, while those who behaved maliciously or were offline are penalized.                                              |
| <nobr> **Finality Checkpoints** </nobr> | The first block of an epoch is considered a checkpoint, refering to the point at which a block cannot be economically changed or removed from the blockchain.                                                                                                             |

:::tip Checkpoints and Finality

A checkpoint becomes **finalised** once more than two thirds of the **total active validator stake** has attested to it. Reverting that finality would require an attacker to build a conflicting chain and get more than‚ÄØone third of the entire network‚Äôs stake to sign slashable votes to slash the other remaining validators.

:::

A slot is a single 12‚Äësecond window where a randomly chosen validator has the right to propose a new block to the blockchain. Non‚Äëproposers vote on head and block validity through attestations.

- **Missed Proposals**: If the proposer is offline the _slot is skipped_.
- **Justified Blocks**: A block that gains more than two thirds of attestations _is considered as valid_.
- **Finalized Blocks**: Once the justified checkpoint finalizes the previous one, _it is marked as final_.

## Computation

Each network sets its own computational limits for their peer nodes.

| Item                                  | **LUKSO**          | **Ethereum**       | Notes                                                                                    |
| ------------------------------------- | ------------------ | ------------------ | ---------------------------------------------------------------------------------------- |
| <nobr>**Block¬†Gas¬†Limit**</nobr>      | ~42‚ÄØmillion gas    | ~30‚ÄØmillion gas    | defined by the [Ethereum Yellow Paper](https://ethereum.github.io/yellowpaper/paper.pdf) |
| <nobr>**Base¬†Fee¬†Volatility**</nobr>  | ¬±‚ÄØ12.5‚ÄØ% per block | ¬±‚ÄØ12.5‚ÄØ% per block | defined by the [EIP‚Äë1559 Standardization](https://eips.ethereum.org/EIPS/eip-1559)       |
| <nobr>**Max‚ÄØTransaction¬†Size**</nobr> | 128‚ÄØkB             | 128‚ÄØkB             | prevents frequent block bloating                                                         |
| <nobr>**Average¬†Gas¬†Price**</nobr>    | 0.1‚ÄØ‚Äì‚ÄØ0.8‚ÄØgwei     | 15‚ÄØ‚Äì‚ÄØ40‚ÄØgwei       | fluctuates with network demand                                                           |

:::info Block Size

The **block gas limit** is strict for a single block but **can adjust over time** by a small step‚Äësize of one 1024th. Block proposers can vote gradually, avoiding abrupt jumps that could destabilise the network or overwhelm nodes.

In practice the consensus code enforces an absolute floor of‚ÄØ5.000‚ÄØgas, and validators almost never coordinate to push in one direction for a significant amount of hours. However, within one day of around 7200 blocks, the limit could still scale by a few percent if every proposer pushes for the same direction.

:::

---

// File: theory/blockchain-knowledge/tokenomics

# Tokenomics

Tokenomics describes the supply schedule, reward mechanics, and economic incentives that keep a Proof of Stake network healthy.

1. **Consensus Rewards**: Validators receive new LYX or LYXt that are minted for timely proposals and attestations.
2. **Execution Fees**: Validators receive priority fees and‚ÄØtips from end‚Äëusers on top of the [burnt base fee](/docs/theory/blockchain-knowledge/proof-of-stake.md#gas-and-fees).
3. **Penalties and Slashing**: The validator's stake may be deducted for downtime or malicious voting behaviour.

:::tip

Staking returns are typically expressed as **Annual Percentage Rate**, assuming permanent validator uptime.

:::

:::info APR May 2025

- The [LUKSO¬†Mainnet](https://deposit.mainnet.lukso.network) has an APR of around **7%**
- The [LUKSO¬†Testnet](https://deposit.testnet.lukso.network) has an APR of around **42%**

:::

## APR Calculation

Returns only include the deterministic and major values of the consensus mechanism.

| Component                                 | Included | Notes                                                                               |
| ----------------------------------------- | -------- | ----------------------------------------------------------------------------------- |
| <nobr> **Consensus Rewards** </nobr>      | ‚úÖ Yes   | Set by the protocol and scaled with active stake on the network.                    |
| <nobr> **Priority Fees and Tips** </nobr> | ‚ùå No    | Directly paid to the proposer to boost returns during highly network utilization.   |
| <nobr> **MEV Commission** </nobr>         | ‚ùå¬†No    | Indirectly paid to block proposer and searchers for manipulating transaction order. |
| <nobr> **Slasher Income** </nobr>         | ‚ùå¬†No    | Directly paid to the proposer broadcasting a proof of network misbehaviour.         |

:::tip

Further details about slashing and MEV can be found within the [**Slasher Service**](/docs/theory/node-operation/slasher-service.md) and [**Proof of Stake**](/docs/theory/blockchain-knowledge/proof-of-stake.md) pages.

:::

## Earnings and Withdrawals

Validators manage two on‚Äëchain addresses to receive withdrawals and returns.

| Address Type                             | Description                                                                                                                        | Mutability                                                                                                                                                                                                                                                                                                                                                              |
| ---------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> **Withdrawal Address** </nobr>    | Receives auto‚Äëpushed consensus rewards through block proposals and in case of an exit, the remaining‚ÄØLYX or LYXt of the validator. | The address can be set during the [validator key generation](/docs/guides/validator-setup/cli-key-generation.md) or [withdrawal update](/docs/guides/withdrawals/adding-withdrawals.md) and is **immutable** after stake has been [deposited](/docs/guides/validator-setup/launchpad-walkthrough.md) as defined by [EIP‚Äë4895](https://eips.ethereum.org/EIPS/eip-4895). |
| <nobr> **Recipient Fee Address** </nobr> | Collects the priority fees, tips, and MEV commission earned by the proposing validator.                                            | The address is **mutable** and can be updated during every start of the validator node.                                                                                                                                                                                                                                                                                 |

:::tip

Both addresses can be equal, in case stakers want to manage earnings and funds with one single account.

:::

:::info

Changing the withdrawal address requires [exiting the validator](/docs/guides/withdrawals/exit-validators.md) and [redepositing the stake](/docs/guides/validator-setup/precautions.md) to a new validator key.

:::

:::warning Wallet Compatability

Both addresses are ordinary _Externally Owned Accounts_ that can be generated from regular EOA wallets within the browser, apps, or on hardware wallets. Ensure your wallet supports **LUKSO** or has the capability of adding **Custom EVM Networks**. Otherwise you may be unable to access rewards or must export the private key into another wallet before acessing the funds.

:::

## Withdrawal Cadence

A maximum of **16 consensus payouts** to the withdrawal address can be processed per block.

| Network                                                            | Active Validators | Daily Blocks | Payout Interval |
| ------------------------------------------------------------------ | ----------------- | ------------ | --------------- |
| [LUKSO¬†Mainnet](https://explorer.consensus.mainnet.lukso.network/) | ~140.000          | ~7.200       | ‚ÄØ29 Hours       |
| [LUKSO¬†Testnet](https://explorer.consensus.testnet.lukso.network/) | ~4.000            | ~7.200       | ‚ÄØ50 Minutes     |

## Semi‚ÄëDeflationary Supply

Since the [London Update](https://ethereum.org/en/history/#london), EVM-based networks feature a transaction base fee that is burned during every block proposal. As outlined by [EIP‚Äë1559](https://eips.ethereum.org/EIPS/eip-1559), the update actively **decreases the circulating supply** of the blockchain's native coin. If demand pushes the occupied block space above 50 percent, the base fee rises by up to 12.5 percent. The total of burned funds can frequently exceed newly minted consensus rewards, giving the network **semi‚Äëdeflationary dynamics**.

:::info Economic Consequences

- Sustained high activity will produce negative issuance periods for LYX and LYXt
- Lighter traffic periods will results in smaller and decreasing amounts of burned funds

:::

:::tip Load Balancing

As burned funds scale with demand while issuance scales with stake, the ultra‚Äësound effect grows when the network is busy.

:::

---

// File: theory/blockchain-knowledge/peer-networks

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Peer Networks

When one tries to visit a website, the request from a computer client often goes through a short series of centralized servers owned by corporations or data centers. These servers take on a vital role in making the service available and, therefore, become inaccessible when they go offline. Blockchains, however, don't rely on centralized servers. Instead, they use a network of computers in a peer-to-peer manner, where hundreds or thousands of servers communicate directly with each other.

Each of the peers maintains its own copy of all the pertinent blockchain details, and helps distribute it to others. The structure forms a distributed mesh network that is not held by any one organization. Rather than depending upon a centralized server for distribution of the packets of data, all parties link with others and help with the distribution of the details. All of the peers are both server and client, facilitating passing of the data directly from parties to parties without the need for go-between intermediaries. It is a resilient system that is harder to censor and that provides increased transparency.

## Blockchain Peers

In a blockchain network, peers are individual nodes that collectively maintain the system. Because these nodes are distributed across various geographic regions, the network becomes decentralized by design, making it extremely difficult for any single actor to manipulate the ledger or disrupt its operation. While nodes have varying roles depending on their setup, all of them contribute to data validation, storage, and propagation.

Each peer is responsible for:

- **Maintaining a local copy** of the chain‚Äôs latest state
- **Validating new transactions and blocks** against protocol rules
- **Broadcasting verified data** to other connected peers
- **Receiving updates** in real time to maintain network consensus

:::info

Since all peers independently confirm the same sata and reach onsensus through clearly defined rules and protocols, users don't need to rely on a source of truth. Blockchains are therefore also referenced as the **trustless** web.

:::

:::tip

Further details on how peer nodes connect and communicate with each other can be found on the [**Peer Discovery**](/docs/theory/node-operation/peer-discovery.md) page.

:::

## Operation Layers

EVM-based blockchains like LUKSO use **two overlapping peer networks**, each with different focus points.

| Layer               | Purpose                                                                                      |
| ------------------- | -------------------------------------------------------------------------------------------- |
| **Execution Layer** | Broadcasting transactions, propagating blocks, and syncing blockchain data with other nodes. |
| **Consensus Layer** | Coordinating validators, attestations, signatures, and finality votes.                       |

:::info

When a node joins the network, it **automatically operates as peer** for **both of these networks** through the Ethereum clients, managing all connections in the background. More details can be found on the [**Client Types**](/docs/theory/blockchain-knowledge/client-types.md) and [**Client Providers**](/docs/theory/blockchain-knowledge/client-providers.md) pages.

:::

## Bootstrap Nodes

Before your node can start participating in the network, it needs a way to find its first peers. Here, bootnodes come into play, describing special nodes with a well-known and static network address. These nodes act like signposts on the internet within the [network configuration](https://github.com/lukso-network/network-configs). Your node can contact them to get directions to other active nodes. When a node starts, it:

1. Connects to one or more bootnodes
2. Asks for a list of known peer addresses
3. Contacts it's first listed and active peers
4. Discovers more nodes through interconnections

:::tip

Bootnodes **don‚Äôt send blocks or transactions** themselves. They can be seen as phonebooks of the network, representing starting points for deeper connections. As such bootnodes come with extremely high peer count limits, always updating and discovering active node lists, they are operated by core institutions and professional setups. Stability and high uptime must be guaranteed, as their addresses are permanently written in the configurations.

:::

:::info Bootnode Hosting

- LUKSO provides **several bootnodes** across different regions, operated by the core team, ensuring **redundancy**.
- Having multiple bootnodes ensures reliability and **full geographic distribution** and **low latency**.

  :::

## Architectural Benefits

Decentralized networks like blockchains offer several advantages over traditional centralized services. Here‚Äôs how they compare:

| Property                                 | Central Servers                                            | Peer-to-Peer Mesh                                                                              |
| ---------------------------------------- | ---------------------------------------------------------- | ---------------------------------------------------------------------------------------------- |
| <nobr> **Fault Tolerance** </nobr>       | If the server fails, the service becomes unavailable.      | The data is replicated across thousands of nodes, meaning no single failure can bring it down. |
| <nobr> **Scalability** </nobr>           | The server must scale resources to match user growth.      | Each new node contributes bandwidth and storage, helping the network scale naturally.          |
| <nobr> **Censorship Resistance** </nobr> | A central authority can block, modify, or restrict access. | No single point of control means it's nearly impossible to censor or shut down.                |
| <nobr> **Trust Model** </nobr>           | Users must trust the operator.                             | Trust is replaced by cryptographically verified math.                                          |

:::tip

This decentralized, self-healing design is what makes public blockchains uniquely resilient and democratic.

:::

## Bootnode Addresses

Here are the bootnode connections for the LUKSO Mainnet based on the official [network configuration](https://github.com/lukso-network/network-configs).

<Tabs>
<TabItem value="nethermind" label="Nethermind, Geth, Erigon, Besu" default>

```text title="Mainnet Execution Bootnodes"
# Address 1
enode://c2bb19ce658cfdf1fecb45da599ee6c7bf36e5292efb3fb61303a0b2cd07f96c20ac9b376a464d687ac456675a2e4a44aec39a0509bcb4b6d8221eedec25aca2@34.147.73.193:30303

# Address 2
enode://276f14e4049840a0f5aa5e568b772ab6639251149a52ba244647277175b83f47b135f3b3d8d846cf81a8e681684e37e9fc10ec205a9841d3ae219aa08aa9717b@34.32.192.211:30303
```

</TabItem>
<TabItem value="prysm" label="Prysm, Nimbus-Eth2, Lighthouse">

```text title="Mainnet Execution Bootnodes"
# Address 1
enr:-MK4QJ-Bt9HATy4GQawPbDDTArtnt_phuWiVVoWKhS7-DSNjVzmGKBI9xKzpyRtpeCWd3qA9737FTdkKGDgtHfF4N-6GAYlzJCVRh2F0dG5ldHOIAAAAAAAAAACEZXRoMpA2ulfbQgAABP__________gmlkgnY0gmlwhCKTScGJc2VjcDI1NmsxoQJNpNUERqKhA8eDDC4tovG3a59NXVOW16JDFAWXoFFTEYhzeW5jbmV0cwCDdGNwgjLIg3VkcIIu4A

# Address 2
enr:-MK4QHcS3JeTtVjOuJyVXvO1E6XJWqiwmhLfodel6vARPI8ve_2q9vVn8LpIL964qBId7zGpSVKw6oOPAaRm2H7ywYiGAYmHDeBbh2F0dG5ldHOIAAAAAAAAAACEZXRoMpA2ulfbQgAABP__________gmlkgnY0gmlwhCIgwNOJc2VjcDI1NmsxoQNGVC8JPcsqsZPoohLP1ujAYpBfS0dBwiz4LeoUQ-k5OohzeW5jbmV0cwCDdGNwgjLIg3VkcIIu4A
```

</TabItem>
</Tabs>

---

// File: theory/blockchain-knowledge/slashing-and-panelties

# Slashing and Penalties

In a Proof of Stake blockchain, validators are monitored under strict scrutiny to maintain the integrity, decentralization, and consistency of the network. When a validator becomes dishonest, it risks punishment in the form of _slashing_ or _penalization_. Although both concepts are used interchangeably, they refer to two different mechanisms.

| Action       | Occurence                                  | Reason             |
| ------------ | ------------------------------------------ | ------------------ |
| **Slashing** | Validators commit provable malicious acts. | Punitive Measure   |
| **Penalty**  | Validator fails to perform their duties.   | Corrective Measure |

## Slashing

If a validator behaves inappropriately on the network, like suggesting two different blocks or distributing two different attestations, the validator is slashed by active participants on the consensus network who run a slasher service. The proof of detected misbehavior is then included in the proposed block and a portion of the slashed amount redistributed to the publisher.

:::tip

More details about slashing abilities and software can be found on the [**Slasher Service**](/docs/theory/node-operation/slasher-service.md) page.

:::

| Offense Type                       | Description                                                       |
| ---------------------------------- | ----------------------------------------------------------------- |
| <nobr> **Double Proposal** </nobr> | Submitting two different blocks for the same slot.                |
| <nobr> **Surround Vote** </nobr>   | Creating an attestation that encloses a previously submitted one. |

:::info

The _surround vote_ occurs when a validator makes an attestation which coincides with a previous one. An example would be to vote on a fresh checkpoint that includes an existing attestation.
This act can compromise the [finality guarantees](/docs/theory/blockchain-knowledge/proof-of-stake.md) of the chain.

:::

When a validator is slashed for performing one of the previous inacceptable behaviours:

- A portion of their staked LYX or LYXt is **burned**, effectively made inaccessible.
- They are **ejected** from the active validator set and lose future reward potential.
- Their offense is publicly **recorded**, ensuring transparency and accountability.

## Penalties

Penalties are leveled against validators who are offline or do not fulfill their commitment obligations without requiring evidence of malicious behavior. These are also known as _inactivity punishments_. Unlike slashing punishments, they are used to slowly reduce a validator's balance unless validators actively participate in consensus activities like block proposing or voting on attestations.

- Penalties **increase** the longer a validator is offline, reducing their balance.
- Multiple offline validators cause penalties to **scale higher** across the network.
- Indirectly, validators **lose potential rewards** while being inactive.

Inactivity penalties decrease as the effective balance of the validator decreases. During every epoch, rewards and penalties for each individual validator [are determined](https://alonmuroch-65570.medium.com/how-long-will-it-take-an-inactive-eth2-validator-to-get-ejected-a6ce8f98fd1c) using the validator's attestations, current block head, inclusion delays, and inactivity leaks.

:::info Inclusion Delay

The inclusion delay is the period between a work's assignment and submission. For blockchain networks, it's the delta between the [slot](/docs/theory/blockchain-knowledge/proof-of-stake.md) that a validator is called to [attest](/docs/theory/blockchain-knowledge/proof-of-stake.md) in, and the slot that includes their attestation on chain.

:::

:::warning

Panelties rely on network-wide participation and values are determined in a network with a participation rate of 98%. If more than 33% of validators are offline and the network stops finalizing blocks, penalties will accelerate significantly.

:::

| Downtime                  | 1 Day        | 1 Week        | 1 Month       | 6 Months       | 2 Years         |
| ------------------------- | ------------ | ------------- | ------------- | -------------- | --------------- |
| **Progressed Epoch**      | ~225 Epochs  | ~1,575 Epochs | ~6,720 Epochs | ~40,320 Epochs | ~161,280 Epochs |
| **Approximate Penalty**   | ~0.01875 LYX | ~0.13125 LYX  | ~0.5625 LYX   | ~3.375 LYX     | ~13.70 LYX      |
| **Stake Loss Percentage** | ~0.06%       | ~0.41%        | ~1.76%        | ~10.55%        | ~42.81%         |
| **Remaining Stake**       | ~31.981 LYX  | ~31.869 LYX   | ~31.438 LYX   | ~28.625 LYX    | ~18.30 LYX      |

:::danger

If the balance falls below 16 LYX or LYXt, the validator is **automatically ejected** from the active validator set of the network.

:::

:::note

On LUKSO, it will approximately take [2 Years and 4 Months](https://explorer.consensus.testnet.lukso.network/validator/903e80371518c7a3e7cb1a4705437f19329f75f0f20f5688ec9bbe38d23870e8e210fdbde332e78f988e67372918dfd7#charts) of downtime until the validator's stake will drop below 50%.

:::

## Termination

A validator may be forcefully exited from the active set under certain conditions, typically when:

- The **balance drops below 50%** due to slashing or penalties.
- It has **been slashed** for a serious offense.

:::info

Once ejected, the validator is immediately placed in an exit queue and gets subtracted from the overall number of validators. A validator is not eligible to receive any reward or participate in the consensus after it exits. To rejoin the validators' group, users have to restart the staking process.

:::

:::tip

A healthy validator should maintain a balance above 32 LYX or LYXt and ensure stable uptimes for good participation rates.
:::

---

// File: theory/blockchain-knowledge/client-types

# Client Types

With blockchain technology, you should have an understanding of various software clients that operate in conjunction to maintain a decentralized network. The clients execute the transactions, validate decisions, operate wallets, and maintain various databases, forming the basis for EVM blockchain networks.

## General Overview

In order to participate as a peer node in the blockchain network, the minimum requirements for operation include the execution and the consensus clients. For additional staking, users also have to run a process for validators along with these clients.

:::tip Optional Add-ons

Depending on infrastructure goals, an optional [**Slasher Service**](/docs/theory/node-operation/slasher-service.md) or [**MEV Process**](/docs/theory/blockchain-knowledge/proof-of-stake.md#roles-and-services) can be run to gain further profits.

:::

| Client Layer                         | Role and Responsibilities                                                                                                                                                                                                                                  |
| ------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> **Execution Client** </nobr>  | Handles EVM execution, transaction validation, state updates, gas accounting, and block propagation, while directly communicating with other execution peers. Aditionally, it also maintains account balances, contract storage, and the transaction pool. |
| <nobr> **Consensus Client** </nobr>  | Connects to the beacon chain, follows fork choice, validates block headers, aggregates attestations, and manages finality while directly communicating with other consensus peers.                                                                         |
| <nobr> **Validator Process** </nobr> | Manages validator keypairs, proposes blocks, signs attestations, and performs [Proof of Stake](/docs/theory/blockchain-knowledge/proof-of-stake.md) duties.                                                                                                |

:::info

Execution and consensus clients connect to separate [**Peer Networks**](/docs/theory/blockchain-knowledge/peer-networks.md) with their own protocols and discovery layers.

:::

## Execution Responsibilities

The execution client, is responsible for all operations related to executing transactions and managing the EVM state:

- Receiving and validating new blocks.
- Managing the transaction memory pool for pending transactions.
- Applying state transitions such as account balance changes and contract updates.
- Storing all on-chain data including, account balances, contract bytecode, contract storage.
- Maintains a frequent section or even the full blockchain history.
- Communicating with the consensus client to execute finalized blocks.

:::tip

The execution client does not determine which block is added next. Instead, it waits for the consensus client to decide on a **canonical block** that will become the head of the chain and only carries it's formation and transaction execution.

:::

:::info

The [Engine API](https://hackmd.io/@danielrachi/engine_api) is used to keep execution and consensus clients aligned on the latest valid blockchain state.

- `eth_newPayload`: Submits a new block from the execution layer to be validated and proposed.
- `forkchoiceUpdated`: Informs the execution client which block is currently considered canonical.

:::

## Consensus Responsibilities

The consensus client is responsible for all consensus-related operations in a Proof of Stake blockchain.

- Syncing the beacon chain and following the correct fork choice rule.
- Aggregating and propagating attestations, sync committee messages, and block proposals.
- Managing the validator registry and shuffling validators between slots and epochs.
- Verifying incoming block headers and ensuring they match the chain rules.
- Providing fork-choice and head updates to the execution client.

:::info

Consensus clients use the üé≤ [**libp2p**](https://libp2p.io/) stack and handle real-time communication with other validator nodes.

:::

## Validator Responsibilities

The validator client is a lightweight process embedded within the consensus client for distinct staking purposes.

- Managing the imported validator keypairs.
- Proposing blocks when selected as the slot leader.
- Attesting to new blocks and voting on chain finality.
- Signing duties with the validator's private keys.
- Monitoring performance and ensuring duties are fulfilled within the slot time.

:::warning

A validator client must be **online and well-connected** to avoid penalties and maximize rewards. While it does not store blockchain state or perform execution, it depends on the consensus client to stay in sync with the rest of the network.

:::

---

// File: theory/blockchain-knowledge/client-providers

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Client Providers

Client software is the essential underlying backbone that enables actions being executed on a blockchain network. Based on the user's specific role, whether stakers, developers, infrastructure providers, or observers, they all use different node setups and software clients that are adjusted according to their specific requirements and roles.

## Node Setups

There are three basic setups in which an execution client of the network can be operated.

| Node Type                                 | Description                                                            | Use Case                                                                        | <nobr> Typical Execution Clients </nobr> |
| ----------------------------------------- | ---------------------------------------------------------------------- | ------------------------------------------------------------------------------- | ---------------------------------------- |
| <nobr> **Light Node** </nobr>             | Downloads block headers and verifies only part of the chain.           | Wallets and Mobile dApps, <nobr> Low-Resource Devices </nobr>                   | [Helios], [Nimbus-Eth2], [Lodestar]      |
| <nobr> **Full Node** </nobr>              | Stores recent state and verifies all transactions and blocks.          | RPC Endpoints, Stakers, <nobr> Regular Node Operaters </nobr>                   | [Geth], [Erigon], [Nethermind], [Besu]   |
| <nobr> **Node‚ÄØ+‚ÄØSlasher Service** </nobr> | Runs a proof‚Äëof‚Äëstake slasher service on top of regular node services. | Staking Institutions, Watchers, <nobr> Advanced Node Operaters </nobr>          | [Geth], [Erigon], [Nethermind], [Besu]   |
| <nobr> **Archive Node** </nobr>           | Stores all historical state since genesis.                             | Indexers, <nobr> Block Explorers, </nobr> <nobr> Data Analytic Services </nobr> | [Erigon], [Geth]                         |

:::tip

Further details about hardware requirements can be found on the [**Node Specifications**](/docs/theory/preparations/node-specifications.md) page.

:::

## Supported Clients

Any Ethereum client can be set up to join the open LUKSO Network effectively. This can be done by using the publicly available [network configuration](https://github.com/lukso-network/network-configs). It should be noted, however, that some clients have been officially tested, which not only guarantees their compatibility but also ensures correct behavior within the network itself. Moreover, this testing has been carried out to ensure that the process of entering into staking is easy and not complicated for users.

:::tip Verified Support

Within the [LUKSO CLI v 0.25.1](https://github.com/lukso-network/tools-lukso-cli) the following clients are officially tested and supported by the LUKSO Network Team.

:::

| Consensus Client                                                  | Version | Github                                         | Docs                                                     | Chat                                | System Support         | Language | [CLI Staking](https://github.com/lukso-network/tools-lukso-cli) |
| ----------------------------------------------------------------- | ------- | ---------------------------------------------- | -------------------------------------------------------- | ----------------------------------- | ---------------------- | -------- | --------------------------------------------------------------- |
| [**Lighthouse**](https://lighthouse.sigmaprime.io/)               | 7.0.1   | [üîó](https://github.com/sigp/lighthouse/)      | [üìò](https://lighthouse-book.sigmaprime.io/)             | [üí¨](https://discord.gg/cyAszAh)    | Linux, Win, macOS, ARM | Rust     | ‚úÖ Yes                                                          |
| [**Prysm**](https://prysmaticlabs.com/)                           | 6.0.4   | [üîó](https://github.com/prysmaticlabs/prysm)   | [üìò](https://docs.prylabs.network/docs/getting-started/) | [üí¨](https://discord.gg/YMVYzv6)    | Linux, Win, macOS, ARM | Go       | ‚úÖ Yes                                                          |
| [**Teku**](https://consensys.net/knowledge-base/ethereum-2/teku/) | 25.6.0  | [üîó](https://github.com/ConsenSys/teku)        | [üìò](https://docs.teku.consensys.net/)                   | [üí¨](https://discord.gg/9mCVSY6)    | Linux, Win, macOS      | Java     | ‚úÖ Yes                                                          |
| [**Nimbus-Eth2**](https://nimbus.team/)                           | 25.5.0  | [üîó](https://github.com/status-im/nimbus-eth2) | [üìò](https://nimbus.team/docs/)                          | [üí¨](https://discord.gg/qnjVyhatUa) | Linux, Win, macOS, ARM | Nim      | ‚ùå No                                                           |

| Execution Client                                          | Version | Github                                            | Docs                                                               | Chat                                                   | System Support         | Language |
| --------------------------------------------------------- | ------- | ------------------------------------------------- | ------------------------------------------------------------------ | ------------------------------------------------------ | ---------------------- | -------- |
| [**Besu**](https://hyperledger.org/use/besu)              | 25.7.0  | [üîó](https://github.com/hyperledger/besu/)        | [üìò](https://besu.hyperledger.org/en/stable/)                      | [üí¨](https://discord.com/invite/hyperledger)           | Linux, Win, macOS      | Java     |
| [**Erigon**](https://github.com/erigontech/erigon#erigon) | 3.0.12  | [üîó](https://github.com/erigontech/erigon)        | [üìò](https://docs.erigon.tech/)                                    | [üí¨](https://github.com/erigontech/erigon/discussions) | Linux, Win, macOS, ARM | Go       |
| [**Geth**](https://geth.ethereum.org/)                    | 1.15.11 | [üîó](https://github.com/ethereum/go-ethereum)     | [üìò](https://geth.ethereum.org/docs/)                              | [üí¨](https://discord.com/invite/nthXNEv)               | Linux, Win, macOS, ARM | Go       |
| [**Nethermind**](http://nethermind.io/)                   | 1.32.2  | [üîó](https://github.com/NethermindEth/nethermind) | [üìò](https://docs.nethermind.io/get-started/installing-nethermind) | [üí¨](https://discord.com/invite/PaCMRFdvWT)            | Linux, Win, macOS, ARM | .NET     |

:::warning Further Assistance

If you have client-specific issues, it's best to contact the software providers directly. While LUKSO orchestrates the network, client maintainers have more hands-on knowledge about the software tools and supported infrastructure.

:::

## Provider Differences

Each client has different runtime requirements, optimization, and unique features.

:::tip

There is **no preferred client**. What‚Äôs most important is maintaining [**Client Diversity**](/docs/theory/blockchain-knowledge/client-diversity.md) to ensure network resilience.

:::

| Client          | Description                                                                                                      | Benefits                                                                              |
| --------------- | ---------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------- |
| **Geth**        | Most widely used Ethereum client, maintained by the Ethereum Foundation. Longstanding and stable.                | Default in many setups, strong community support, and broad tooling compatibility     |
| **Erigon**      | Modern execution client focused on performance and modularity. Optimized for archive and historical data access. | Ideal for data-heavy applications, efficient disk use, and fast synchronization times |
| **Nethermind**  | Performance-oriented client built with analytics and customizability in mind.                                    | Excellent logging, modular design, and strong support for advanced node operators     |
| **Besu**        | Enterprise-ready client maintained by the Hyperledger Foundation. Supports public and private network use cases. | Permissioned features, great for institutional and consortium chain deployments       |
| **Prysm**       | Popular consensus client with a clean terminal interface and great user experience, developed by Prysmatic Labs. | Intuitive tooling, widely adopted, with solid performance and documentation           |
| **Lighthouse**  | Security-first consensus client from Sigma Prime, known for audit quality and reliable performance.              | Efficient on low-end hardware, great default for solo stakers and hobbyists           |
| **Teku**        | Institutional-grade client maintained by ConsenSys, with focus on interface integrations and operability.        | Preferred by data centers and custodians with strong monitoring and API support       |
| **Nimbus-Eth2** | Minimalist, resource-light consensus client designed for embedded and ARM devices.                               | Excellent for mobile, Raspberry Pi, and custom lightweight deployments                |

## Storage Comparison

Disk utilization is not just determined by the clients and additional software, but mainly the node's operation type. The following comparison clarifies the storage requirement for both LUKSO networks and the supported execution clients.

<Tabs>
<TabItem value="ethereum" label="Ethereum Mainnet">

| Client         | Total <br /> Full Node Size | Monthly <br /> Full‚ÄëNode Growth | Yearly <br /> Full‚ÄëNode Growth | Total <br /> Archive Node Size | Yearly <br /> Archive Growth |
| -------------- | --------------------------- | ------------------------------- | ------------------------------ | ------------------------------ | ---------------------------- |
| **Geth**       | ‚âà 1.3‚ÄØTB                    | ‚âà‚ÄØ18 GB                         | ‚âà‚ÄØ217 GB                       | ‚âà‚ÄØ12‚ÄØTB                        | ‚âà‚ÄØ950 GB                     |
| **Erigon**     | ‚âà 1.0‚ÄØTB                    | ‚âà‚ÄØ16‚ÄØGB                         | ‚âà‚ÄØ193‚ÄØGB                       | ‚âà‚ÄØ3.5‚ÄØTB                       | ‚âà‚ÄØ320‚ÄØGB                     |
| **Nethermind** | ‚âà‚ÄØ1.1‚ÄØTB                    | ‚âà‚ÄØ17‚ÄØGB                         | ‚âà 204‚ÄØGB                       | ‚âà‚ÄØ7.5‚ÄØTB                       | ‚âà 690 GB¬†                    |
| **Besu**       | ‚âà‚ÄØ1.4‚ÄØTB                    | ‚âà‚ÄØ19‚ÄØGB                         | ‚âà‚ÄØ220‚ÄØGB                       | ‚âà‚ÄØ12‚ÄØTB                        | ‚âà 950 GB                     |

:::note Disclaimer

Estimated numbers sourced from [Geth Y-Chart](https://ycharts.com/indicators/ethereum_chain_full_sync_data_size), [Erigon Requirements](https://github.com/ledgerwatch/erigon#system-requirements), [Nethermind Documentation](https://docs.nethermind.io/get-started/system-requirements), and [Besu Resources](https://ethdocker.com/Usage/ResourceUsage). <br /> Blockchain created on [30th July 2015](https://etherscan.io/block/1), metrics gathered after _9 years and 10 months_ of uptime.

:::

</TabItem> <TabItem value="lukso-mainnet" label="LUKSO Mainnet">

| Client         | Total <br /> Full Node Size | Monthly <br /> Full‚ÄëNode Growth | Yearly <br /> Full‚ÄëNode Growth | Total <br /> Archive Node Size | Yearly <br /> Archive Growth |
| -------------- | --------------------------- | ------------------------------- | ------------------------------ | ------------------------------ | ---------------------------- |
| **Geth**       | ‚âà‚ÄØ62‚ÄØGB                     | ‚âà‚ÄØ2.6 GB                        | ‚âà‚ÄØ31 GB                        | ‚âà‚ÄØ572‚ÄØGB                       | ‚âà‚ÄØ286‚ÄØGB                     |
| **Erigon**     | ‚âà‚ÄØ54‚ÄØGB                     | ‚âà‚ÄØ2.2‚ÄØGB                        | ‚âà‚ÄØ27‚ÄØGB                        | ‚âà‚ÄØ169‚ÄØGB                       | ‚âà‚ÄØ85‚ÄØGB                      |
| **Nethermind** | ‚âà‚ÄØ56‚ÄØGB                     | ‚âà‚ÄØ2.3‚ÄØGB                        | ‚âà‚ÄØ28‚ÄØGB                        | ‚âà 361 GB                       | ‚âà 181 GB                     |
| **Besu**       | ‚âà‚ÄØ67‚ÄØGB                     | ‚âà‚ÄØ2.7‚ÄØGB                        | ‚âà‚ÄØ32‚ÄØGB                        | ‚âà 574 GB                       | ‚âà 287 GB                     |

:::note Disclaimer

Estimated numbers from the LUKSO Validator Community and Ethereum-based client projections. <br /> Blockchain created on [23rd May‚ÄØ2023](https://explorer.execution.mainnet.lukso.network/block/0x0f1192332bf25788a44610f912a3ac38342051707720afff667b4744785bfc79), metrics gathered after _2 years_ of uptime.

:::

</TabItem> <TabItem value="lukso-testnet" label="LUKSO Testnet">

| Client         | Total <br /> Full Node Size | Monthly <br /> Full‚ÄëNode Growth | Yearly <br /> Full‚ÄëNode Growth | Total <br /> Archive Node Size | Yearly <br /> Archive Growth |
| -------------- | --------------------------- | ------------------------------- | ------------------------------ | ------------------------------ | ---------------------------- |
| **Geth**       | ‚âà‚ÄØ7.4‚ÄØGB                    | ‚âà‚ÄØ310‚ÄØMB                        | ‚âà‚ÄØ3.7‚ÄØGB                       | ‚âà‚ÄØ67‚ÄØGB                        | ‚âà‚ÄØ34‚ÄØGB                      |
| **Erigon**     | ‚âà‚ÄØ6.4‚ÄØGB                    | ‚âà‚ÄØ260‚ÄØMB                        | ‚âà‚ÄØ3.2‚ÄØGB                       | ‚âà‚ÄØ20‚ÄØGB                        | ‚âà‚ÄØ10‚ÄØGB                      |
| **Nethermind** | ‚âà‚ÄØ6.8‚ÄØGB                    | ‚âà‚ÄØ280‚ÄØMB                        | ‚âà‚ÄØ3.4‚ÄØGB                       | ‚âà‚ÄØ43‚ÄØGB                        | ‚âà‚ÄØ22‚ÄØGB                      |
| **Besu**       | ‚âà‚ÄØ8.0‚ÄØGB                    | ‚âà‚ÄØ320‚ÄØMB                        | ‚âà‚ÄØ3.8‚ÄØGB                       | ‚âà‚ÄØ69‚ÄØGB                        | ‚âà‚ÄØ34‚ÄØGB                      |

:::note Disclaimer

Estimated numbers from LUKSO Testnet Operators and Ethereum-based client projections. <br /> Blockchain created on [3rd May‚ÄØ2023](https://explorer.execution.testnet.lukso.network/block/0xaf02ebeed3c2e900d7319535a08daa5fb21bc7d3e3603fc23e221e39925625bc), metrics gathered after _2 years_ of uptime.

:::

</TabItem> 
</Tabs>

:::info Archive Setups

Both, **Besu** and **Geth** support two archive architectures. Metrics were done using their default **LevelDB** + **Bonsai Tries**.

:::

:::tip

Details on the additional [**Slasher Service**](/docs/theory/node-operation/slasher-service.md)'s database growth, can be found on the [**Node Specifications**](/docs/theory/preparations/node-specifications.md#storage-demand) page.

:::

## Size‚ÄØDifferences

All execution clients store the same, verifiable blockchain state, yet their disk sizes vary widely through different trade‚Äëoffs in database layouts, compression, pruning policies or snapshot schedules.

| Client         | Storage Schema                                  | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| -------------- | ----------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Geth**       | <nobr> _LevelDB & Path Tries + Freezer_ </nobr> | Uses a [Merkle-Trie](https://ethereum.org/de/developers/docs/data-structures-and-encoding/patricia-merkle-trie/) in [LevelDB](https://github.com/google/leveldb) and moves old blocks to a Freezer directory. There is no auto-pruning, meaning every state is kept unless manually expired, therefore has one of the larger footprints across clients. The new additional Path Trie helps shrink the massive database size of the default LevelDB archive to around 85%, from around 12TB to only 2TB.                                                                                                                                            |
| **Erigon**     | <nobr> _Flat & Caplin_ </nobr>                  | Uses flat key-value tables with staged syncing and [Caplin](https://erigon.tech/releasing-caplins-archival-format/) compression file format to strip out redundant historical trie node data. With aggressive pruning and a column-oriented layout, it has the lowest growth in size with around 20% less than Geth, most significantly as archive node with around 33% of Geth's or Besu's size.                                                                                                                                                                                                                                                  |
| **Nethermind** | <nobr> _RocksDB & Hybrid Prune_ </nobr>         | Stores it's state in [RocksDB](https://github.com/facebook/rocksdb) and sweeps stale old trie nodes via [hybrid pruning](https://docs.nethermind.io/fundamentals/pruning/). Growth around 15% smaller than Geth, but higher than Erigon as the schema stores more historical receipts and keeps a chunk of pre‚Äëprune snapshots. It's archive size sits in the middle with around 25% less than Geth or Besu.                                                                                                                                                                                                                                       |
| **Besu**       | <nobr> _Bonsai Trie & Forest Tries_ </nobr>     | Ships with two different storage layouts for regular and full archive setups. While the [Forest Trie](https://besu.hyperledger.org/public-networks/concepts/data-storage-formats#forest-of-tries) is a classic archive, the default [Bonsai Trie](https://besu.hyperledger.org/public-networks/concepts/data-storage-formats#bonsai-tries) is a flat table layout for regular nodes, only writing leaf nodes and log deltas within a [Merkle-Trie](https://ethereum.org/de/developers/docs/data-structures-and-encoding/patricia-merkle-trie/). Additional prune commands can reduce occupied space further and make the client extremely modular. |

[Helios]: https://github.com/a16z/helios
[Nimbus-Eth2]: https://nimbus.guide/index.html
[Lodestar]: https://chainsafe.github.io/lodestar/
[Geth]: https://geth.ethereum.org/docs/getting-started/hardware-requirements
[Erigon]: https://docs.erigon.tech/getting-started/hw-requirements
[Nethermind]: https://docs.nethermind.io/get-started/system-requirements/
[Besu]: https://besu.hyperledger.org/24.3.0/public-networks/get-started/system-requirements

---

// File: theory/blockchain-knowledge/client-diversity

# Client Diversity

Client diversity refers to the practice of using **multiple, independently developed software clients** across one blockchain network. These clients are built by different engineering teams, often in different programming languages, and serve the same purpose of running the blockchain protocol Maintaining client diversity is essential **for network resilience**, security, and decentralization. If too many validators rely on the same software, a single bug or vulnerability could have catastrophic consequences.

:::tip

A detailed list of supported client software and differences can be found on the [**Client Providers**](/docs/theory/blockchain-knowledge/client-providers.md) page.

:::

## Diversity Measures

| Topic                                            | Description                                                                                                                                                                             |
| ------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> **Security & Resilience** </nobr>         | Individual bugs or attacks on a single client are not harmful to the other clients on the network and hence do not increase the risk of a mass failure happening as a consequence.      |
| <nobr> **Decentralization & Governance** </nobr> | No particular development group or codebase has an inordinate amount of power or control over the overall functionality and operation of the network as a whole.                        |
| <nobr> **Implementation Independence** </nobr>   | Different clients have different understandings of the protocol, highlighting some of the ambiguities in the specifications. This ends up with collevtive refinements of the standards. |
| <nobr> **Update Flexibility** </nobr>            | With multiple software manufacturers to choose from, there is less chance of delays in applying upgrades and a unified competition across companies to deliver features.                |

:::tip

Node operators should aim to **distribute their client usage** across the officially supported clients **to avoid dominance** by any single implementation. The current network metrics can be found on the [**LUKSO Diversity Dashboard**](https://clientdiversity.lukso.network/).

:::

## Historical Incidents

Client diversity has always proven to be of fundamental significance in the wide Ethereum Ecosystem. Below are some of the most important events in which diversity served an essential function in either protecting the network or bringing to light crucial vulnerabilities that would have had severe consequences.

- **[Shanghai DoS Attacks, 2016](https://blog.ethereum.org/2016/09/22/ethereum-network-currently-undergoing-dos-attack)**  
  Throughout the course of the Devcon2, Ethereum was targeted by a series of denial-of-service attacks that had a profound effect on its performance and stability. The dominant Geth client struggled, causing degraded performance and crashes. The alternative Parity client proved to be more resilient, keeping the network functional until highlighed issues were fixed.

- **[OpenEthereum Consensus Bug, 2020](https://www.coindesk.com/tech/2020/08/27/buggy-code-release-knocks-13-of-ethereum-nodes-offline/)**  
  A bug that was found in the OpenEthereum client led to a situation in which approximately 13% of all nodes halted at a particular block. The issue could have resulted in a chain split that would have been disruptive to the network. However, the chain kept operating normally and uninterrupted due to other nodes running Geth and Besu clients without issues.

- **[Prysm Client Finality Failure, 2023](https://offchain.medium.com/post-mortem-report-ethereum-mainnet-finality-05-11-2023-95e271dfd8b2)**  
  Shortly before the DappCon event, the Prysm client experienced severe delays due to a transaction ordering bug, also partially effecting other consensus clients. The only client not suffering from these issues at the time was Lighthouse and instrumentally kept the finality process alive even when following a long network stall of 25 minutes.

:::info

Client diversity is a **core pillar of network health to avoid systemic risks** and ensure long-term sustainability.

:::

---

// File: theory/node-operation/client-setups

# Client Setups

Running a blockchain node on LUKSO can be accomplished through different methods, depending on your experience level, use case, and available infrastructure. Whether you're looking for a simple setup or a more advanced environment with isolated containers, there‚Äôs a suitable option available.

| Setup                                                                                                          | Difficulty                 | Description                                                                                                                                                                                                                                                                                                                                                                 | Advantages                                                                                                                                                     |
| -------------------------------------------------------------------------------------------------------------- | -------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> üé® [**DAppNode**](https://dappnode.com) </nobr>                                                         | <nobr> üü¢ Simple </nobr>   | Platform to manage multiple blockchain clients using a preconfigured operating system and apps for node management and remote access. <br/><br/> **‚Üí** [DAppNode Staking Guide](https://docs.dappnode.io/docs/user/staking/lukso/solo/)                                                                                                                                     | - Graphical User Interface <br /> <nobr> - Runs Multiple Chains Simultaneously </nobr> <br /> - Integrated Network Configuration <br/> - Includes Auto-Updates |
| <nobr> üëæ [**LUKSO CLI**](https://github.com/lukso-network/tools-lukso-cli) </nobr>                            | <nobr> üîµ Advanced </nobr> | Command line interface to set up and maintain a LUKSO node in a home or server environment. <br/><br/> **‚Üí** [Server Configuration](/docs/guides/client-setup/firewall-settings.md) <br /> **‚Üí** [CLI Client Setup](/docs/guides/client-setup/lukso-cli-installation.md) <br /> **‚Üí** [Client Modifications](/docs/guides/modifications/slasher-configuration.md)           | - Simple Terminal Commands <br /> - Wide OS and Platform Support <br /> - Integrated Network Configuration <br /> - Runs All Supported Clients                 |
| <nobr> üê≥ [**Docker**](https://github.com/lukso-network/network-docker-containers) </nobr>                     | <nobr> üî¥ Expert </nobr>   | Container-based configuration to manage isolated nodes in a home or server environment. <br/><br/> **‚Üí** [LUKSO Docker Setup](https://github.com/lukso-network/network-docker-containers) <br /> **‚Üí** [Docker Configuration Factory](https://docker-factory.lukso.tech) <br /> **‚Üí** [Docker Monitoring Setup](https://github.com/lukso-network/network-docker-monitoring) | - Flexible Data Management <br /> - Runs Multiple Chains Simultaneously <br /> - Wide OS and Platform Support <br />                                           |
| <nobr> üóÇÔ∏è [**Custom**](https://docs.lukso.tech/networks/mainnet/running-a-node#-with-your-own-clients) </nobr> | <nobr> üî¥ Expert </nobr>   | Custom client installation and setup using the public LUKSO network configuration. <br/><br/> **‚Üí** [LUKSO Network Configuration](https://github.com/lukso-network/network-configs) <br /> **‚Üí** [Custom Client Advice](https://docs.lukso.tech/networks/mainnet/running-a-node#-with-your-own-clients)                                                                     | - Total Customizability <br /> - Wide OS and Platform Support <br /> - Runs All Supported Clients <br />                                                       |

:::info

The üé® [**DAppNode**](https://dappnode.com) setup utilizes üê≥ [**Docker**](https://www.docker.com/) under the hood, combining the flexibility of containers with a user-friendly GUI.

:::

:::warning DAppNode Support

Currently, üé® [**DAppNode**](https://dappnode.com) **only supports Geth** as execution client, further decreasing the [**Client Diversity**](/docs/theory/blockchain-knowledge/client-diversity.md) of the LUKSO Network. If you're technically skilled, consider an alternative setup using the LUKSO CLI or Docker.

:::

:::tip

None of the setups does restrict modification of the underlying blockchain clients. A whole suite of flags and settings can be added during startup or within configuration files to change service behaviour as described in the [Modification](/docs/guides/modifications/slasher-configuration.md) chapter.

- üé® [**DAppNode**](https://dappnode.com): You can pass down the `--<flag-name>` within the _EXTRA_OPTS_ field of the client page.
- üëæ [**LUKSO CLI**](https://github.com/lukso-network/tools-lukso-cli): You can pass the superordinate `--<client>-<flag-name>` or modify the `config` folder files.
- üê≥ [**Docker**](https://github.com/lukso-network/network-docker-containers): You can modify or add settings to the client container's `docker_compose.yml` files.
- üóÇÔ∏è [**Custom**](https://docs.lukso.tech/networks/mainnet/running-a-node#-with-your-own-clients): Modify network configurations files or directly pass the `--<flag-name>` to the clients.

:::

:::note

Further Sources about Client Configurations:

- [Geth Parameters](https://geth.ethereum.org/docs/fundamentals/command-line-options)
- [Erigon Options](https://github.com/ledgerwatch/erigon)
- [Besu Options](https://besu.hyperledger.org/stable/private-networks/reference/cli/options)
- [Nethermind Configuration](https://docs.nethermind.io/fundamentals/configuration)
- [Prysm Parameters](https://docs.prylabs.network/docs/prysm-usage/parameters)
- [Lighthouse Flags](https://lighthouse-book.sigmaprime.io/help_general.html)
- [Teku Reference](https://docs.teku.consensys.io/reference/cli)
- [Nimbus-Eth2 Options](https://nimbus.guide/options.html)

:::

---

// File: theory/node-operation/operation-systems

# Operation Systems

The choice of operating system for blockchain nodes makes a considerable difference in terms of security, availability, and compatibility. Node operators mostly use open source-based Linux distributions because they are very stable and perform well and have wide compatibility with Ethereum Virtual Machine toolsets. Ubuntu and Debian lead among them because they have strong package management and support life cycles.

:::tip External Analysis

- According to üçÉ [**Ether Nodes**](https://www.ethernodes.org/os), more than 95% of EVM-based nodes run on Linux, with üî∂ [**Ubuntu**](https://ubuntu.com/) and üç• [**Debian**](https://www.debian.org/) on top.
- Wide-spread consumer software like üé® [**DAppNode**](https://dappnode.com/) also operates üç• [**Debian**](https://www.debian.org/) under the hood.

:::

## System Comparison

Ubuntu and Debian are both capable operating systems for running a blockchain node.

| Feature      | Ubuntu                                                                                                       | Debian                                                                                                       |
| ------------ | ------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------ |
| **Overview** | _Most popular and widespread Linux distribution with regular updates, low maintenance, and great stability._ | _Rock-solid Linux distribution focused on long-term stability, reliability, security, and minimalism._       |
| **Focus**    | - User-Friendliness <br/> - Frequent Updates <br/> - Easy Access to Latest Software <br/> - Active Community | - Maximum Stability <br/> - Lower Resource Use <br/> - Conservative Release Cycles <br/> - Ideal for Experts |

:::info

Ubuntu and Debian both are distributions of high-performance operating systems with considerable support for various platforms. Both distributions act as effective nodes. The main difference is how users want to balances usability and stability, and how much manual effort one is willing to take in setting up modern defaults.

:::

:::tip

The [**Hardware Setup**](/docs/guides/hardware-setup/introduction.md) of the üìñ [**Guide**](/docs/guides/validator-setup/precautions.md) section uses **Ubuntu 22.04.2 LTS Server**. While Debian users can follow along, some commands or package names may slightly differ. Feel free to look up distribution-specific alternatives when needed.

:::

## Server Systems

It is strongly advised to use a server version of an operating system over a desktop version. Server versions are designed to be operated headless and ensure a decrease in background processes that could interfere with system functioning.

| Feature                                              | Description                                                                                                                                                             |
| ---------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> **Minimal Resource Usage** </nobr>            | It lacks a graphical user interface and unnecessary packages, thus reducing the overall CPU, memory, and disk usage, which improves the performance of the node.        |
| <nobr> **Increased Stability & Reliability** </nobr> | Fewer packages mean fewer points of failure, such as avoiding graphical rendering and display output, unwanted package interactions, or reserved ports.                 |
| <nobr> **Focus on Server Apps** </nobr>              | The system is built using command-line tools and services that mainly target the backend, making it very fitting for persistent processes and software daemons.         |
| <nobr> **Security and Patch Cycle** </nobr>          | It gets more regular security and software updates than regular consumer repositories, thus allowing all its components to be kept up-to-date to their newest versions. |

## Long-Term Support

Both software manufacturers offer special long-term-support versions of their operation systems, serving as checkpoints through their rollouts. LTS versions get more frequent security upgrades, receive support over extended periods, and go through rigorous testing before their releases. These versions are critically designed for business servers expected to run with little interruption.

:::info Additional Resources

- **Ubuntu**: [Lifecycle and Release Cadence](https://ubuntu.com/about/release-cycle)
- **Debian**: [Long Term Support](https://wiki.debian.org/LTS)

:::

| Feature                                 | Description                                                            |
| --------------------------------------- | ---------------------------------------------------------------------- |
| <nobr> **Improved Stability** </nobr>   | Prioritizes uptime and reliability for all included software packages. |
| <nobr> **Greater Security** </nobr>     | Extended patch cycle with regular updates for core system packages.    |
| <nobr> **Lower Maintenance** </nobr>    | Avoids frequent upgrades or reinstallations over the years.            |
| <nobr> **Better Compatibility** </nobr> | Supported by a wider range of node software and community guides.      |

## Installation Types

Most installers support different images types, most notably normal and minimized setups.

| Type            | Regular Installation                                                                   | Minimized Installation                                                                      |
| --------------- | -------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------- |
| **Purpose**     | User-Operated Devices and Instances                                                    | Automated Deployments and Containers                                                        |
| **Description** | - normal boot process <br /> - regular package support <br /> - frequent update cycles | - smaller boot process <br /> - fewer pre-installed packages <br /> - reduced update cycles |

:::tip

The **regular installation** is **recommended**, as it contains all relevant configuration tools and full logging capabilities.

:::

:::warning

The **minimal installation** [lacks essential tools](https://ubuntuforums.org/showthread.php?t=2474104) for debugging and user configuration and is **only advised** for **professionals**. Subsequent installations for any missing software can lead to additional friction during maintenance, customization, or when troubleshooting issues.

:::

The following comparison presents a more detailed look at the different installation types for Ubuntu:

| Ubuntu 22.04.2 Server                        | Regular Installation                                                                    | Minimized Installation                                                        |
| -------------------------------------------- | --------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------- |
| <nobr> **Installed Packages** </nobr>        | ~606 packages                                                                           | ~420 packages                                                                 |
| <nobr> **Initial Storage Footprint** </nobr> | ~4,5 GB                                                                                 | ~ 4,1 GB                                                                      |
| <nobr> **Initial RAM Usage** </nobr>         | ~192 MB                                                                                 | ~176 MB                                                                       |
| <nobr> **User Interaction** </nobr>          | - Multiple Text Editors <br /> - Full Firewall Capabilities <br /> - Includes MAN Pages | - Without Text Editors <br /> - Lacks Firewall Commands <br /> - No MAN Pages |

:::danger

During community testing, the minimized installation lacked debugging commands and generated incomplete service logs. Some configuration files had to be generated manually before configuring monitoring processes.

:::

---

// File: theory/node-operation/validator-credentials

# Validator Credentials

The setup of a validator requires the coordination of multiple credentials, passwords, and files, each playing an individual role in the lifecycle of validation and staking. Understanding them is important, both for the initial setup and for maintaining secure operation and recovery over the long-term.

:::warning

Negligent handling of credentials could result in **lost funds, missed rewards, or permanent loss of validator access**.

:::

| Name                                               | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| -------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> **Validator Mnemonic Seed** </nobr>         | A set of 12 or 24 words used to derive your validator deposit keys and deposit data. It's the most critical credential you must protect. Anyone accessing it can regenerate your validator setup and steal your staked LYX. If lost, you cannot restore your validator keys. Store it securely, preferably offline and in multiple physical backups. <br /><br /> **‚Üí** [Wagyu Key Generation](/docs/guides/validator-setup/wagyu-key-generation.md), [CLI Key Generation](/docs/guides/validator-setup/cli-key-generation.md)                                                                                                                     |
| <nobr> **Validator Deposit Key** </nobr>           | Your validator private key, stored within a keystore file, is necessary for starting the validating procedure and should be safely kept. It can be recreated if it is lost using your validator mnemonic seed. However, if stolen, an adversary can use your validator and reap the rewards attached to it. <br /><br /> **‚Üí** [Wagyu Key Generation](/docs/guides/validator-setup/wagyu-key-generation.md), [CLI Key Generation](/docs/guides/validator-setup/cli-key-generation.md) , [Validator Configuration](/docs/guides/client-setup/validator-configuration.md)                                                                            |
| <nobr> **Validator Key Password** </nobr>          | Individual validator keystore files are encrypted by a password. Decrypting them when importing validator keys into the validator client is necessary. You can use one password per key or reuse one password for multiple keys, depending on your security needs. This password should be stored securely, much like you would for a wallet password. <br /><br /> **‚Üí** [Wagyu Key Generation](/docs/guides/validator-setup/wagyu-key-generation.md), [CLI Key Generation](/docs/guides/validator-setup/cli-key-generation.md), [Validator Configuration](/docs/guides/client-setup/validator-configuration.md)                                  |
| <nobr> **Deposit Data** </nobr>                    | The public key and the validator's signature are placed into a JSON file that is used within the deposit process to register the validator on-chain. While this file is necessary to register for staking, it is not secret. However, people could count the total number of validators form the file to plan potentially worthwhile attacks. <br /><br /> **‚Üí** [Wagyu Key Generation](/docs/guides/validator-setup/wagyu-key-generation.md), [CLI Key Generation](/docs/guides/validator-setup/cli-key-generation.md) , [Launchpad Walkthrough](/docs/guides/validator-setup/launchpad-walkthrough.md)                                           |
| <nobr> **Validator Wallet Password** </nobr>       | A strong and unique password that provides safe access to the wallet holding your validator deposit keys. It is required on every startup of the validator client. <br /><br /> **‚Üí** [Validator Configuration](/docs/guides/client-setup/validator-configuration.md) , [Service Automation](/docs/guides/modifications/service-automation.md)                                                                                                                                                                                                                                                                                                     |
| <nobr> **Validator Withdrawal Address** </nobr>    | The address of an Ethereum account to which the staking rewards from consensus are automatically transferred. This address will also be the recipient for the returning stake when leaving the network. Once it got set for the validator key on-chain, it cannot be updated. Therefore, it should be kept under long-term control using secure backups or by deriving it from a hardware wallet. <br /><br /> **‚Üí** [Wagyu Key Generation](/docs/guides/validator-setup/wagyu-key-generation.md), [CLI Key Generation](/docs/guides/validator-setup/cli-key-generation.md) , [Adding Withdrawals](/docs/guides/withdrawals/adding-withdrawals.md) |
| <nobr> **Validator Recipient Fee Address** </nobr> | The address of an Ethereum account used for receiving the transaction fees and tips earned as a validator has a purpose. If you have only one account for managing all rewards, this address can match the validator withdrawal address. <br /><br /> **‚Üí** [Validator Configuration](/docs/guides/client-setup/validator-configuration.md) , [Service Automation](/docs/guides/modifications/service-automation.md)                                                                                                                                                                                                                               |

:::danger

Never disclose or share your **Validator Mnemonic Seed.** It is the source of your entire set of staking credentials. If a hacker gets access to it, they can recreate your deposit keys and steal your validator, your staked coins, or harm you by running a second node to drain your stake. Once you lose access, your validator and coins **cannot be recovered**. Therefore, store it offline, redundantly, and securely.

:::

:::tip

For more details about earnings and withdrawals, check the [**Tokenomics**](/docs/theory/blockchain-knowledge/tokenomics.md) and [**Proof of Stake**](/docs/theory/blockchain-knowledge/proof-of-stake.md) pages in the üß† [**Theory**](/docs/theory/preparations/node-specifications.md) section.

:::

---

// File: theory/node-operation/staking-deposits

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Staking Deposits

Staking is the process of locking up tokens to activate validator responsibilities in a Proof-of-Stake blockchain. Validators play a crucial role in securing the LUKSO network, proposing blocks, and participating in consensus. The process requires careful key management, node setup, and regular monitoring, but results in staking rewards for honest participation.

:::tip

Further details about staking in general can be found on the [**Proof of Stake**](/docs/theory/blockchain-knowledge/proof-of-stake.md) and [**Tokenomics**](/docs/theory/blockchain-knowledge/tokenomics.md) pages.

:::

## Validator Operation

Each validator requires a **fixed stake of 32 LYX** on mainnet or **32 LYXt** on testnet. While both mainnet and testnet mirror the same blockchain protocol and apply equal updates, their validator deposit processes differ in access, value, and purpose. While the mainnet is a fully public permissionless blockchain, the testnet uses a curated list of long-term operators to ensure stable validation and reliable testing for developers.

| Category                              | LUKSO Mainnet                                                  | LUKSO Testnet                                                                                |
| ------------------------------------- | -------------------------------------------------------------- | -------------------------------------------------------------------------------------------- |
| <nobr> **Access** </nobr>             | - Open and permissionless                                      | - Requires whitelisting by the core team                                                     |
| <nobr> **Stake Coin** </nobr>         | - LYX with real monetary value                                 | - LYXt with no monetary value                                                                |
| <nobr> **Purpose** </nobr>            | - Secure the public network <br /> - Earn staking rewards      | - Environment for protocol deployment <br /> - Developer platform for smart contract testing |
| <nobr> **Validator Deposits** </nobr> | [Mainnet Launchpad](https://deposit.mainnet.lukso.network/en/) | [Testnet Launchpad](https://deposit.testnet.lukso.network/en/)                               |

:::tip Whitelisting

If you want to apply as testnet validator, send an email to `testnet-validators@lukso.network` containing a wallet address, a detailed infrastructure description of your service or business, and the validator use case and network involvement.

:::

## Deposit Instructions

Setting up a validator involves multiple careful steps. Below is an overview of the entire deposit journey on both networks:

<Tabs>
<TabItem value="mainnet" label="Mainnet">

1. _Acquire LYX and transfer to a regular browser wallet_
2. [**Device Setup**](/docs/guides/validator-setup/precautions.md): _Configure a secure and offline device_
3. [**Key Generation**](/docs/guides/validator-setup/wagyu-key-generation.md): _Generate validator keys and deposit data on an offline device_
4. [**Hardware Setup**](/docs/guides/hardware-setup/introduction.md): _Configure your homestaking node or server_
5. [**Client Setup**](/docs/guides/client-setup/router-port-arrangement.md): _Set up your node with execution, consensus, and validator clients_
6. [**Validator Configuration**](/docs/guides/client-setup/validator-configuration.md): _Transfer generated keys to your staking node_
7. [**Validator Configuration**](/docs/guides/client-setup/validator-configuration.md) _Import validator keys into your node's consensus client_
8. [**Validator Configuration**](/docs/guides/client-setup/validator-configuration.md): _Start the staking node in idle mode until deposit is confirmed_
9. [**Deposit Stake**](/docs/guides/validator-setup/launchpad-walkthrough.md): _Deposit 32 LYX to each validator using the Mainnet Launchpad_
10. _Wait for the validator to activate_

</TabItem>

<TabItem value="testnet" label="Testnet">

1. _Apply for validator keys through email and attach your browser wallet address_
2. _Wait upon whitelisted deposits and receipt of LYXt from the LUKSO team_
3. [**Device Setup**](/docs/guides/validator-setup/precautions.md): _Configure a secure and offline device_
4. [**Key Generation**](/docs/guides/validator-setup/wagyu-key-generation.md): _Generate validator keys and deposit data on an offline device_
5. [**Hardware Setup**](/docs/guides/hardware-setup/introduction.md): _Configure your homestaking node or server_
6. [**Client Setup**](/docs/guides/client-setup/router-port-arrangement.md): _Set up your node with execution, consensus, and validator clients_
7. [**Validator Configuration**](/docs/guides/client-setup/validator-configuration.md): _Transfer generated keys to your staking node_
8. [**Validator Configuration**](/docs/guides/client-setup/validator-configuration.md) _Import validator keys into your node's consensus client_
9. [**Validator Configuration**](/docs/guides/client-setup/validator-configuration.md): _Start the staking node in idle mode until deposit is confirmed_
10. [**Deposit Stake**](/docs/guides/validator-setup/launchpad-walkthrough.md): _Deposit 32 LYX to each validator using the Testnet Launchpad_
11. _Wait for the validator to activate_

</TabItem>
</Tabs>

:::info Activation Delay

After the deposit, validators may need to wait several hours to be activated. Only a few validators are activated per epoch.

:::

---

// File: theory/node-operation/slasher-service

# Slasher Service

The slashing service is an optional but crucial network service that adds an additional layer of protocol-level security to Proof of Stake blockchains. It detects misbehavior by a validator, like double-signing or surround-voting, which then triggers slashing by the consensus protocol. On a broader view, slashing nodes can be considered the network's watchdogs to help enforce honesty and proper punishment for violators.

:::tip

More details about slashing and validator duties can be found on the [**Slashing and Panelties**](/docs/theory/blockchain-knowledge/slashing-and-panelties.md) and [**Proof of Stake**](/docs/theory/blockchain-knowledge/proof-of-stake.md) pages.

:::

## Responsibilities

A slasher keeps track of all the validators on the network by block proposals per slot and attestations to chain the new heads or checkpoints. It cross-verifies those records against each other to detect double proposals or a surrounded votes. Once an offense was found, the slasher service reports evidence to the network so that the misbehaving validator can be sanctioned. However, slashers themselves don't stop or ban validators.

Theoretically, one honest slasher within the network would be sufficient. Once published, any other operator within the network could add the proof to a future block. However, as slasher services are operated on top of nodes, multiple instances should be run geographically spread to ensure resilience during downtime.

:::info

The slashing only affects **individual validators at protocol level** and not the ongoing execution of the node clients. However, in case validators were operated on several nodes simultaniously, its possible that they are slashed all together.

:::

## Slasher Operation

Slashing is **not required** for node operators or validators. While any validator can attach a slashing report to a block and get a small reward, the frequency of misbehaviour paired with the chance of publishing the subsequent block are extremely low for solo stakers or those running only a few validators. As most participants behave correctly, running a slasher service is mostly advisable for:

- Large staking institutions or services
- Advanced staking nodes above 100 keys
- Operators focusing on fraud detection

:::info

In two years of [LUKSO](https://explorer.lukso.network/block/0x0f1192332bf25788a44610f912a3ac38342051707720afff667b4744785bfc79) with around [140.000 validators](https://explorer.consensus.mainnet.lukso.network/) and [4,5 million blocks](https://explorer.lukso.network/blocks), [less than 500 slashable events](https://explorer.consensus.mainnet.lukso.network/validators/slashings) were detected.

:::

## Rewards

If a slasher detects misbehaviour and broadcasts a valid slashing proof, it becomes available to be included in the next block. The validator that **publishes this proof** within a block, **earns a small** part of the slashed stake through a **whistleblower reward**. Since validators are selected randomly, one can't guarantee that the detecting node is also the one to publish the proof on-chain. In reality, several nodes will detect a slashable event and compete that one of their validators gets to propose the subsequent block.

:::tip

Slashing rewards are meant to **incentivize correctness**, not serve as a business model. The goal is prevention, not profit.

:::

---

// File: theory/node-operation/peer-discovery

# Peer Discovery

Peer discovery is the mechanism by which a peer on a distributed network finds peers with which it may communicate. In peer-to-peer blockchain, this process is done automatically with algorithms that create channels of communication between the clients. All of the nodes are equal parties in this mesh, and dynamic peer discovery allows the network to heal, expand, and adapt.

:::tip

The fundamentals of peer networks, operation layers, and blockchain nodes can be found on the [**Peer Networks**](/docs/theory/blockchain-knowledge/peer-networks.md) page.

:::

:::info

EVM-based blockchains like LUKSO use [two overlapping peer networks](/docs/theory/blockchain-knowledge/peer-networks.md#operation-layers), for the consensus and execution layer.

:::

## Connection Process

The peer-to-peer discovery process is surprisingly elegant and efficient. Here‚Äôs a high-level overview of how your node finds others:

1. **Every node has a unique ID**, derived from its cryptographic keys. This is like its personal identity on the network.
2. **Nodes maintain a routing table**, organizing other peer IDs into buckets based on how close their IDs are.
3. **When searching for peers**, your node asks others ‚Äúwho is closer to this target ID?‚Äù and walks through the routing tree.
4. **Once a new peer is found**, the connection is upgraded to a secure, encrypted session using mutually agreed sub-protocols.
5. **After connection**, nodes begin exchanging blocks, transactions, and consensus messages through gossip networks.

:::tip

All of this happens behind the scenes. Node operators just need to make sure that the router allows incoming connections on the appropriate ports. Further details can be found on the [**Router Setup**](/docs/guides/router-setup/static-ip-assignment.md) and [**Firewall Settings**](/docs/guides/client-setup/firewall-settings.md) pages.

:::

:::note Further Details

The peer discovery within mesh networks like EVM-based blockchains utilizes the üï∏Ô∏è [**Kademlia**](https://medium.com/coinmonks/a-brief-overview-of-kademlia-and-its-use-in-various-decentralized-platforms-da08a7f72b8f) algorithm.

:::

## Adjustment Effects

While you may increase your peer count and visibility to add to your node's network connectivity and health, overly high peer limits can be inefficient or interfere with optimal topology design. Theoretical recommendations for setting peer discovery parameters are presented in the next table.

| Effect                                     | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| ------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> **Resource Usage** </nobr>          | Each additional peer is requiring system resources, including CPU, memory, and bandwidth. Having high peer counts increases your [uploaded data](/docs/theory/preparations/network-demand.md), since your node is sending out more packages to other peers. Node effectiveness and synchronization rate can be degraded if system resources are overwhelmed.                                                                                                                                                                                                                                                                                                                    |
| <nobr> **Network Topology Impact** </nobr> | The peer-to-peer network thrives with decentralization. The moment that one node is linked with too many peers, by default it creates a hub, centralized communication, going in direct opposition of the distributed nature of the network. Ideally, the network is made up of tiny overlapping subgroups. Overconnecting creates systemic risk. When a ordinary node is offline in a small sub-group, the overall network does not notice. However, if highly-connected peers generate downtime, a much bigger portion of the network fluctuates, as hundreds of communication channels will stall at once, re-try to establish connections, and might drop their peer count. |
| <nobr> **Wasted Connections** </nobr>      | Above a peer count of around 100 on large networks with thousands of nodes, further connections gain little propagation rate or stability. They just consume bandwidth and sockets with no improvement on any fault tolerance or synchronization time of the overall network. The added connections add redundancy with little real gain, especially on small or medium nodes.                                                                                                                                                                                                                                                                                                  |

:::tip

If you are unsure about [**Peer Count Limits**](/docs/guides/modifications/peer-count-limits.md), it‚Äôs best to rely on the [default network configuration](https://github.com/lukso-network/network-configs), designed to balance resource use, discovery efficiency, and network stability for homestaking nodes within the community.

:::

---

// File: theory/node-operation/dynamic-dns

# Dynamic DNS

In order for the node to be accessible to other participants in a peer-to-peer blockchain, it must have an identifiable and stable IP address. Most internet service providers assign dynamically changing IP addresses to residential customers, and these can change on a weekly basis or router reboots.

The frequent IP address changes disrupt incoming peer connections and slow down the node's visibility and synchronization times. Dynamic DNS solves the problem through linking the dynamic IP address to a permanent domain name, allowing others to find you even when the IP changes.

:::info Default Setup

The üëæ [LUKSO CLI](/docs/guides/client-setup/lukso-cli-installation.md) will optionally set the current interchangeble IP address during the client installation.

:::

## DNS Records

A Domain Name System record can be thought of as the internet's directory and is used to associate a human-readable domain name with an IP address used by computers to communicate. DNS records are of particular importance for the following reasons:

- Allow devices to find each other over the internet without hardcoding IPs
- Enable services like HTTPS, email delivery, and node routing
- Abstract IPs behind stable webpage or service names

:::note DNS Schematic

`mynode.example.com` ‚Üí `198.51.100.12`

:::

## Dynamic DNS

A Dynamic DNS service allows for automatic domain name registration and update in case of an IP address change. Once the IP address changes, the node or the router can trigger the respective DDNS provider to update the DNS record accordingly. Other nodes can thereby continue to be in touch using the domain name without interruption. This is especially useful for:

- Devices that must maintain consistent connectivity
- Services that want to stay discoverable during updates

:::note DDNS Schematic

`mynode.example.com` ‚Üí `198.51.100.12` at _Time A_ / `198.51.100.13` at _Time B_

:::

## DDNS Setups

There are several ways to implement Dynamic DNS. Each varies in technical complexity, flexibility, and setup cost.

| Approach                                       | Difficulty                 | Description                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ---------------------------------------------- | -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| <nobr> **Dynamic DNS Providers** </nobr>       | <nobr> üü¢ Simple </nobr>   | Users can register and choose free domains from DNS providers. The services often come with plug-and-play installation and scripts, which are ideal for regular node setups. For little money, the domain ownership can even be extended without further maintenance. <br /> <br /> **‚Üí** [Dynamic DNS](/docs/guides/modifications/dynamic-dns.md), [üö´ No-IP](https://www.noip.com/), [üê§ Duck-DNS](https://www.duckdns.org/) |
| <nobr> **Built-in Router DDNS** </nobr>        | <nobr> üü¢ Simple </nobr>   | Many consumer routers support built-in DDNS settings for providers or ISP services. Users can configure their DDNS via the router's user interface. It's free and easy to set up, but people are bound to the hardware and supported service partners. <br /> <br /> **‚Üí** [Router Requirements](/docs/theory/preparations/router-requirements.md), [üß≠ AVM](https://fritz.com/) , [üí† ASUS](https://www.asus.com/)            |
| <nobr> **Cloudflare DNS + API Script** </nobr> | <nobr> üîµ Advanced </nobr> | Technically experienced users can register a domain and update the DNS record through the [Cloudflare API](https://developers.cloudflare.com/api/). While offering great control, this requires experience with scripting and API calls.                                                                                                                                                                                       |
| <nobr> **Cronjob or Shell Script** </nobr>     | <nobr> üîµ Advanced </nobr> | Developers can register their own domain and run a local IP checking script that sends a DNS update call to the domain provider. While offering great control, it requires experience with daemon software and API calls.                                                                                                                                                                                                      |
| <nobr> **Self-Hosted DDNS Server** </nobr>     | <nobr> üî¥ Expert </nobr>   | System administrators can create their own DDNS update server and use their domain registrar‚Äôs API. This offers self-sufficient control over the setup but requires extensive development and DNS knowledge.                                                                                                                                                                                                                   |

:::tip

A guide to integrate **DDNS** into the blockchain clients can be found on the [**Dynamic DNS**](/docs/guides/modifications/dynamic-dns.md) guide.

:::

:::warning

**Advanced** and **Expert** setups might come with monthly or yearly costs due to the **required domain registration**.

:::

---

// File: theory/node-operation/monitoring-tools

# Monitoring Tools

Monitoring tools help node operators monitor hardware health, service availability, connection reliability, and validator performance. Whether someone is running a home setup or cloud nodes, real-time observability is essential to avoid downtime, correct bottlenecks, and respond quickly to any type of anomaly.

| Category                               | Description                                                                                                  | <nobr> Related Services </nobr>                                                                                                                                                                                                                                                                                                                                                     |
| -------------------------------------- | ------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> **Local Monitoring** </nobr>    | Tracks and collects data **from within your own node**. <br /> Useful for internal health & uptime tracking. | - [Prometheus](/docs/guides/monitoring/prometheus.md) and [Grafana Dashboard](/docs/guides/monitoring/grafana.md)<br/>- [Node](/docs/guides/monitoring/node-exporter.md), [JSON](/docs/guides/monitoring/json-exporter.md), and [Blackbox Exporters](/docs/guides/monitoring/blackbox-exporter.md)                                                                                  |
| <nobr> **External Monitoring** </nobr> | Provides visibility into **your node's public behavior**. <br /> Useful for consensus and network analysis.  | - [Execution Explorer](/docs/guides/monitoring/external-monitoring.md#execution-block-explorer) and [Status Page](/docs/guides/monitoring/external-monitoring.md#execution-status-page)<br/>- [Consensus Explorer](/docs/guides/monitoring/external-monitoring.md#consensus-block-explorer) and [Status Page](/docs/guides/monitoring/external-monitoring.md#consensus-status-page) |

:::tip

A list of external tools, descriptions, and validator setups can be found within [**External Monitoring**](/docs/guides/monitoring/external-monitoring.md) of the üìñ [**Guide**](/docs/guides/validator-setup/precautions.md) section.

:::

:::info

Monitoring tools typically get connected to [**Alert Systems**](/docs/guides/alert-systems/telegram-bot.md) for receiving status updates and warnings via message or email.

:::

## Software List

Local node monitoring tracks the hardware condition and performance of a node. Commonly measured parameters usually include CPU load, memory pressure level, disk utilization, consensus and execution metrics, validator uptimes and syncing health. Having everything measured in real time, the software enables preemptive debugging and extended stability.

| Tool           | Description                                                                                                                                                                                                                                                                                                                         |
| -------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Prometheus** | Prometheus is an open source system and service monitor and alert tool. It gathers statistics from exporters based on periodic time intervals and provides historical data storage. The service works based on custom rules and alert configurations to proactively detect and diagnose anomalies within the node's infrastructure. |
| **Grafana**    | Grafana is a data visualisation system that converts Prometheus metrics into insightful dashboards. The service supports querying, visualising, alerting, and monitoring data over time. At local node configuration level, it is generally utilized as primary interface to monitor node health and blockchain-specific telemetry. |

## Exporter Services

In a Prometheus environment, internal as well as external metrics get exposed as local HTTP targets that get scraped and saved through exporter services. Depending on their purpose for use, they become system-level or application-level services.

:::info Categories

- **Machine-Centric Exporters**: Monitor system resources from the host's operation system or hardware.
- **Application-Centric Exporters**: Monitor specific services, blochain clients, or fetch external APIs.

:::

| Exporter                             | Description                                                                                                                                                                                                                                                                                                                |
| ------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> **Node Exporter** </nobr>     | Monitors hardware and statistics from the operation system such as CPU utilization, memory load, disk utilization growth, and network throughput. Running it on each node outlines a full picture of the system's health and prevents potential performance degradation.                                                   |
| <nobr> **JSON Exporter** </nobr>     | Periodically fetches data from JSON APIs. This type of exporter is generally used to fetch current prices of the staked coin to synchronize validator activity with market data. For LUKSO homestakers, the LYX price is fetchable using the [ü¶é CoinGecko](https://www.coingecko.com/) API.                               |
| <nobr> **Blackbox Exporter** </nobr> | Frequently sends data requests to an stable external server, like the [üì° Google DNS](https://developers.google.com/speed/public-dns?hl=en), to ensure connectivity and low latency. The exporter is used to determine potential connection issues or clarify if downtime comes from the home network or external parties. |

:::tip

The table only shows the node's most important datapoints configured within the [**Monitoring Setup**](/docs/guides/monitoring/software-preparation.md) of the üìñ [**Guide**](/docs/guides/validator-setup/precautions.md) section. Optional exporters can be configured for various metrics and a more comprehensive dashboards.

:::

## Client Metrics

Each blockchain client comes with at least one built-in endpoint metrics endpoint to let Prometheus scrape and observe chain progression, peer connectivity, syncronization lag, and validator performance and returns in real-time.

| Client Type                         | Description                                                                                                                                                                                                                                                                                   |
| ----------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> **Consensus Client** </nobr> | Consensus clients typically expose metrics for chain synchronization, finality, slot and epoch tracking, peer count, memory usage, and log events. Key metrics include the current head slot, network liveness and participation rate, and peer connections.                                  |
| <nobr> **Validator Client** </nobr> | Validator clients usually provide detailed telemetry on validator-specific behavior like earnings, return rates, successful or failed duties, inactivity scores, and slashing status. Often, they also monitory the average balance or the number of currently exiting or pending validators. |

:::warning Differences

The **Metrics** and **Dashboards** differ across clients, as they expose various lables.

- **Prysm**: Exposes all data streams from validators and consensus clients.
- **Teku**: Does not show slashing validators, failed attestations and aggregations, <br/> inactivity scores, or validator balances, statuses, returns, and earnings.
- **Nimbus-Eth2**: Does not show slashing validators or separated validator <br/> logs for memory usage, uptime, restarts, errors, and warnings.
- **Lighthouse**: Does not expose slashing validators.

:::

:::tip

The **Nimbus-Eth2** client is not supported for Staking within the [**LUKSO CLI**](https://github.com/lukso-network/tools-lukso-cli). Additionally, the consensus client requires a custom `--validator-monitor-details` flag to expose regular blockchain metrics. When using the LUKSO CLI, the dashboard will still lack metrics until staking is fully supported. Further details can be found on the [**Monitoring Settings**](/docs/guides/maintenance/monitoring-settings.md) page of the üìñ [**Guide**](/docs/guides/validator-setup/precautions.md) section.

:::

---

// File: theory/node-operation/ssh-and-vpn-tunnel

# SSH and VPN Tunnel

Having a remote blockchain node generally requires secure and persistent access during maintenance. This page covers the SSH service and VPN tunnels, essential tools for maintaining encrypted, remote connections to allow secure management, monitoring, and interaction with your node from anywhere in the world.

:::tip

A detailed guide about remote access can be found within the [**SSH Setup**](/docs/guides/ssh-setup/initialization.md) and [**Tailscale**](/docs/guides/external-access/tailscale.md) pages of the üìñ [**Guide**](/docs/guides/validator-setup/precautions.md) section.

:::

## SSH Service

Open Secure Shell software allows secure communication and high-speed data transfer among two networked devices. It is a necessary tool for remote management, secure file transfer, and executing shell commands over an assured channel. In a blockchain context, running an OpenSSH server on one's node allows secure management from outside networks and is especially beneficial with cloud-based setups or when reaching the homenetwork while travelling.

| Feature                                        | Description                                                                                                                                                                            |
| ---------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> **Secure Remote Access** </nobr>        | Enables encrypted, remote access, which is crucial when your node is permanently hosted at home or on a cloud-based server but requires maintenance from a different location.         |
| <nobr> **Command-Line Interface** </nobr>      | Provides terminal-level management, perfect for minimal servers like Ubuntu that are primarily controlled via shell and don't have any peripherals connected to their machines.        |
| <nobr> **Key-Based Authentication** </nobr>    | It uses public and private keys instead of passwords, making unauthorized access from anywhere in the world significantly more difficult, as only specific devices are allowed access. |
| <nobr> **Port Forwarding & Tunneling** </nobr> | It offers strong support for secure tunnels, which allow users to reach other services, like RPC ports or local dashboards, using encrypted connections for data security and privacy. |
| <nobr> **Extensive Compatibility** </nobr>     | It works across all operation systems or even ARM-based devices. High interoperability allows unified access, even if you are restricted to devices while travelling.                  |

## VPN Tunnel

A Virtual Private Network creates an encrypted tunnel between a remote device and your device even through untrusted networks like the internet or wireless hotspots. VPNs are beneficial when secure ongoing access to a server is needed without exposing it publicly and protect against:

- Spying on unencrypted traffic or packages
- IP-based censorship or filtering
- Geographic routing restrictions
- Unreliable or changing IP addresses

## WireGuard

WireGuard is a next-generation VPN protocol that is a sophisticated virtual private networking technology. It is highly valued for its ease of use, strong security features, and high-speed performance.

:::info

Unlike older VPN stacks like üçä [**OpenVPN**](https://github.com/OpenVPN/openvpn) or üåê [**IPSec**](https://github.com/hwdsl2/setup-ipsec-vpn), üêâ [**WireGuard**](https://github.com/WireGuard/wireguard-linux) has modern cryptography and minimal requirements.

:::

| Feature                          | Description                                                                                                                                               |
| -------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> **Simplicity** </nobr>    | Minimal configuration. Easier to set up and audit due to a smaller codebase compared to other VPN protocols.                                              |
| <nobr> **Speed** </nobr>         | High-performance protocol using modern [ChaCha20](https://en.wikipedia.org/wiki/ChaCha20-Poly1305) cryptography with lower latency and better throughput. |
| <nobr> **Security** </nobr>      | Strong encryption with [Perfect Forward Secrecy](https://en.wikipedia.org/wiki/Forward_secrecy) while only built upon widely peer-reviewed protocols.     |
| <nobr> **Compatibility** </nobr> | Cross-platform support for Linux, Windows, macOS, iOS, Android, and routers.                                                                              |

## Tailscale

Tailscale is a free identity-based VPN service, simplifying the creation of secure peer-to-peer connections between devices without having to deal with additional keys, IP addresses, or firewall rules. Its well-suited at linking personal or team devices in one private network, without the need to open ports or manually operate a VPN protocol.

| Feature                                      | Description                                                                                                                                                                      |
| -------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> **Identity-Based Networking** </nobr> | Authenticates users via [Google](https://www.google.com/), [GitHub](https://www.github.com/), or [Microsoft](https://www.microsoft.com/) to configure access rules aside of IPs. |
| <nobr> **WireGuard Protocol** </nobr>        | All connections are encrypted using the [WireGuard](https://github.com/WireGuard/wireguard-linux) protocol for performance and security.                                         |
| <nobr> **Peer-to-Peer Connections** </nobr>  | Uses [NAT Traversal](https://en.wikipedia.org/wiki/NAT_traversal) for direct streams to reduce latency behind behind intermediate firewalls.                                     |
| <nobr> **Zero Configuration** </nobr>        | Devices are automatically assigned internal IPs and routing without manual setup.                                                                                                |
| <nobr> **Central Control Panel** </nobr>     | Web-based dashboard for monitoring, revoking access, and managing devices.                                                                                                       |
| <nobr> **Cross-Platform Support** </nobr>    | Connect across Windows, macOS, Linux, Android or iOS using related clients or apps.                                                                                              |

:::info

Alternative VPN software for ü¶æ [**Tailscale**](https://tailscale.com/) would be üà∏ [**ZeroTier**](https://www.zerotier.com) and üõ°Ô∏è [**OpenVPN**](https://openvpn.net/community/), both with compromises in ease of use.

:::

---

// File: theory/node-operation/disk-management

# Disk Management

Managing storage is essential when running a blockchain node, particularly for handling large and continuously growing datasets. Using flexible volume management, proper filesystem types, and well-structured partitioning can significantly improve system reliability and future maintenance.

## Logical Volume Manager

LVM is a storage management system that offers flexibility in managing disk space. It allows pooling of several physical disks into a consistent storage pool, known as a volume group, from which logical volumes are created. The system is especially useful for those planning for several nodes, expecting storage growth, and avoiding re-partitioning, as it allows:

- Easy resizing of partitions
- Grouping storage across multiple physical disks
- Clean logical structure for service-specific storage
- Adding new disks without downtime

:::tip Industry Standard

- LVM is the default partitioning method on üî∂ [**Ubuntu**](https://ubuntu.com/download) from version _20.04_ and above.
- üé® [**DAppNode**](https://dappnode.com/) machines also ship with LVM pre-enabled.

:::

## Storage Components

Within the Logical Volume Manager there are several terminologies and concepts.

| Name                             | Abbreviation | Description                                                                                                                               |
| -------------------------------- | ------------ | ----------------------------------------------------------------------------------------------------------------------------------------- |
| <nobr> Physical Volume </nobr>   | PV           | The underlying physical storage disk or partition that is added to a volume group.                                                        |
| <nobr> Logical Volume </nobr>    | LV           | A flexible storage partition carved out of a volume group.                                                                                |
| <nobr> Volume Group </nobr>      | VG           | A collection of physical volumes pooled together into a single logical unit. <br /> **‚Üí** _Logical volumes are created from these groups_ |
| <nobr> Physical Extent </nobr>   | PE           | A fixed-size chunk of space used to manage allocation within a volume group. <br /> **‚Üí** _Logical volumes are built from these chunks_   |
| <nobr> Logical Extent </nobr>    | LE           | Each logical volume consists of multiple logical extents mapped to physical extents.                                                      |
| <nobr> Allocated Extents </nobr> | ‚Äî            | All Physical Extents that are currently assigned to one or more logical volumes.                                                          |

:::tip

Logical volumes can span across multiple hardware disks and can be resized dynamically.

:::

## Filesystem Metadata

Each file system keeps track of data by using index nodes and descriptor blocks. When volume or filesystem expansion occurs, new index nodes and descriptor blocks are created as needed to define and manage additional storage space.

| Component             | Purpose                                                                                |
| --------------------- | -------------------------------------------------------------------------------------- |
| **Index Nodes**       | Track metadata like file size, ownership, and timestamps                               |
| **Descriptor Blocks** | Map index nodes to actual physical extends, used during file creation and modification |

:::info

LVM Metadata is stored on each physical volume to hold configuration data about volume groups and logical volumes.

:::

## Volume Sizing

LVM sets a default size for the root logical volume during server installation to leave headroom for future expansions.

- It's safer to grow volumes than shrink them.
- Shrinking involves more steps and risks, including potential data loss.
- This approach allows resizing after performance benchmarking or growth.

:::tip

More advanced instructions for resizing, expanding volumes, or adding disks can be found in the [**Disk Volumes**](/docs/guides/system-setup/disk-volumes.md) guide.

:::

:::info

The üî∏ [**Ubuntu Server**](/docs/guides/system-setup/disk-volumes.md) installation configured LVM with a default logical volume size of `100GB`.
:::

## Disk Encryption

Encrypting the entire disk ensures maximum data protection but introduces complexity for maintenance or restarts.

- Full disk encryption requires manual decryption on every boot.
- Remote connections and unlocking setups are extremely complex and harder to maintain.

:::tip

For most node setups, **full disk encryption** adds a barrier and **is not recommended**.

:::

:::info

The node's wallet and validator keys are encrypted independently. If needed, smaller encrypted partitions can be added after the regular node setup was completed. This might include extended service automation or sensitive data folders.

:::

---

// File: theory/node-operation/utility-tools

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Utility Tools

Proficiently running a node requires an in-depth knowledge of the command line. From updating packages, editing configuration files, and running system services, having basic tool familiarity will save time and reduce the chances of misconfiguration.

## Text Editors

Text editors allow editing configuration files, service configurations, and application setting tweaking directly from the command line. Ubuntu comes with Vim installed as its default editor, while Nano provides an easier option.

:::tip

For additional commands and descriptions, have a look at the üêç [**Vim Help Page**](https://manpages.ubuntu.com/manpages/noble/de/man1/vim.1.html) or ‚òÇÔ∏è [**Nano Help Page**](https://manpages.ubuntu.com/manpages/bionic/man1/nano.1.html) for üî∏ [**Ubuntu**](https://ubuntu.com/).

:::

| **Editor**      | **Vim**                                                                        | **Nano**                                                          |
| --------------- | ------------------------------------------------------------------------------ | ----------------------------------------------------------------- |
| **Description** | Advanced, modal editor used in Unix systems                                    | <nobr> Beginner-friendly, modeless editor for quick edits </nobr> |
| **Benefits**    | - Highly Configurable <br/> - Ideal for Power Users                            | - Intuitive and Immediate Editing <br/> - Features On-Screen Help |
| **Startup**     | - Write `vim [file]` to open file                                              | - Write `nano [file]` to open file                                |
| **Navigation**  | - Navigate with arrows                                                         | - Navigate with arrows                                            |
| **Insertion**   | - Press `i` to start insertion mode <br/> - Press `Esc` to return to view mode | - No separate modes <br/> - Start typing immediately              |
| **Save**        | - Write `:wq` from view mode to save and quit                                  | - Press `Ctrl + O` to save and `Y` to confirm                     |
| **Quit**        | - Write `:q!` from view mode to exit                                           | - Press `Ctrl + X` to exit                                        |

## Package Management

The Advanced Package Tool is the default package manager used in Debian-based distributions, such as Ubuntu. It is used for the installation, update, and maintenance of software packages downloaded from online repositories.

:::tip

For additional commands and descriptions, have a look at the üì¶ [**APT Help Page**](https://manpages.ubuntu.com/manpages/xenial/man8/apt.8.html) for üî∏ [**Ubuntu**](https://ubuntu.com/).

:::

| Frequent Commands                      | Description                                                                 |
| -------------------------------------- | --------------------------------------------------------------------------- |
| <nobr> `apt update` </nobr>            | Updates the list of available packages and their versions                   |
| <nobr> `apt list --upgradable` </nobr> | Displays a list of packages that can be updated                             |
| <nobr> `apt install [service]` </nobr> | Installs the package of a service                                           |
| <nobr> `apt upgrade` </nobr>           | Upgrades all upgradable packages                                            |
| <nobr> `apt autoremove` </nobr>        | Removes packages that were automatically installed and are no longer needed |
| <nobr> `apt autoclean` </nobr>         | Cleans up the local repository of retrieved package files                   |

## System Control

A system daemon service forms a critical part of modern Debian-based operating systems, as it starts and manages the running programs in the background. System control commands allow the user to monitor and manage such programs individually.

:::tip

For additional commands and descriptions, have a look at the üïπÔ∏è [**System Control Help Page**](https://manpages.ubuntu.com/manpages/trusty/man1/systemctl.1.html) for üî∏ [**Ubuntu**](https://ubuntu.com/).

:::

| Frequent Commands                          | Description                                                |
| ------------------------------------------ | ---------------------------------------------------------- |
| `systemctl list-unit-files --type=service` | Lists all available services and their enablement state    |
| `systemctl daemon-reload`                  | Reloads systems daemon manager configuration               |
| `systemctl is-enabled [service]`           | Checks whether a service is enabled to start at boot       |
| `systemctl start [service]`                | Starts a service immediately                               |
| `systemctl stop [service]`                 | Stops a running service                                    |
| `systemctl restart [service]`              | Restarts a running service                                 |
| `systemctl enable [service]`               | Enables a service to start on boot                         |
| `systemctl disable [service]`              | Disables a service from starting on boot                   |
| `systemctl status [service]`               | Displays current status, logs, and metadata of the service |

## Service Logging

When configuring your service file output, you can choose between journal and system logging, two variants that are very common for reading data and the status of services during maintenance or if there are hickups on ports or interfaces.

| Feature          | Journal Logging                                 | System Logging                           |
| ---------------- | ----------------------------------------------- | ---------------------------------------- |
| Format           | Human Friendly, Structured Format with Metadata | Basic Output as Plain Text               |
| Filtering        | Powerful Filtering by Unit, Process ID, Time    | Less Advanced Filtering through _grep_   |
| Remote Logging   | Not built-in                                    | Supports remote logging over UDP and TCP |
| Space Efficiency | More Compact using Binary Format                | Larger due to Plain Text Format          |
| Tooling          | Requires _journalctl_ from Ubuntu or Linux      | Compatible across all UNIX tools         |

:::tip

For additional commands and descriptions, have a look at the üì∞ [**Journal Control Help Page**](https://manpages.ubuntu.com/manpages/focal/man1/journalctl.1.html) for üî∏ Ubuntu.

:::

<Tabs groupId="logging-tool">
  <TabItem value="journal" label="Journal Logging" default>

| Frequent Commands                          | Description                                                    |
| ------------------------------------------ | -------------------------------------------------------------- |
| `journalctl`                               | Show all logs                                                  |
| `journalctl -r`                            | Show logs in reverse chronological order                       |
| `journalctl -u [service]`                  | Show logs for a specific service                               |
| `journalctl -b`                            | Show logs from the current boot                                |
| `journalctl -b -1`                         | Show logs from the previous boot                               |
| `journalctl --since "YYYY-MM-DD HH:MM:SS"` | Show logs since a specific date and time                       |
| `journalctl --since "1 hour ago"`          | Show logs from the last hour                                   |
| `journalctl -p [priority]`                 | Show logs of a specific priority like `err`, `warning`, `info` |
| `journalctl -f`                            | Follow new log entries in real-time                            |
| `journalctl \| grep [keyword]`             | Search logs for a specific keyword                             |

</TabItem> <TabItem value="system" label="System Logging">

| Frequent Commands                | Description                                      |
| -------------------------------- | ------------------------------------------------ |
| `cat /var/log/syslog`            | Display the entire syslog file                   |
| `less /var/log/syslog`           | View syslog file with pagination                 |
| `tail -f /var/log/syslog`        | Monitor new log entries in real-time             |
| `grep [keyword] /var/log/syslog` | Search for a specific keyword in the syslog file |
| `logger "Your message"`          | Add a custom message to the syslog               |
| `sudo systemctl restart rsyslog` | Restart the syslog service                       |
| `sudo systemctl status rsyslog`  | Check the status of the syslog service           |

</TabItem>
</Tabs>